{"pages":[{"title":"tags","text":"","link":"/tags/index.html"},{"title":"","text":"Emailxuzhipeng418@foxmail.com","link":"/about/index.html"}],"posts":[{"title":"LeetCode Note","text":"一些算法归纳： 2-PassQ1 给定一个字符串S，返回字符串中所有字符距离指定字符C 的最短距离。 A1 从左至右扫描一次，记下 dis[i]=disLeft；再从右至左扫描一次，dis[i]=min(dis[i], disRight)。 12345678910111213141516int[] shortestToChar(String s,char c){ int n=s.length(); int[] ans=new int[n]; int pos=-n; for(int i=0;i&lt;n;i++){ if(s.charAt(i)==c) pos=i; ans[i]=i-pos; } for(int i=n-1;i&gt;=0;i--){ if(s.charAt(i)==c) pos=i; ans[i]=min(ans[i], abs(i-pos)); } return ans;} 152 Given an integer array nums, find the contiguous subarray within an array (containing at least one number) which has the largest product. Example 1: 1234&gt; Input: [2,3,-2,4]&gt; Output: 6&gt; Explanation: [2,3] has the largest product 6.&gt; 解法一：暴力破解。遍历所有子数组，求最大值。 解法二：存储到某个位置为止的所有子数组的最大值和最小值。","link":"/2019/02/24/algorithm/leetcode/"},{"title":"DynamicProxy","text":"关键代码12345678910111213141516171819202122232425262728293031323334interface Interface{ void doSth(String s);}class RealObject implments Interface { void doSth(String s){ //... }}class DynamicProxyHandler implments InvocationHandler { private Object proxied; public DynamicProxyHandler(Object proxied) { this.proxied = proxied; } public Object invoke(Object proxy, Method m, Object[] args){ /* 在此插入代理逻辑 */ return m.invoke(proxied, args); }}public class SimpleDynamicProxy { Interface proxy = (Interface) Proxy.newInstance( Interface.class.getClassLoader(), //一般传这个已加载的类加载器就行 new Class[]{Interface.class}, //实现的接口 new DynamicProxyHandler(new RealObject()) ); proxy.doSth();} 可能生成如下代理类 123456789101112131415161718192021222324final class $proxy0 extends Proxy implments Interface { public $Proxy0(InvocationHandler var1) { super(var1); } public final void doSth(String var){ try{ // 这里的h即上文传入的 new DynamicProxyHandler(new RealObject()) super.h.invoke(this, m4, new Object[]{var}); }catch{ ... } } static{ try{ m4=Class.forName(\"ProxyDemo$Interface\").getMethod(\"doSth\", Class.forName(\"java.lang.String\")) }catch{ ... } } } Proxy 类的源码简单说：先是生成构造器，再用构造器newInstance生成动态代理对象。","link":"/2019/03/10/java/DynamicProxy/"},{"title":"DP Note","text":"dp分类1 Max 1D Range Sumdescription：Give an integer array A containing n non-zero integers, find the max Range Sum Query(RSQ) between two indices i and j in [0…n-1]. dp[i]代表以A[i]结尾的最大范围和。 对于dp[i]：dp[i]= max(dp[i-1], 0) + A[i]. 最大范围和即dp[i]中的最大值。 12345678main(int A[]){ int sum=0,ans=0; for(int i=0;i&lt;A.length,i++){ sum+=A[i]; ans=max(ans,sum); if(sum&lt;0) sum=0; }} 2 LIS最长递增子序列。 例子 ｛-7, 10 , 9 , 2, 3 , 8, 8 , 1｝ 1）LIS[i]= max(LIS[j])+1 (j∈[0,i-1] ,A[j]&lt;A[i] ) 2）L={-7} , L={-7, 10}, L={-7, 9}… 3 0-1 Knapsacktop-down 123456int value(int i,int w){ if(i==N || w==0) return 0; if(dp[i][w]!= -1) return dp[i][w]; if(W[i]&gt;w) return dp[i][w]= value(i+1, w）; return dp[i][w]=max(value(i+1, w), V[i]+ value(i+1, w-W[i]));} bottom-up 123456789101112131415int value(int N, int W){ int[][] dp=new int[N+1][W+1]; for(int i=1;i&lt;=N;i++) for(int j=1;j&lt;=W;j++) if(W[i]&gt;j) dp[i][j]=dp[i-1][j]; else dp[i][j]=max(dp[i-1][j], V[i]+dp[i-1][j-W[i]]);}//可以优化，一维数组解决。int value(int N; int W){ int[] dp=new int[W+1]; for(int i=1;i&lt;=N;i++) for(int j=W;j&gt;=V[i];j--) dp[j]=max(dp[j],dp[j- W[i]]);} 3.2 Subset Sum1）给定一个非负数整数集S，判断是否有S的非空子集之和等于给定的Sum。 top-down 123456789solve(i,sum) 表示从i开始是否有子集和等于Sum。base case:solve(n,sum)=false (sum&gt;0 &amp;&amp; i==n);solve(i,0)=true (sum==0)//!!!! Important 跳过if(S[i]&gt;sum) return solve(i+1,sum);solve(i,sum)=solve(i+1,sum) || solve(i+1,sum-S[i]); bottom-up 123456789101112131415//dp[i][j] 表示到前i个数中，是否有sum=j；boolean[][] dp=new boolean[n+1][sum+1];for(int i=0;i&lt;=n;i++) dp[i][0]=true;for(int i=1;i&lt;=n;i++) for(int j=1;j&lt;=sum;j++){ if(j&lt;S[i]) dp[i][j]=dp[i-1][j]; else dp[i][j]=dp[i-1][j] || dp[i-1][j-S[i]]; }//可以优化for(int i=1;i&lt;=n;i++) for(int j=sum;j&gt;=S[i];j--) dp[j]=dp[j] || dp[j-S[i]]; 变种1 给定一个非负数的数组，是否可以将其分成两个和相等的数组？ Q： 搜索该数组中是否有部分和等于数组和的一半。 ​ 1 用Subset Sum。 ​ 2 回溯。 变种2 给定一个非负数的数组， 是否可以将其分为 k 个和相等的数组？ Q：回溯搜索该数组，目标为 sum/k。 1234567891011121314151617boolean backtract(int start, int[] a, boolean[] visited, int k, int sum, int target){ if(k==1) return true;//只剩下最后一组 if(sum&gt;target) return false; if(sum==target) return backtract(0,a,visited,k-1,0,target); for(int i=start;i&lt;n;i++){ if(!visited[i]){ visited[i]=true; if(backtract(i+1,a,visited,k, sum+a[i], target)) return true; visited[i]=false; } } return false;} 4 Coin Change例子 N=2, 币种 {1,5}, V=10 1 求最少使用多少个硬币。 123change(0)=0;change(&lt;0) = INF;change(i) = min(change(i- coinValue[j])) +1 2 求有多少种换法。 1234dp[i][0]=1;if(j&lt;coinValue[i]) dp[i][j]=dp[i-1][j];else dp[i][j] = dp[i-1][j]+dp[i][j- coinValue[i]]; 5 K个数加到N12345678ways(n,k);ways(i,1)=1;for(int j=2;j&lt;=k;j++;) for(int i=0;i&lt;=n;i++) for(int x=0;x&lt;=i;x++) dp[i][j]+=dp[i-x][j-1]; 6 Cutting Sticks123cut(i,i+1)=0；cut(i,j)=min(cut(i,k) + cut(k,j) + A[j]-A[i]) k∈[i+1,j) dp一般思路：State Expressions –&gt; Base Case –&gt; General Case（Top-down , Bottom-up） 7 String Processing With DP7.1 LCS(最长公共子序列)12if(a[i]== b[j]) dp[i][j]=dp[i-1][j-1]+1;else dp[i][j]=max(dp[i-1][j], dp[i][j-1]); 另外：最长公共子串 12if(a[i]==b[j]) dp[i][j]=dp[i-1][j-1]+1;else dp[i][j]=0; 7.2 Longest Palindrome(回文)搜索回文串可用“中心向两边扩散算法”。 一个变种：可删除的情况下，某字符串中最长回文串长度。 12345678dp[l][r] 表示 A[l...r] 最长回文串的长度。Base Case: if(l== r) dp[l][r]= 1Recurrent: if(l&lt;r) if(A[l]==A[r]) dp[l][r]=dp[l+1][r-1]+2; else dp[l][r]= max(dp[l+1,r] , dp[l][r-1]);","link":"/2019/02/24/algorithm/dp/"},{"title":"Java concurrency in practice Note","text":"Java concurrency in practice Notestate（状态）是一种数据，储存在状态变量中，状态变量有可能是实例域或静态域。 线程安全表面上是在谈论代码，实际上是在使数据避免不受控制的线程的访问。 为了使对象线程安全，我需要使用同步来协调线程的访问对象的可变状态。 实现同步主要是synchronization关键字，这个关键字提供了排他锁。其他的同步机制还有volatile、显示锁和原子变量。 避免线程安全问题，三种思路： 不在线程间分享状态变量 使状态变量变得不可变 任何时候访问状态变量时，都使用同步 设计一个线程安全的类比改进一个类变得线程安全容易得多。 无状态的类总是线程安全的。 但是当我们引入状态以后： 12345678class A{ private long count=0; public long getCount(){...} public void service(){ ++count; }} ++count不是原子性的，即它是可拆分的：先读数据，再加，再写数据，该操作可以定义为“read-modify-write” 那么就可能不安全，如下 “check-then-act” 123456789class A{ private Object instance=null; public Object getInstance(){ if(instance==null) instance=new Object(); return instance; }} 以上也不是线程安全的，两个线程访问，可能得到两个不同的对象。 可以使用已存在的原子对象来执行以上操作，使得以上类满足线程安全。使用已存在的原子类的原因是：容易被验证为是线程安全的。 12345678// Code1-1class A{ private final AtomicLong count=new AtomicLong(0); public service(){ count.incrementAndGet(); }} 锁 同步锁 每个Java对象都可以隐式地作为锁，以用来实现同步。这个锁机制称为固有锁或排他锁，具有排他性。这种机制很容易保证线程安全了。 12345678910class A{ //锁的对象是 调用同步方法的对象 @GuardedBy(\"this\") BigInteger lastNumber; @GuardedBy(\"this\") BigInteger[] lastFactors; public synchronized void service(ServletRequest req, ServletResponse resp){ lastNumber... lastFactors... }} 以上固有锁是可重入的，其实现机制是这样的：JVM记录每个锁的线程，并设置一个计数器；如果同一个线程再次请求这个锁，则计数器加一，不同的线程不会请求到这个锁。锁上每个线程退出时，计数器减一，减到0时，锁释放。可重入机制，简化了面向对象的设计代码，可以在一定程度上防止死锁，如下。 1234567891011class A{ public synchronized void doSomething(){ ... }}public class B extends A{ public synchronized void doSomething(){ super.doSomething(); }} 以上code1-1的并发性很差，原因是：同时调用的请求数并不是受限于计算资源，而是受限于应用本身。可以通过缩小同步块的范围来改善这个状况。 可以把耗时任务排除在同步块外，以致于在进行耗时任务时不会阻止其他线程访问共享状态。 1234567891011121314151617181920212223242526272829303132333435363738class A { @GuardedBy(\"this\") BigInteger lastNumber; @GuardedBy(\"this\") BigInteger[] lastFactors; @GuardedBy(\"this\") long hits; @GuardedBy(\"this\") long cacheHits; public synchronized long getHits(){ return hits; } public synchronized double getCacheHitRatio() { return (double) cacheHits / (double) hits; } public void service(req,resp){ BigInteger i = extractFromRequest(req); BigInteger[] factors = null; synchronized(this){ ++hits; if(i.equals(lastNumber)){ ++cacheHits; factors=lastFactors.clone(); } } if(factors==null){ //long-running factors=factor(i); synchronized(this){ lastNumber=i; lastFactors=factors.clone(); } } encodeIntoResponse(resp, factors); }} 以上说了同步块的大小，不要把JUC中的原子类和Synchronize混用，这样容易引起混淆，也不会提高性能和安全。 由于同步是有代价，不要把同步块的范围分割过大。例如，不要单独将以上“++hits”放在一个同步块中。 共享对象同步不仅保证了原子性，保证了一个线程的修改在其他线程的可见性。 volatile变量一种同步的弱形式，读一个volitale类型的变量，总会返回某一个线程写入的最新值。只能保证可见性。 典型使用场景是标记。 12345volatile boolean asleep;... while(!asleep){ countSomeSheep(); } 显示锁内部锁在大多数情况下可以很好工作，但存在一定的局限性：不能中断那些正在等待锁的线程，且在请求锁失败的情况下必须无限等待。某些时候，显示锁提供了更好的活跃性和性能。 123456789Lock lock = new ReentrantLock();...lock.lock();try{ //更新状态 }finally{ lock.unlock();} 在内部锁中，死锁是致命的，唯一的恢复方法是重启，唯一的预防方法是构建程序时不出错，这样就不可能允许不一致的锁顺序。","link":"/2019/05/11/java/concurrent/"},{"title":"Java Advanced","text":"why Generic progrgrammingType Params1234567//before generic classesclass ArrayList{ Object[] elemData; ... Object get(int i){...} void add(Object o){...}} 以上两个问题： 1、取数据时要转换类型。 1234ArrayList files = new ArrayList();...files.add(new File(\"...\"));//运行时出错String filename=(String)files.get(0); 2、泛型提供了一个更好地解决办法：类型参数。 1234ArrayList&lt;String&gt; files=new ArrayList&lt;&gt;();String filename=files.get(0);// a string not an objectfiles.add(new File(\"...\"))//wrong Defining a Simple Generic class123456789class Pair&lt;T&gt;{ T first; T second; Pair(T first,T second){...} T getFirst(){} T getSecond(){} void setFirst(T val){} void setSecond(T val){}} 一般 E -&gt; elem; K,V-&gt;key,value; T,U,S -&gt;any type Generic Methods123456789101112class ArrayAlg{ static &lt;T&gt; T getMiddle(T... a){ return a[a.length/2]; }}String middle =ArrayAlg.getMiddle(\"a\",\"b\",\"c\");//Double Integer : wrongdouble middle=ArrayAlg.getMiddle(3.14, 1 , 0);double middle=ArrayAlg.getMiddle(3.14, 1.0 , 0.0); Bounds for Type Var有时候，需要限制。 12345678class ArrayAlg{ static &lt;T&gt; T min(T[] a){ T smallest =a[0]; for(int i=1;i&lt;a.length;i++) if(smallest.compareTo(a[i])&gt;0) smallest=a[i]; return smallest; }} 如何保证T[] a有compareTo方法呢？ 限制bound static &lt;T extends Comparable&gt; T min(T[] a){ } 和继承一样，class至多只能有一个，且必须放在第一个。 T extends Comparable &amp; Serializable Genneric code and the VM虚拟机中没有泛型类型对象，所有对象都是原始类型。 Type erasure类型变量被它们的bounding type替换，或Object 1234567891011121314151617class Interval &lt;T extends Comparable &amp; Serializable&gt; implements Serializable{ T lower; T upper; ... Interval(T first,T second){ if(first.compareTo(second)&lt;=0) {low=first; upper=second;} else{lower=second;upper=first;} }}//raw typesclass Interval implements Serializable{ Comparable lower; Comparable upper; ... Interval(Comparable first,Comparable second){}} 若以上是&lt;T extends Serializable &amp; Comparable&gt; 则raw type将T 替换为Serializable，必要时，编译器插入到Comparable的转换。 因此，为了效率，将没有方法的接口放在bound list最后。 Translating Generic Expressionscompiler translates the method call into two vm instrucations: A call to the raw method Pair.getFirst A cast of the returned Object to the real type Translating Generic Methods类型擦除也发生在泛型方法。 static &lt;T extends Comparable&gt; T min(T[] a) static Comparable min(Comparable[] a) 问题： 123456789101112131415161718192021class DateInterval extends Pair&lt;LocalDate&gt;{ void setSecond(LocalDate second){ if(second.compareTo(getFirst())&gt;=0){ super.setSecond(second); } }}//after erasureclass DateInterval extends Pair{ void setSecond(Object second){ } void setSecond(LocalDate second){ }}Pair&lt;LocalDate&gt; pair =new DataInterval(...);pair.setSecond(aDate); 我们期待多态调用setSecond(LocalDate second)。 解决类型擦除对多态调用的干扰，编译器生成了bridge method。 void setSecond(Object second){ setSecond((LocalDate)second) } get 1234class DateInterval extends Pair&lt;LocalDate&gt;{ public LocalDate getSecond() { return (LocalDate) super.getSecond(); } . . .} LocalDate getSecond() // defined in DateIntervalObject getSecond() // overrides the method defined in Pair to call the first method VM中，参数和返回值类型指定了一个函数。 总结： 虚拟机中只有原始类型和方法，没有泛型。 所有的类型被其限制（bound）代替。 桥方法被合成来保留泛型。 类型转换在必要时插入以保证类型安全。 Restrictions and LimitationsType params cannot be instantiated with primative types因为类型擦除。 Runtime Type Inquiry only works with raw types12345Pair&lt;String&gt; stringPair=\"...\"Pair&lt;Employee&gt; employeePair=\"...\"//equal if(stringPair.getClass()==employeePair.getClass()) Cannot Create Arrays of Parameterized TypesPair&lt;String&gt;[] table=new Pair&lt;String&gt;[10]; //error use ArrayList&lt;Pair&lt;String&gt;&gt; #### Inheritance Rules for generic types Wildcard(通配符) Types12345void printCollection(Collection&lt;?&gt; c){ for(Object e:c){ print(c); }} collection&lt;?&gt; 是所有集合类型的超类。 12Collection&lt;?&gt; c=new ArrayList&lt;String&gt;();c.add(new Object()); //compile-time error 以上collection&lt;?&gt;中的类型是未知的，不能添加任何类型。 Bounded wildcards1234567//List&lt;Circle&gt;void drawAll(List&lt;? extends Shape&gt; shapes){ ... //compile-time error, 不能确定\"?\"是否为Rect的超类 shapes.add(new Rect());} 一个用例： 12345678class Census{ public static void addRegistry(Map&lt;String,? extends Person&gt;){ }}Map&lt;String,Driver&gt; allDrives=...Census.addRegistry(allDrives); 1234567891011121314151617181920static &lt;T&gt; T writeAll(Collection&lt;T&gt; coll,Sink&lt;T&gt; sink){ }Sink&lt;Object&gt; s;Collection&lt;String&gt; cs;String str=writeAll(cs,s);//wrong ,T must be same//fix1static &lt;T&gt; T writeAll(Collection&lt;? extends T&gt; coll,Sink&lt;T&gt; sink){ }String str=writeAll(cs,s);//return value is wrong//fix2static &lt;T&gt; T writeAll(Collection&lt;T&gt; coll,Sink&lt;? super T&gt; sink){ }String str=writeAll(cs,s);//ok! java source examples 12345TreeSet&lt;E&gt;//constructorTreeSet(Collection&lt;E&gt; c)TreeSet(Collection&lt;? super E&gt; c) 12345678910111213141516static &lt;T extends Comparable&lt;T&gt;&gt; T max(Collection&lt;T&gt; coll){ }class Foo implements Comparable&lt;Object&gt;{ }Collection&lt;Foo&gt; c;//wrong Foo not implements Comparable&lt;Foo&gt;Foo foo=max(c);//fixstatic &lt;T extends Comparable&lt;? super T&gt;&gt; T max(Collection&lt;T&gt; coll){ } 通常来说，可用？来提高灵活性。 wildcard capture12345678Set&lt;?&gt; unknownSet=new HashSet&lt;String&gt;();public static &lt;T&gt; void addToSet(Set&lt;T&gt; s,T t){ } //unknownSet cannot be guaranteed to be a set of stringsaddToSet(unknownSet,\"abc\");//wrong 12345678class Collections { ... public static &lt;T&gt; Set&lt;T&gt; unmodifiableSet(Set&lt;T&gt; set) { ... }}...Set&lt;?&gt; s = Collections.unmodifiableSet(unknownSet); // This works! Why? It seems this should not be allowed; yet, looking at this specific call, it is perfectly safe to permit it. After all, unmodifiableSet() does work for any kind of Set, regardless of its element type. IO Byte Based input ouput Character Based input output Base InputStream OutputStream Reader Write File FileInputStream FileOutputStream FileReader FileWriter Buffer BufferedInputStream BufferedOutputStream BufferedReader BufferedWrite Format PrintStream PrintWriter Data DataInputStream DataOutputStream Object ObjectInputStream ObjectOutputStream 字节流应该只被用于最原始的I/O。 字符流比字节流更复杂。 字符流可以封装字节流，字符流用字节流处理物理IO，而字节流处理字符与字节之间的翻译，例如FileReader用FileInputStream，FileWriter用FileOutputStream。 有两个byte-to-character “bridge” streams: InputStreamReader和OutputStreamWriter。当原有的字符流不符合需求时，可用它们新建字符流来适应需求。如Sockets。 当字符IO出现更大的单位时（非单个字符），常见的是line：a string of characters with a line terminator at the end。(“\\r \\n”) 用BufferReader和PrintWriter。 Buffer reader仅当buffer空时，调用native API，同理，writer当buffer fill时，调用native API。 若要fill之前，及时输出buffer，可用flush 处理格式化的数据：Scanner、Format。 命令行IO Standard Stream：System.in，out，err。 System.out,err 定义为PrintStream字节流，但模仿字符流的特征，而System.in是字节流，但没有字符流的特征，使用标准输入作为字符流，可以包装InputStreamReader，InputStreamReader cin=new InputStreamReader(System.in); Console更高级。 Data Streams支持原始数据类型及字符串类型的二进制IO。 Object Stream支持对象IO。绝大多数标准类实现了Serializable。对象流也实现了数据流的接口。 File IO：java.nio 可替代基础的java.io。 Path：representing a file or directory 一个例子：target.reslove(source.relativize(file)); While stream I/O reads a character at a time, channel I/O reads a buffer at a time. JAVA IO：Decorator design pattern！！ Channel IO ByteBuffer.flip() after a sequence of puts is used to fill the ByteBuffer, flip will set the limit of the buffer to the current position and reset the position to zero 12345678CharBuffer cbuff = CharBuffer.allocate(40);cbuff.put(\"hello\"); // what below two line of code is what flip doescbuff.limit(cbuff.position());cbuff.position(0); while(cbuff.hasRemaining()) { System.out.println(cbuff.get());} ReflectClass对于每个对象，JVM实例化一个不可变的Class，它提供检测对象运行时属性的方法，这些属性包括了对象的成员和类型信息。Class也提供了创建新的类和对象的能力。更重要的是，它是所有Reflection API的入口。","link":"/2018/12/31/java/generic/"},{"title":"Spring框架的一些理解","text":"Java Annotation对于注解而言，若没有相应处理器，那它和注释没什么区别。 Java注解示例： 123456789101112131415161718192021222324252627// 声明注解使用的地方。 这里是方法级。@Target(ElementType.METHOD)//声明注解的生命时长。 这里是在运行时被虚拟机获得，所以可以使用反射来读。@Retention(RetentionPolicy.RUNTIME)public @interface UseCase{ int id(); String description() default \"no description\";}class A{ @UseCase(id=1,description=\"......\") void methodA{...} ....}class UseCaseTracker{ public static void trackUseCases(List&lt;Integer&gt; useCases, Class&lt;?&gt; cl){ for(Method m: cl.getDeclaredMethods()){ UseCase uc=m.getAnnonation(UseCase.class); if(uc!=null){ print(uc.id(), uc.description()); } } }} 另外，注解特别适用于生成框架的“样板文件”（boilerplate）代码。如Hibernate、Spring Boot等。 SpringIoC 的一种类型是依赖注入。 ApplicationContext接口代表了Spring IoC容器，它负责实例化、配置并装配beans。 而容器是通过读配置metadata来获取配置的指令，其中，metadata包括XML、Java 注解或Java 代码。 @Configuration 表明该类可声明@Bean方法，并可Spring容器处理而产生Bean定义。 12345678910111213141516@Configurationpublic class HelloWorldConfiguration { //等价于&lt;bean id=\"provider\", class=\"...\"/&gt; @Bean public MessageProvider provider() { return new HelloWorldMassgeProvider(); } @Bean public MessageRenderer renderer() { MessageRenderer renderer = new StandardOutMessageRenderer(); renderer.setMessageProvider(provider()); return renderer; }} 相应的测试代码 12345678public class HelloWorldSpringAnnotated { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext (HelloWorldConfiguration.class); MessageRenderer renderer = ctx.getBean(\"renderer\", MessageRenderer.class); renderer.render(); }} 以上代码也可以将Bean定义到外面，然后通过@ComponentScan来引入，如下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package ch3.annotated@Service(\"provider\")public class ConfigurableMessageProvider implements MessageProvider { private String message; //基于构造器的注入 @Autowired public ConfigurableMessageProvider( @Value(\"Cofigurable message\") String message) { this.message = message; } public String getMessage() { return message; }}//-------@Service(\"renderer\")public class StandardOutMessageRenderer implements MessageRenderer { private MessageProvider messageProvider; public void render() { System.out.println(messageProvider.getMessage()); } //基于Setter注入 @Autowired public void setMessageProvider(MessageProvider provider) { messageProvider = provider; } public MessageProvider getMessageProvider() { return messageProvider; }}//--------//启动 @Component的扫描@ComponentScan(\"ch3.annotated\")@Configurationpublic class HelloWorldSpringAnnotated { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext (HelloWorldSpringAnnotated.class); MessageRenderer renderer = ctx.getBean(\"renderer\", MessageRenderer.class); renderer.render(); }} 由以上，可以引出Spring Boot中的 @SpringBootApplication。 它等价于 @ComponentScan、@Configuration、@EnableAutoConfiguration。","link":"/2019/04/22/java/spring/"},{"title":"Java interview","text":"Java GCJava堆和方法区中内存的分配和回收是动态的，所以GC关注的是这部分内存。 判断对象可回收引用计数算法对于一个对象，每当有地方引用它，计数器加1；当引用失效，计数器减1。任何时刻计数器为0的对象为可回收的对象。存在对象之间相互循环引用问题。 可达性分析算法通过一系列的“GC Roots”对象作为起始点，从这些节点开始向下搜索。当一个对象到GC Roots不可达时，则被判定为可回收的对象。 收集算法根据对象存活周期的不同，把Java堆分为新生代和老年代。新生代中，对象大批死亡，存活率较少，可以选用复制算法。老年代中对象存活率高、没有额外空间对它进分配担保，使用“标记-清除”和“标记-整理”（多了整理）回收。 回收时机 大多数情况下，对象在新生代Eden区中分配。当空间不足时，发生Minor GC（新生代GC）。新生代的From Space区域空间不足，可会发生GC。 程序调用System.gc。 HashMapHashMap在底层将key-value当成一个整体，即Node对象，这个对象实现了Map.Entry接口。通过Node[]来保存所有的key-value。 存数据时，通过hash算法决定其在数组中的存储位置；若该位置已经有数据，再根据equals来判断key是否相同，若相同更新，若不相同，则发生冲突，连接在链表头。 取数据时，同样通过hash和equals。 扩容随着数组中元素增多，hash冲突的几率变大。为了提高查询的效率，要进行扩容。扩容时最消耗性能：将原数组中的元素重新计算再存到新数组中。 当HashMap中元素的个数超过 数组的大小*load factor时，就会扩容，扩大一倍。 默认16，0.75 ConrrentHashMap 锁segment，其他线程可以put，可以读。","link":"/2019/05/11/java/interview/"},{"title":"Java8 Learn","text":"行为参数化 行为参数化，就是一个方法接受多个不同的行为作为参数，并在内部使用它们，完成不同行为的能力。 行为参数化让代码更好地适应不断变化的要求，减轻未来的工作量。 传递代码，就是将新行为作为参数传递给方法。Java API中包括排序、线程和GUI处理。 Lambda在哪里使用Lambda? 函数式接口函数式接口即只定义一个抽象方法的接口。 Lambda表达式允许你直接以内联的形式为函数式接口的抽象方法提供实现，并把整个表达式作为函数式接口的实例（具体说来，是函数式接口一个具体实现的实例）。 使用： 1234@FunctionalInterfacepublic interface BufferedReaderProcessor { String process(BufferedReader b) throws IOException;} 123456789101112131415public class BufferTest { public static String processFile(BufferedReaderProcessor p) throws IOException { try (BufferedReader br = new BufferedReader(new FileReader(\"data.txt\"))) { return p.process(br); } } public static void main(String[] args) throws IOException { String oneLine = processFile((BufferedReader br) -&gt; br.readLine()); // String oneLine = processFile(BufferedReader::readLine); String twoLines = processFile( (BufferedReader br) -&gt; br.readLine() + br.readLine()); }} 使用函数式接口函数式接口很有用，因为抽象方法的签名可以描述Lambda表达式的签名。函数式接口的抽象方法的签名称为函数描述符。 Java API中已经有了几个函数式接口，比如 Comparable 、 Runnable 和Callable 。 Java 8 中有Predicate 、 Consumer 和 Function。 123456@FunctionalInterfacepublic interface Predicate&lt;T&gt;{ boolean test(T t);}Predicate&lt;String&gt; nonEmptyStringPredicate = (String s) -&gt; !s.isEmpty(); 12345678910111213@FunctionalInterfacepublic interface Consumer&lt;T&gt;{ void accept(T t);}public static &lt;T&gt; void forEach(List&lt;T&gt; list, Consumer&lt;T&gt; c){ for(T i: list){ c.accept(i); }}forEach( Arrays.asList(1,2,3,4,5),(Integer i) -&gt; System.out.println(i)); 123456789101112131415@FunctionalInterfacepublic interface Function&lt;T, R&gt;{ R apply(T t);}public static &lt;T, R&gt; List&lt;R&gt; map(List&lt;T&gt; list,Function&lt;T, R&gt; f){List&lt;R&gt; result = new ArrayList&lt;&gt;(); for(T s: list){ result.add(f.apply(s)); } return result;}// [7, 2, 6]List&lt;Integer&gt; l = map(Arrays.asList(\"lambdas\",\"in\",\"action\"),(String s) -&gt; s.length()); 原始类型特化比如，在下面的代码中，使用 IntPredicate 就避免了对值 1000 进行装箱操作，但要是用 Predicate&lt;Integer&gt; 就会把参数 1000 装箱到一个 Integer 对象中： 12345678public interface IntPredicate{ boolean test(int t);}IntPredicate evenNumbers = (int i) -&gt; i % 2 == 0;evenNumbers.test(1000);Predicate&lt;Integer&gt; oddNumbers = (Integer i) -&gt; i % 2 == 1;oddNumbers.test(1000); 因函数式接口都不允许抛出受检异常。如果需要Lambda表达式抛出异常，有两种方法：定义一个自己的函数式接口，并声明受检异常，或把Lambda包在一个try/catch块中。 类型检查、类型推断以及限制类型推断Java编译器会从上下文（目标类型）推断出用什么函数式接口来配合Lambda表达式，这意味着它也可以推断出适合Lambda的签名，因为函数描述符可以通过目标类型来得到。这样做的好处在于，编译器可以了解Lambda表达式的参数类型，这样就可以在Lambda语法中省去标注参数类型。 方法引用可以视为某些Lambda的快捷写法。可以重复使用现有的方法定义，并像Lambda一样传递它们。 如果一个Lambda表达式只是“直接调用这个方法”，那最好还是用名称来调用它，而不是去描述如何调用它。 复合Lambda表达式的有用方法比较器复合1inventory.sort(comparing(Apple::getWeight).reversed()); 比较器链123inventory.sort(comparing(Apple::getWeight) .reversed() .thenComparing(Apple::getCountry)); 谓词复合123Predicate&lt;Apple&gt; redAndHeavyAppleOrGreen = redApple.and(a -&gt; a.getWeight() &gt; 150) .or(a -&gt; \"green\".equals(a.getColor())); 函数复合1234Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;Function&lt;Integer, Integer&gt; h = f.andThen(g);int result = h.apply(1); 流它允许以声明性方式处理数据集合（通过查询语句来表达，而不是临时编写一个实现）。 只能遍历一次。 内部迭代与外部迭代Java Collection外部迭代，Stream内部迭代。 内部迭代优点：可以透明地并行处理， 或者用更优化的顺序进行处理。 中间操作诸如 filter 或 sorted 等中间操作会返回另一个流。这让多个操作可以连接起来形成一个查询。重要的是，除非流水线上触发一个终端操作，否则中间操作不会执行任何处理——它们很懒。 终端操作终端操作会从流的流水线生成结果。其结果是任何不是流的值，比如 List 、 Integer ，甚至 void 。 使用流三件事：一数据源、二中间操作链、三终端操作。 流的流水线理念类似于构建器模式。 筛选和切片用谓词筛选123List&lt;Dish&gt; vegetarianMenu = menu.stream() .filter(Dish::isVegetarian) .collect(toList()); 流还支持一个叫作 distinct 的方法，它会返回一个元素各异（根据流所生成元素的hashCode 和 equals 方法实现）的流。 截短流流支持 limit(n) 方法，该方法会返回一个不超过给定长度的流。 跳过元素流还支持 skip(n) 方法，返回一个扔掉了前 n 个元素的流。 映射流的扁平化 Arrays.stream() 的方法可以接受一个数组并产生一个流 123456List&lt;String&gt; uniqueCharacters = words.stream() .map(w -&gt; w.split(\"\")) .flatMap(Arrays::stream) .distinct() .collect(Collectors.toList()); flatMap合并为一个流。 查找和匹配allMatch、anyMatch、noneMatch、findFirst、findAny 短路求值对于流而言，某些操作（例如 allMatch 、 anyMatch 、 noneMatch 、 findFirst 和 findAny ）不用处理整个流就能得到结果。只要找到一个元素，就可以有结果了。同样， limit 也是一个短路操作：它只需要创建一个给定大小的流，而用不着处理流中所有的元素。在碰到无限大小的流的时候，这种操作就有用了：它们可以把无限流变成有限流。 归约算术123int sum = numbers.stream().reduce(0, (a, b) -&gt; a + b);int sum = numbers.stream().reduce(0, Integer::sum); 最值1Optional&lt;Integer&gt; max = numbers.stream().reduce(Integer::max); 原始类型流特化IntStream、DoubleStream、LongStream，分别将流中的元素特化为int、long和double，从而避免了暗含的装箱成本。还带来了进行常用数值归约的新方法，如sum、max。 IntStream 还支持其他的方便方法，如max 、 min 、 average 等。 映射到数值流123int calories = menu.stream() .mapToInt(Dish::getCalories) .sum(); 转换回对象流IntStream 上的操作只能产生原始整数： IntStream 的 map 操作接受的Lambda必须接受 int 并返回 int。 1Stream&lt;Integer&gt; stream = intStream.boxed(); 数值范围Java 8引入了两个可以用于 IntStream 和 LongStream 的静态方法，帮助生成这种范围：range 和 rangeClosed 。这两个方法都是第一个参数受起始值，第二个参数接受结束值。但range 是不包含结束值的，而 rangeClosed 则包含结束值。 构建流由值创建流静态方法Stream.of，通过显示值创建流。可接受任意数量的参数。 1Stream&lt;String&gt; stream = Stream.of(\"Java 8 \", \"Lambdas \", \"In \", \"Action\"); 可使用empty得到一个空流。 1Stream&lt;String&gt; emptyStream = Stream.empty(); 由数组创建流Arrays.stream接受数组作为参数，例如，可将一个原始类型int转换成IntStream。 12int[] numbers = {2, 3, 5, 7, 11, 13};int sum = Arrays.stream(numbers).sum(); 由文件生成流Java NIO（非阻塞IO） 由函数生成流：创建无限流Stream API提供了两个静态方法来从函数生成流： Stream.iterate 和 Stream.generate 。 123Stream.iterate(0, n -&gt; n + 2) .limit(10) .forEach(System.out::println); 都是按需生成，但generate不是依次对每个新生成的值应用函数。它接受一个Supplier&lt;T&gt;类型的Lambda提供新的值。 123Stream.generate(Math::random) .limit(5) .forEach(System.out::println); 用流&lt;收集&gt;数据函数式编程相对于指令式编程一个主要的优势：只需指出希望的结果——“做什么”，而不用操心执行的步骤——“如何做”。 预定义收集器三大功能： 将流元素归约和汇总为一个值 元素分组 元素分区 归约和汇总12long howManyDishes = menu.stream().count()；int howManyDishes = menu.size(); 查找流中的最大值和最小值Collectors.maxBy 和Collectors.minBy ，用来计算流中的最大或最小值。这两个收集器接收一个 Comparator 参数来比较流中的元素。 12345678910Comparator&lt;Dish&gt; dishCaloriesComparator = Comparator.comparingInt(Dish::getCalories);Optional&lt;Dish&gt; mostCalorieDish = menu.stream() .collect(maxBy(dishCaloriesComparator));Optional&lt;Dish&gt; mostCalorieDish = menu.stream() .max(dishCaloriesComp); 汇总12345678910111213141516// 求和int totalCalories = menu.stream().collect(summingInt(Dish::getCalories));int totalCalories = menu.stream() .mapToInt(Dish::getCalories).sum();// 求平均值double avgCalories = menu.stream().collect(averagingInt(Dish::getCalories));OptionalDouble avgCalories2 = menu.stream() .mapToDouble(Dish::getCalories) .average(); 有时候，我们可能希望得到两个或更多这样的结果，而且只需要一次操作就可以完成。此时，可以使用summarizingInt工厂方法返回收集器。例如，通过一次summarinzing操作，即可得到菜肴热量的总和、平均值、最大值、最小值： 12IntSummaryStatistics menuStatistics = menu.stream().collect(summarizingInt(Dish::getCalories)); 收集到一个IntSummaryStatisics中，它提供了一个取值方法来访问结果。 连接字符串joining工厂方法返回一个收集器会把对流中的每一个对象应用toString方法得到的字符串连接成一个字符串。 1String shortMeu = menu.stream().map(Dish::getName).collect(joining()); joining内部使用StringBuilder。如果Dish类有一个toString方法来返回菜肴的名称，那无需用提取每一道菜名称的函数来对原流做映射，就能得到相同的结果： 1String shortMenu = menu.stream().collect(joining()); joining()工厂方法有一个重载版本，可接受分界符， 1String shortMenu = menu.stream().map(Dish::getName).collect(joining(\", \")); 广义的归约汇总以上所有的收集器，都可以用reducing方法定义归约过程。以上方法只是方便程序员而已。 collect与reduce: collect()适合表达可变容器上的归约，更关键的是它适合并行操作。 根据情况选择最佳方案 以下开始发挥collect的作用分组Collections.groupingBy(Function) Function称为分类函数。分组操作的结果是一个Map。 12Map&lt;Dish.Type, List&lt;Dish&gt;&gt; dishesByType = menu.stream().collect(groupingBy(Dish::getType)); 可用Lambda编写复杂的分类函数。 Collections.groupingBy(Function,Collector) 接受collector类型的第二个参数，进行二级分组。可把一个内层的groupingBy传递给外层的groupingBy，作为二级分类标准。 这里的collector可以是任意类型，例如counting()，maxBy()。 maxBy(Comparator) 1234Map&lt;Dish.Type, Optional&lt;Dish&gt;&gt; mostCaloricByType = menu.stream() .collect(groupingBy(Dish::getType, maxBy(comparingInt(Dish::getCalories)))); groupingBy 收集器只有在应用分组条件后，第一次在流中找到某个键对应的元素时才会把键加入分组 Map 中。这意味着 Optional 包装器在这里不是很有用。 把收集器返回的结果转换为另一种类型，你可以使用Collectors.collectingAndThen 工厂方法返回的收集器。 123456Map&lt;Dish.Type, Dish&gt; mostCaloricByType = menu.stream() .collect(groupingBy(Dish::getType, collectingAndThen( maxBy(comparingInt(Dish::getCalories)), Optional::get))); 123Map&lt;Dish.Type, Integer&gt; totalCaloriesByType = menu.stream().collect(groupingBy(Dish::getType, summingInt(Dish::getCalories))); 1234567Map&lt;Dish.Type, Set&lt;CaloricLevel&gt;&gt; caloricLevelsByType = menu.stream().collect( groupingBy(Dish::getType, mapping( dish -&gt; { if (dish.getCalories() &lt;= 400) return CaloricLevel.DIET; else if (dish.getCalories() &lt;= 700) return CaloricLevel.NORMAL; else return CaloricLevel.FAT; }, toSet() ))); 注意在上一个示例中，对于返回的 Set 是什么类型并没有任何保证。但通过使用 toCollection ，你就可以有更多的控制。 1234567Map&lt;Dish.Type, Set&lt;CaloricLevel&gt;&gt; caloricLevelsByType = menu.stream().collect( groupingBy(Dish::getType, mapping( dish -&gt; { if (dish.getCalories() &lt;= 400) return CaloricLevel.DIET; else if (dish.getCalories() &lt;= 700) return CaloricLevel.NORMAL; else return CaloricLevel.FAT; }, toCollection(HashSet::new) ))); 分区它是分组的特殊情况：由一个谓词（返回布尔值的函数）作为分类函数，称为分区函数。 12345Map&lt;Boolean, List&lt;Dish&gt;&gt; partitionedMenu = menu.stream() .collect(partitioningBy(Dish::isVegetarian));List&lt;Dish&gt; vegetarianDishes = partitionedMenu.get(true); 分区的好处在于保留了分区函数返回 true 或 false 的两套流元素列表。 123456Map&lt;Boolean, Dish&gt; mostCaloricPartitionedByVegetarian = menu.stream().collect( partitioningBy(Dish::isVegetarian, collectingAndThen( maxBy(comparingInt(Dish::getCalories)), Optional::get))); 可以仿造groupingBy多级分区。 收集器接口可为collector接口提供自己的实现，从而自由地创建自定义归约操作。 1234567public interface Collector&lt;T, A, R&gt; { Supplier&lt;A&gt; supplier(); BiConsumer&lt;A, T&gt; accumulator(); Function&lt;A, R&gt; finisher(); BinaryOperator&lt;A&gt; combiner(); Set&lt;Characteristics&gt; characteristics();} 并行流对顺序流调用parallel方法，并不意味着流本身有任何实际的变化。它在内部实际上就是设了一个 boolean 标志，表示你想让调用 parallel 之后进行的所有操作都并行执行。 并行流内部使用了默认的ForkJoinPool，它默认的线程数量是处理器的数量，可由Runtime.getRuntime().availableProcessors()得到。 避免共享可变状态，确保并行 Stream 得到正确的结果。 并行流无需显式地处理线程和同步问题。 自定义Spliterator因为原始的 String 在任意位置拆分，所以有时一个词会被分为两个词，然后数了两次。这就说明，拆分流会影响结果，而把顺序流换成并行流就可能使结果出错。 如何解决这个问题呢？解决方案就是要确保 String 不是在随机位置拆开的，而只能在尾拆开。要做到这一点，你必须为 Character 实现一个 Spliterator ，它只能在两个词之间拆开String （如下所示），然后由此创建并行流。 Optional替代Null如何为缺失的对象建模？Optional：当变量存在时，Optional类只是对类的简单封装。当变量不存在时，缺失的值被建模成一个“空”的Optional对象，由方法Optional.empty返回。 Optional.empty() 方法是一个静态工厂方法，它返回 Optional 类的特定单一实例。 Optional.empty()用处： 应用Optional创建Optional对象： 声明一个空的Optional Optional&lt;Car&gt; optCar= Optional.empty(); 依据一个非空值创建Optional Optional&lt;Car&gt; optCar = Optional.of(car); 若car是null，抛出NPE。 可接受null的Optional Optional&lt;Car&gt; optCar = Optional.ofNullable(car); Optional提供的get方法在遭遇空的Optional对象时，也会抛出异常。 怎么办？ 使用map从Optional对象中提取和转换值123456public String getCarInsuranceName(Optional&lt;Person&gt; person) { return person.flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse(\"Unknown\"); // Optional为空时，设置默认值} 由于 Optional 类设计时就没特别考虑将其作为类的字段使用，所以它也并未实现Serializable 接口。 若要实现序列化的域模型，作为替代方案，提供一个能访问声明为 Optional 、变量值可能缺失的接口。 123456public class Person { private Car car; public Optional&lt;Car&gt; getCarAsOptional() { return Optional.ofNullable(car); }} CompleptableFuture:组合式异步编程Future接口它设计初衷是为将来某个时刻会发生的结果进行建模。 这种编程方式让你的线程可以在 ExecutorService 以并发方式调用另一个线程执行耗时操作的同时，去执行一些其他的任务。接着，如果你已经运行到没有异步操作的结果就无法继续任何有意义的工作时，可以调用它的 get 方法去获取操作的结果。如果操作已经完成，该方法会立刻返回操作的结果，否则它会阻塞你的线程，直到操作完成，返回相应的结果。 Future 接口的局限性：很难表述 Future 结果之间的依赖性。 于是CompletableFuture，CompletableFuture 和 Future 的关系就跟 Stream 和 Collection 的关系一样。 使用 CompletableFuture 构建异步应用12345678910public Future&lt;Double&gt; getPriceAsync(String product) { CompletableFuture&lt;Double&gt; futurePrice = new CompletableFuture&lt;&gt;(); new Thread( () -&gt; { double price = calculatePrice(product); futurePrice.complete(price); }).start(); // 无需等待尚未结束的计算，直接返回Future对象 return futurePrice;} 使用工厂方法 supplyAsync 创建 CompletableFuture123public Future&lt;Double&gt; getPriceAsync(String product) { return CompletableFuture.supplyAsync(() -&gt; calculatePrice(product));} supplyAsync 方法接受一个生产者（ Supplier ）作为参数，返回一个CompletableFuture对象，该对象完成异步执行后会读取调用生产者方法的返回值。 生产者方法会交由 ForkJoinPool池中的某个执行线程（ Executor ）运行，但是你也可以使用 supplyAsync 方法的重载版本，传递第二个参数指定不同的执行线程执行生产者方法。一般而言，向 CompletableFuture 的工厂方法传递可选参数，指定生产者方法的执行线程是可行的。 使用 CompletableFuture 发起异步请求 这里使用两个不同的Stream流水线的原因是：流操作之间存在延迟。如果在单一的流水线中处理流，发向不同商家的请求只能以同步、顺序执行的方式才会成功。 寻找更好的方案 当任务数超过四个时，定制执行器。 N(threads) = N(CPU) U(CPU) (1 + W/C)其中： N CPU 是处理器的核的数目，可以通过 Runtime.getRuntime().availableProce-ssors() 得到 U CPU 是期望的CPU利用率（该值应该介于0和1之间） W/C是等待时间与计算时间的比率 123456789private final Executor executor = Executors.newFixedThreadPool(Math.min(shops.size(), 100), new ThreadFactory() { public Thread newThread(Runnable r) { Thread t = new Thread(r); t.setDaemon(true); return t; } }); Java程序无法终止或者退出一个正在运行中的线程，所以最后剩下的那个线程会由于一直等待无法发生的事件而引发问题。与此相反，如果将线程标记为守护进程，意味着程序退出时它也会被回收。这二者之间没有性能上的差异。 并行——使用流还是 CompletableFutures ？ 如果进行的是计算密集型的操作，并且没有IO，推荐使用Stream接口，因为实现简单，同时效率也可能是最高的（如果所有线程都是计算密集型，根据以上估算公式，就没有必要创建比处理器核数更多的线程）。 反之，如果你并行的工作单元还涉及等待I/O的操作（包括网络连接等待），那么使用CompletableFuture 灵活性更好，你可以像前文讨论的那样，依据等待/计算，或者W/C的比率设定需要使用的线程数。这种情况不使用并行流的另一个原因是，处理流的流水线中如果发生I/O等待，流的延迟特性会让我们很难判断到底什么时候触发了等待。 对多个异步任务进行流水线操作123456789101112131415public List&lt;String&gt; findDiscountFuture(String product) { List&lt;CompletableFuture&lt;String&gt;&gt; futureList = shops.stream() .map(shop -&gt; CompletableFuture.supplyAsync( () -&gt; shop.getName() + \" price is \" + shop.getPrice(product),executor)) .map(future -&gt; future.thenApply(Quote::parse)) .map(future -&gt; future.thenCompose(quote -&gt; CompletableFuture.supplyAsync( () -&gt; Discount.applyDiscount(quote), executor))) .collect(toList()); return futureList.stream() .map(CompletableFuture::join) .collect(toList()); } thenCompose方法允许对两个异步操作进行流水线，第一个操作完成时，将其结果作为参数传递给第二个操作。换句话说，即创建两个CompletableFuture对象调用thenCompose，并向其传递一个Function。当第一个CompletableFuture执行完毕后，它的结果结果将作为该函数的参数， 这个函数返回值是以第一个 CompletableFuture 的返回做输入计算出的第二个 CompletableFuture 对象。 thenCompose 方法像 CompletableFuture 类中的其他方法一样，也提供了一个以 Async 后缀结尾的版本 thenComposeAsync 。通常而言，名称中不带 Async的方法和它的前一个任务一样，在同一个线程中运行；而名称以 Async 结尾的方法会将后续的任务提交到一个线程池，所以每个任务是由不同的线程处理的。就这个例子而言，第二个CompletableFuture 对象的结果取决于第一个CompletableFuture ，所以无论你使用哪个版本的方法来处理 CompletableFuture 对象，对于最终的结果，或者大致的时间而言都没有多少差别。我们选择 thenCompose 方法的原因是因为它更高效一些，因为少了很多线程切换的开销。 主线程还能执行其它重要的操作，如响应UI。 另一种比较常见的情况是，你需要将两个完全不相干的 CompletableFuture 对象的结果整合起来，而且你也不希望等到第一个任务完全结束才开始第二项任务。 1234567Future&lt;Double&gt; futurePriceInUSD = CompletableFuture.supplyAsync(() -&gt; shop.getPrice(product)) .thenCombine( CompletableFuture.supplyAsync( () -&gt; exchangeService.getRate(Money.EUR, Money.USD)), (price, rate) -&gt; price * rate ); 这里thenCombine方法，它接受BiFunction作为第二个参数，这个参数定义了两个CompletableFuture 对象完成计算后，如何合并结果。它的Async版本是：导致BiFunction中定义的合并操作被提交到线程池中，由另一个任务以异步的方式执行。其中的两个CompletableFuture 对象是在不同的线程执行的。 CompletableFuture 利用Lambda表达式以声明式的API提供了一种机制，能够用最有效的方式，非常容易地将多个以同步或异步方式执行复杂操作的任务结合到一起。 响应 CompletableFuture 的 completion 事件避免的首要的问题是，等待创建一个包含了所有价格的List创建完成。应该直接处理CompletableFuture。这样每个 CompletableFuture 都在为某个商店执行必要的操作。 1234567891011121314public Stream&lt;CompletableFuture&lt;String&gt;&gt; findDiscountStream(String product) { return shops.stream() .map(shop -&gt; CompletableFuture.supplyAsync( () -&gt; shop.getName() + \" price is \" + shop.getPrice(product), executor)) .map(future -&gt; future.thenApply(Quote::parse)) .map(future -&gt; future.thenCompose(quote -&gt; CompletableFuture.supplyAsync( () -&gt; Discount.applyDiscount(quote), executor))); }findPricesStream(\"myPhone\").map(f -&gt; f.thenAccept(System.out::println)); thenAccept方法也有Async版本。异步版本会对处理结果的消费者进行调度，从线程池中选择一个新的线程继续执行，不再由同一个线程完成CompletableFuture的所有任务。 如果想避免不必要的上下文切换，避免在等待线程上浪费时间，尽快响应CompletableFuture的completion事件，可以不使用异步版本。 由于 thenAccept 方法已经定义了如何处理 CompletableFuture 返回的结果，一旦CompletableFuture 计算得到结果，它就返回一个CompletableFuture&lt;Void&gt;。 1234CompletableFuture[] futures = findPricesStream(\"myPhone\") .map(f -&gt; f.thenAccept(System.out::println)) .toArray(size -&gt; new CompletableFuture[size]);CompletableFuture.allOf(futures).join(); allOf 工厂方法接收一个由 CompletableFuture 构成的数组，数组中的所有CompletableFuture 对象执行完成之后，它返回一个CompletableFuture&lt;Void&gt; 对象。这意味着，如果你需要等待最初 Stream 中的所有 CompletableFuture 对象执行完毕，对 allOf 方法返回的CompletableFuture 执行 join 操作是个不错的主意。 然而在另一些场景中，你可能希望只要 CompletableFuture 对象数组中有任何一个执行完毕就不再等待，比如，你正在查询两个汇率服务器，任何一个返回了结果都能满足你的需求。在这种情况下，你可以使用一个类似的工厂方法 anyOf 。该方法接收一个 CompletableFuture 对象构成的数组，返回由第一个执行完毕的 CompletableFuture 对象的返回值构成的CompletableFuture&lt;Object&gt; 。 新的日期和时间API","link":"/2018/11/12/java/java8/"},{"title":"JavaReview","text":"仅限个人学习总结，不适用参考。 参考文献：《Java 核心技术（第 10 版）》 journaldev 异常逐级传递；若未找到异常处理者，终止程序，抛出异常。 Java 语言规范将派生于 Error 类或 RuntimeException 类的所有异常称为非受查异常( unchecked ) ， 所有其他的异常称为受查异常（ checked )编译器将核查是否为所有的受査异常提供了异常处理器。 断言检查只用于开发和测试阶段 创建文件三种方法 file.createNewFile();分 absolute、relative 两种；要求路径已存在，否则抛出 IOException 创建并写入数据，要求同上 1234567FileOutputStream.write(byte[] b){ String data=&quot;some data&quot;; FileOutputStream fos=new FileOutputStream(&quot;name.txt&quot;); fos.write(data.getBytes()); fos.flush(); fos.close(); } 不必担心关闭 IO 资源 123Files.write()String data=&quot;some data&quot;;Files.write(Paths.get(&quot;name.txt&quot;),data.getBytes()); 接口与回调（callback）回调：指出某事件发生时，执行的动作 内部类（inner class） 访问外部类的数据，包括私有数据 对同一包中其他类隐藏 回调函数、匿名内部类 匿名内部类：只创建类的一个对象 泛型(generic)聚集任意类型的对象 ArrayList&lt;String&gt;“String” 类型参数（type paraments）: 使程序具有更好的可读性和安全性 自定义泛型 泛型类Class Pair&lt;T&gt;“T” 类型变量 泛型方法 123static &lt;T&gt; T methodName(){ ...} 调用泛型方法绝大多数情况不用指明 T，由编译器推断 泛型类型限定(bound)123static &lt;T extends BoundType&gt; T min(){ ...} 多限定 123static &lt;T extends BoundType1 &amp; BoundType2&gt; T min(){ ...} 桥方法123456789101112131415public class Pair&lt;T&gt; { private T first; private T second; public Pair(T first, T second) { this.first = first; this.second = second; } public void setSecond(T second) { this.second = second; } ...} 类型擦除后 123456789101112131415public class Pair&lt;Object&gt; { private Object first; private Object second; public Pair(Object first, Object second) { this.first = first; this.second = second; } public void setSecond(Object second) { this.second = second; } ...} 问题 123class DateInterval extends Pair&lt;LocateDate&gt;{ public void setSecond(LocateDate second){...}} 此时有 12DateInterval.setSecond(LocateDate s)DateInterval.setSecond(Object s) 编译器在 DateInterval 生成桥方法 123public void setSecond(Object second){ setSecond((LocateDate) second);} 泛型事实： 虚拟机中没有泛型，只有普通的类和方法。 所有的类型参数都有它们的限定类型替换。（默认 Object） 桥方法被合成来保持多态。 泛型继承Pair&lt;Manager&gt;和 Pair&lt;Employee&gt;无继承关系 但泛型可以实现接口例如ArrayList&lt;T&gt; implements List&lt;T&gt; 集合基本接口：Collection Map 并发(concurrent)进程、线程。二者本质的区别在于每个进程拥有自己的一整套变量，线程则共享变量。 123Runnable r = ()-&gt;{ ...} 创建一个执行 run 方法的新线程 1Thread.start() 当线程 run 方法执行方法体中的最后一条语句后，并 return 返回或者出现没有捕获的异常时，线程终止。 产生 InterruptedException 异常: 线程被阻塞，就无法检测中断状态,产生 InterruptedException 异常 在中断状态被置位时调用 sleep 方法，它不会休眠。相反，它将清除这一状态并拋出 InterruptedException 同步如果能保证线程在失去控制之前完成任务，那么就不会出现错误。 加锁ReentrantLock 123456789101112131415class Bank{ private ReentrantLock bankLock = new ReentrantLock(); bankLock.lock(); try { System.out.print(Thread.currentThread()); accounts[from] -= amount; System.out.printf(\" %10.2f from %d to %d\", amount, from, to); accounts[to] += amount; System.out.printf(\" Total Balance: %10.2f%n\", getTotalBalance()); } finally { bankLock.unlock(); }} 假定第一个线程调用 transfer , 在执行结束前被剥夺了运行权。假定第二个线程也调用 transfer , 由于第二个线程不能获得锁，将在调用 lock 方法时被阻塞 。 它必须等待第一个线程完成 transfer 方法的执行之后才能再度被激活。当第一个线程释放锁时 ， 那么第二个线程才能开始运行 条件变量不满足条件时阻塞线程 12await()signalAll() 调用 signalAll() 不会立即激活一个等待线程。 它仅仅解除等待线程的阻塞 ，以便这些线程可以在当前线程退出同步方法之后 ， 通过竞争实现对对象的访问 总结锁和条件： 锁用来保护代码片段，任何时刻只能有一个线程执行被保护的代码 锁可以管理试图进入被保护代码段的线程 锁可以拥有一个或多个条件对象 每个条件对象管理那些已经进入被保护的代码段但还不能运行的线程 123public synchronized void method(){ ....} 等价于 123456789public void method(){ this.intrinsicLock.1ock() ; try{ ... } finally { this.intrinsicLock.unlock(); }} 忠告：如果 synchronized 关键字适合你的程序，那么请尽量使用它，这样可以减少编写的代码数量，减少出错的几率 。 何时使用同步？如果向一个变量写入值，而这个变量接下来可能会被另一个线程读取；或者，从一个变量读值，而这个值可能是之前被某一线程写入的，此时必须使用同步。 volatile为实例域的同步提供了一种免锁机制 例 12345678public boolean done;public synchronized boolean isDone(){return done;}public synchronized void setDone(done){this.done=done;}...public volatile boolean done;public boolean isDone(){return done;}public void setDone(done){this.done=done;} 多线程Timer TimerTask典型代码 123456{ TimerTask timerTask = new MyTimerTask(); Timer timer = new Timer(true); // 每隔 10s 调度一次 timer.scheduleAtFixedRate(timerTask, 0, 10 * 1000);} time.cancel() 可以终止 timer 和相关调度任务，但不干扰当前任务。 守护进程在所有用户进程终止后终止。 time.scheduleAtFixedRate() 调度时间应略大于任务线程执行时间，否则任务线程队列会越来越长。 线程池 ExecutorServiceExceutors 使用 ThreadPoolExecutor 提供了 ExecutorService 的实现。 123456ExecutorService executor = Executors.newFixedThreadPool(5);executor.execute(worker);class Worker implements Runnable{ ...} ThreadPoolExecutor更全 12ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor();poolExecutor.execute(worker); Callable &amp; FutureCallable 比 Runnable 多了返回值，Callable 使用泛型定义返回类型，Callable 并行运行，使得我们必须等待返回对象。 Callable 返回 Future，它使我们能够查询 Callable 状态，get()可得到返回值。","link":"/2018/10/16/java/java/"},{"title":"Python编程中邂逅的问题","text":"for循环12345for i in range(5): print(i) i += 1# output 1 2 3 4 5 for 循环中的 循环变量 不会被修改，此时应使用 while。 with表达式12345678910111213141516with open('output/0.txt') as f1: # 这里的f2是动态变化的 f2 = open('output/2.txt') # f2.close() print(f2.readline())print(f1.readline())# output2016-03-22 20:25:28,20001,89,NQ,396,58.00,S Traceback (most recent call last): File \"D:/0hadoop/python/pystudy/action/test.py\", line 7, in &lt;module&gt; print(f1.readline())ValueError: I/O operation on closed file. with表达式建立的上下文会自动关闭IO。 列表123l = []# return None,不应该作为参数,应该 fun(l + [\"sth\"]) l.append(\"sth\") %12# 7print(-123%10) 12// -3System.out.println(-123%10) Python IO读text data 1234567# 读整个文件为一个字符串with open('somefile.txt') as f: data=f.read() #迭代处理文件 with open('somefile.txt') as f: for line in f: 写text data，会覆盖。 12345678with open('somefile.txt') as f: f.write(text1) f.write(text2) with open('somefile.txt') as f: #输出重定向到f，覆盖 print(line1,file=f) print(line2,file=f) 追加文本文件，open(… , ‘at’) binary data such as images、sound files等等。 Infinite如果只需要一个表示无限的数，可以用： 12float('inf')float('-inf') 全局变量不要命名太简单，例如 i，j；否则容易与局部变量冲突。 LeetCode12","link":"/2018/11/20/python/problem/"},{"title":"PyReview","text":"仅限个人学习总结，不适用参考。 参考文献：《python 从入门到实践》《流畅的 python》 pycharm 导入自定义模块 把当前项目所在文件夹设为根目录即：右键文件夹 &gt; Make Directory as &gt; Sources root from folder.filename import classname stringtitle()upper()lower()rstrip() lstrip() strip()“ ‘ “正确使用单、双引号str() list 可变12list.append(elem)list.insert(pos,elem) 123del list[pos]val = list.pop() #删除列表尾元素val = list.pop(pos) 原则：删除后不用，del；删除后还用，pop list.remove(elem) # 移除首个 elem 123# 永久性,元素顺序改变list.sort() #字母序list.sort(reverse=True) 12# 临时性，元素顺序不变sorted(list) list.reverse()len(list)list[-1] #最后一个元素 12# 操作列表for elem in list: 12345# 生成数值列表range(start,end) #tuple; start ~ end-1range(start,end,step)list(range(start,end)) num**2 次方 min() max() sum() 列表解析squares = [val**2 for value in range(1,5)] 12345678910# 切片list[start:end] #start ~ end-1list[:end]list[start:] # list[-3:end]list[start:end:step] #step 步长for elem in list[:3]:list_b = list_a[:] # 复制列表 tuple 不可变ifif :elif:else: dict 键值对dict = {}dist[‘a’] = b 键不可变类型：整型、浮点型、字符串、元组值：任意类型 123456789del list['a']for key,value in list.items():for key in list.keys():for value in list.values():for key in sorted(list.keys()) input &amp; whilemessage = input(‘some hint’) #解读为字符串 age = input()age = int(age) whilefor 循环是一种遍历列表的有效方式，但在 for 循环中不应修改列表，否则将导致 Python 难以跟踪其中的元素。要在遍历列表的同时对其进行修改，可使用 while 循环。通过将 while 循环同列表和字典结合起来使用，可收集、存储并组织大量输入，供以后查看和显示。 function传递参数 位置参数 顺序不能错 关键字参数 传参时关联名称和值 默认值 使用默认值时，形参列表中必须先列出没有默认值的形参，正确解读。 传递列表function(list) 禁止函数修改列表function(list[:]) 传递任意数量的实参function(*tuple_name)生成一个名为 tuple_name 的空元组，并将所有的值都封装到该元组中 结合使用位置实参和任意数量实参如果要让函数接受不同类型的实参，必须在函数定义中将接纳任意数量实参的形参放在最后。Python 先匹配位置实参和关键字实参，再将余下的实参都收集到最后一个形参中。 使用任意数量的关键字实参1234def build_profile(first, last, **user_info):\"\"\"创建一个字典，其中包含我们知道的有关用户的一切\"\"\"user_profile = build_profile('albert', 'einstein',location='princeton',field='physics') class开头和末尾各有两个下划线，这是一种约定，旨在避免 Python 默认方法与普通方法发生名称冲突如 __init()__ 12345678910111213141516171819202122class Car(): def **init**(self, make, model, year): \"\"\"初始化描述汽车的属性\"\"\" self.make = make self.model = model self.year = year # 给属性指定默认值 self.odometer_reading = 0 def get_descriptive_name(self): \"\"\"返回整洁的描述性信息\"\"\" long_name = str(self.year) + ' ' + self.make + ' ' + self.model return long_name.title()class ElectricCar(Car): def __init__(self, make, model, year): super().__init__(make, model, year) # 新属性 self.battery = Battery() 将实例用作属性1234567891011121314class Battery(): \"\"\"一次模拟电动汽车电瓶的简单尝试\"\"\" def __init__(self, battery_size=70): self.battery_size = battery_size def describe_battery(self): \"\"\"打印一条描述电瓶容量的消息\"\"\" print(\"This car has a \" + str(self.battery_size) + \"-kWh battery.\")my_tesla = ElectricCar(\"tesla\", \"model s\", 2018)print(my_tesla.get_descriptive_name())my_tesla.battery.describe_battery() 可以以三种不同的方式修改属性的值： 直接通过实例进行修改； 通过方法进行设置； 通过方法进行递增（增加特定的值） 类名应采用驼峰命名法，即将类名中的每个单词的首字母都大写，而不使用下划线。实例名和模块名都采用小写格式，并在单词之间加上下划线。 higher-order function接受函数为参数，或者把函数作为结果返回的函数是高阶函数函数式编程的特点之一是使用高阶函数 map() map 函数返回一个可迭代对象，里面的元素是把第一个参数（一个函数）应用到第二个参数（一个可迭代对象) 123456789101112131415161718def factorial(n): return 1 if n &lt; 2 else n \\* factorial(n - 1)print(list(map(factorial, range(11))))sort(key=function)sorted(key=function)# 任何单参数函数都能作为 key 参数的值fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana']print(sorted(fruits, key=len))def reverse(word): return word[::-1]# reverse 仅作为排序条件print(sorted(fruits, key=reverse)) 最为人熟知的高阶函数有 map、filter、reduce如果想使用不定量的参数调用函数，可以编写 fn(*args, **keywords)，不用再编写apply(fn, args, kwargs) map、filter 和 reduce 的现代替代品列表推导和生成器表达式 12345list(map(factorial, range(6)))print([factorial(n) for n in range(6)])list(map(factorial, filter(lambda n: n % 2, range(6))))print([factorial(n) for n in range(6) if n % 2]) 在 Python 3 中，map 和 filter 返回生成器（一种迭代器），因此现在它们的直接替代品是生成器表达式（在 Python 2 中，这两个函数返回列表，因此最接近的替代品是列表推导） 12reduce(add, range(100))print(sum(range(100))) lambda1234567# lambda 返回函数def make_increment(n):return lambda x: x + nf = make_increment(42)print(f(1)) 12345# lambda 作参数pairs = [(1, 'one'), (2, 'two'), (3, 'three'), (4, 'four')]pairs.sort(key=lambda pair: pair[1])print(pairs) 在参数列表中最适合使用匿名函数除了作为参数传给高阶函数之外，Python 很少使用匿名函数。 closure（闭包）只有涉及嵌套函数时才有闭包问题 闭包指延伸了作用域的函数， 其中包含函数定义体中引用、但是不在定义体中定义的非全局变量。函数是不是匿名的没有关系，关键是它能访问定义体之外定义的非全局变量。 123456789def make_averager(): series = [] def averager(new_value): series.append(new_value) total = sum(series) return total / len(series) return averager 综上，闭包是一种函数，它会保留定义函数时存在的自由变量的绑定，这样调用函数时，虽然定义作用域不可用了，但是仍能使用那些绑定。 nonlocal1234567891011def make_averager(): count = 0 total = 0 def averager(new_value): nonlocal count, total count += 1 total += new_value return total / count return averager 文件和异常读文件123with open(file_name) as file_object: contents = file_object.read() print(contents) 关键字 with 在不再需要访问文件后将其关闭。 相比于原始文件，该输出末尾多了一个空行。因为 read() 到达文件末尾时返回一个空字符串，而将这个空字符串显示出来时就是一个空行。可调用 rstrip()删除。 逐行读取123with open(file_name) as file_object: for line in file_object: print(line) 每行的末尾都有一个看不见的换行符 创建一个包含文件各行内容的列表12345with open(file_name) as file_object: lines = file_object.readlines()for line in lines: print(line) 写文件123filename = 'output/program.txt'with open(filename, 'w') as file_object:file_object.write('I love programming!') 打开文件时，可指定读取模式（ ‘r’ ）、写入模式（ ‘w’ ）、附加模式（ ‘a’ ）或让你能够读取和写入文件的模式（ ‘r+’ ）‘b’: binary mode。如果你省略了模式实参，Python 将以默认的只读模式打开文件。 以写入（ ‘w’ ）模式打开文件时千万要小心，因为如果指定的文件已经存在，Python 将在返回文件对象前清空该文件。 Python 只能将字符串写入文本文件。要将数值数据存储到文本文件中，必须先使用函数 str() 将其转换为字符串格式。 要让每个字符串都单独占一行，需要在 write() 语句中包含换行符. 异常123try：except:else: 经验Python 不能直接将包含小数点的字符串'1127437398.85751' 转换为整数int(float(...))函数 float() 将字符串转换为小数，而函数 int() 丢弃小数部分 python False constants defined to be false: None and False. zero of any numeric type: 0, 0.0, 0j, Decimal(0), Fraction(0, 1) empty sequences and collections: ‘’, (), [], {}, set(), range(0) python 一些函数built-in functionenumerate(iterable, start=0)returns a tuple containing a count (from start which defaults to 0) and the values obtained from iterating over iterable 具名元组collections.namedtuple(typename,fields_name,...)namedtuple 就加入到 Python 里，用以构建只有少数属性但是没有方法的对象，比如数据库条目。前两个参数：一个是类名，另一个是类的各个字段的名字。后者可以是由数个字符串组成的可迭代对象，或者是由空格分隔开的字段名组成的字符串。 math.hypot即：sqrt(x*x + y*y) random random.choice(seq)Return a random element from the non-empty sequence seq. If seq is empty, raises IndexError. random.randint(a, b)Return a random integer N such that a &lt;= N &lt;= b. Alias for randrange(a, b+1).","link":"/2018/10/16/python/python/"},{"title":"FluentPy Note（1）","text":"python数据模型如何创建符合python风格的类？ 123456789101112131415161718Card = collections.namedtuple('Card', ['rank', 'suit'])class FrenchDeck: \"\"\"扑克牌类\"\"\" ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] 因__getitem__方法把 [ ] 操作交给self._cards列表，故FrenchDeck自动支持切片。 实现__getitem__方法，这个类就变成可迭代的；实现__len__，则可调用len() 迭代通常是隐式的，譬如一个集合类型没有实现__contains__方法，那么in运算符就会按顺序做一次迭代搜索。于是，in可用在FrenchDeck类上。 以上，通过实现__len()__和__getitem__，FrenchDeck就跟Python自有的序列数据类型一样，可以体现Python语言的核心特性（例如迭代和切片）。 如何使用特殊方法特殊方法是为被解释器调用的，在执行len(my_object)时，若my_object是自定义对象，那么解释器调用其实现的__len__ 如果是内置类型，如list、str、bytearray，CPython会抄近路…，快得多。 很多时候，特殊方法的调用是隐式的，如 for i in x -&gt; iter(x) -&gt; x.__iter__() 通常自己的代码无需直接使用特殊方法，除非有大量的元编程存在。 字符串表现形式repr()对应__repr__()，str()对应__str__() !r和!s是对应的格式符 两者的区别在于，__str__是在str()函数被使用，或是在print打印一个对象时候调用，且其返回的字符串更友好，没有引号('') 如果只想实现这两个特殊方法中的一个，__repr__是更好的选择。用为如果没有__str__，解释器会用__repr__作为替代。 自定义布尔值默认情况下，自定义类的实例总被认为是真，除非这个类对__bool__或者__len__ 有自己的实现。bool(x)调用x.__bool__()；若未定义__bool__方法，则尝试调用x.__len__()。若返回0，则为False，否则为True。 python中为False constants defined to be false: None and False. zero of any numeric type: 0, 0.0, 0j, Decimal(0), Fraction(0, 1) empty sequences and collections: '', (), [], {}, set(), range(0) python特殊方法 类别 方法名 字符串/字节序列表示形式 __repr__ __str__ __format__ __bytes__ 数值转换 __abs__ __bool__ __complex__ __int__ __float__ __hash__ __index__ 集合模拟 __len__ __getitem__ __setitem__ __delitem__ __contains__ 迭代模拟 __iter__ __reversed__ __next__ 可调用模拟 __call__ 实例创建和销毁 __new__ __init__ __del__ 属性管理 __getattr__ __getattribute__ __setattr__ __delattr__ __dir__ 属性描述符 __get__ __set__ __delete__ 小结：通过实现特殊方法，自定义数据类型可以表现得跟内置类型一样，从而让我们写出更具表达力的代码——或者说，更具 Python 风格的代码。 数据结构python序列类型 容器序列：list、tuple和collections.deque 这些序列存放不同类型的数据。 扁平序列：str、bytes、bytearray、memoryview和array.array 这些只能容纳一种类型 容器序列存放的是任意类型对象的引用，而扁平序列存放的是值。即，扁平序列其实是一段连续的内存空间。由此可见，扁平序列更加紧凑，但只能存诸如字符、字节和数值这些基础类型。 序列还能按是否被修改分类： 可变序列 list、bytearray、array.array、collections.deque和memoryview 不可变序列 tuple、str和bytes 列表推导内置函数 ord() ：返回字符的Unicode码，如ord(‘a’)返回97； 与 chr() 效果相反。 列表推导同filter和map比较 123symbols = '$¢£¥€¤'beyond_ascii = [ord(s) for s in symbols if ord(s) &gt; 127]beyond_ascii = list(filter(lambda c: c &gt; 127, map(ord, symbols))) 生成器表达式虽然也能用列表推导来初始化元组、数组和其他序列类型，但生成器是更好的选择。 因为生成器表达式遵守迭代器协议，可逐个产出元素，而不是建立一个完整的列表，节约内存。 1tuple(ord(symbol) for symbol in symbols) 元组可用作不可变的列表，还可以用于没有字段名的记录。 若将元组理解为数据记录：元组中的每个元素都存放了记录中一个字段的数据，外加这个字段的位置。 元组拆包元组拆包可应用到任何可迭代的对象上（可迭代元素拆包）。 平行赋值latitude, longitude = (33.9425, -118.408056) 还可以用*运算符把可迭代对象拆开作为函数的参数 quotient, remainder = divmod(*t)。 拆包中，_ 为占位符。 用来处理剩下的元素 ` a, b, rest = range(5)` 嵌套元组拆包 1for name, cc, pop, (latitude, longitude) in metro_areas: 具名元组1Card = collections.namedtuple('Card', ['rank', 'suit']) namedtuple构建的类的实例所消耗的内存跟元组一样，因字段名都被存在对应的类里。 这个实例跟普通的对象实例比起来也要小一些，因Python不会用__dict__来存放这些实例的属性。 具名元组的专有属性： _fields属性是一个包含这个类所有字段的元组 _make()通过接受一个可迭代对象来生成这个类的一个实例 _asdict()把具名元组以collections.OrderedDict形式返回，友好呈现数据 切片s[a:b:c]形式对s在a和b之间以c为间隔取值。c也可以为负，意味反向取值。 1234567&gt;&gt;&gt; s = 'bicycle'&gt;&gt;&gt; s[::3]'bye'&gt;&gt;&gt; s[::-1]'elcycib'&gt;&gt;&gt; s[::-2]'eccb' 可以把切片放在赋值语句左边，或把它作为del操作的对象。 对序列使用+和*123&gt;&gt;&gt; l = [1, 2, 3]&gt;&gt;&gt; l * 5[1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3] 注意在l*n语句中，当序列 l里的元素是对其他可变对象的引用时： 如 my_list= [[]]*3，此时得到的列表里包含的其实是三个引用，而这三个引用指向的是用一个列表。 序列的增量赋值+=背后的特殊方法是__iadd__（“就地加法”）。但如果一个类没有实现这个方法的话，Python会退一步调用__add__。 1a += b 如果 a 实现了__iadd__ 方法，就会调用这个方法。同时对可变序列（例如 list、bytearray 和 array.array）来说，a 会就地改动，就像调用了 a.extend(b) 一样。但是如果 a 没有实现__iadd__ 的话，a+= b 这个表达式的效果就变得跟 a = a + b 一样了：首先计算 a +b，得到一个新的对象，然后赋值给 a。 list.sort()和内置的sorted()参数：reversed 、key 可用bisect管理已排序的序列 当列表不是首选时 存放1000万个浮点数，数组（array）的效率要高得多，因数组背后存放的不是float对象，而是数字的机器翻译，也就是字节表述。 如果需要频繁对序列做先进先出的操作，deque（双端队列）的速度更快。 若检查一个元素是否出现的操作频率很高，用set更合适。 数组如果需要一个只包含数字的列表，那么 array.array 比 list 更高效。数组支持所有跟可变序列有关的操作，包括 .pop 、.insert 和 .extend。另外，数组还提供从文件读取和存入文件的更快的方法，如 .frombytes 和 .tofile。 创建数组需要指定类型码，如 b 类型码代表有符号的字符（signed char） d 代表双精度实数 h 代表短整型有符号整数 123456789101112floats = array('d', (random() for i in range(10 ** 7)))print(floats[-1])# 存with open('output/test/floats.bin', 'wb') as fp: floats.tofile(fp)floats2 = array('d')# 取with open('output/test/floats.bin', 'rb') as fp: floats2.fromfile(fp, 10 ** 7)print(floats2[-1]) 数组排序，需新建一个数组a = array.array(a.typecode, sorted(a)) memoryview是内置类，它能让用户在不复制内容的情况下操作同一个数组的不同切片。 双向队列和其他形式队列列表利用 .append 和 .pop(0) 合起来，就能模拟队列“先进先出”特点，但是删除列表的第一个元素（在第一个元素前插入元素）之类的操作很耗时，因这些操作牵扯移动列表里所有元素。 collections.deque（双向队列）是一个线程安全、可以快速从两端添加或删除元素的数据类型。 123456789101112131415161718&gt;&gt;&gt; dq = deque(range(10), maxlen=10)&gt;&gt;&gt; dqdeque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)&gt;&gt;&gt; dq.rotate(3) # 右移&gt;&gt;&gt; dqdeque([7, 8, 9, 0, 1, 2, 3, 4, 5, 6], maxlen=10)&gt;&gt;&gt; dq.rotate(-4) # 左移&gt;&gt;&gt; dqdeque([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], maxlen=10)&gt;&gt;&gt; dq.appendleft(-1)&gt;&gt;&gt; dqdeque([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)&gt;&gt;&gt; dq.extend([11, 22, 33]) &gt;&gt;&gt; dqdeque([3, 4, 5, 6, 7, 8, 9, 11, 22, 33], maxlen=10)&gt;&gt;&gt; dq.extendleft([10, 20, 30, 40]) &gt;&gt;&gt; dqdeque([40, 30, 20, 10, 3, 4, 5, 6, 7, 8], maxlen=10) 双向队列也付出了一些代价，从队列中间删除元素的操作会慢一些，因为它只对在头尾的操作进行了优化。 字典和集合泛映射类型 以上是形式化的文档，定义了最基本的接口，还可以用来跟 isinstance 做类型判断。非抽象映射类型一般直接对 dict 或是 collections.User.Dict 进行扩展。 标准库中所有的映射类型都是利用dict来实现的，因此有共同的限制，即只有可散列的数据类型才能用作这些映射里的键（值不需要可散列）。 什么是可散列的？ 如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变的。而且这个对象需要实现__hash__()，还要有__qe__()。如果两个可散列的对象是相等的，散列值一定相等。 原子不可变数据类型（str、bytes 和数值类型）都是可散列类型，frozenset 也是可散列的，因为根据其定义，frozenset 里只能容纳可散列类型。元组的话，只有当一个元组包含的所有元素都是可散列类型的情况下，它才是可散列的。 字典构造1234567&gt;&gt;&gt; a = dict(one=1, two=2, three=3)&gt;&gt;&gt; b = {'one': 1, 'two': 2, 'three': 3}&gt;&gt;&gt; c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))&gt;&gt;&gt; d = dict([('two', 2), ('one', 1), ('three', 3)])&gt;&gt;&gt; e = dict({'three': 3, 'one': 1, 'two': 2})&gt;&gt;&gt; a == b == c == d == eTrue 字典推导1country_code = {country: code for code, country in DIAL_CODES} 用setdefault处理找不到的键可以用 d.get(k, default) 来代替 d[k]，给找不到的键一个默认的返回值（这比处理 KeyError 要方便不少） 1my_dict.setdefault(key, []).append(new_value) 等价于 123if key not in my_dict: my_dict[key] = []my_dict[key].append(new_value) 映射的弹性键查询有时候为了方便起见，就算某个键在映射里不存在，我们也希望在通过这个键读取值的时候能得到一个默认值。 一个是通过 defaultdict 这个类型而不是普通的 dict，另一个是给自己定义一个 dict 的子类，然后在子类中实现 __missing__ 方法。 对于defaultdict: 如 dd = defaultdict(list)，这里将 list 指定为 default_factory，它是defaultdict用来生成默认值的实例属性，需要存放可调用对象。 这里，若dd['new_key']中键 ‘new_key’ 不存在的话，按以下处理： 调用 list() 来建立一个新列表。 把这个新列表作为值，’new-key’ 作为它的键，放到 dd 中。 返回这个列表的引用。 defaultdict 里的 default_factory 只会在__getitem__里被调用，也就是dd[k]会调用default_factory，而dd.get(k)则会返回None。 所有这一切背后的功臣其实是特殊方法 __missing__。它会在defaultdict 遇到找不到的键的时候调用 default_factory，而实际上这个特性是所有映射类型都可以选择去支持的。 特殊方法__missing__如果有一个类继承了 dict，然后这个继承类提供了__missing__方法，那么在 __getitem__ 碰到找不到的键的时候，Python 就会自动调用它，而不是抛出一个 KeyError 异常。 __missing__ 方法只会被 __getitem__ 调用（比如在表达式 d[k] 中） 字典的变种 collections.OrderedDict 这个类型添加键时会保持顺序，因此键的迭代次序总是一致的。 collections.ChainMap 该类型可容纳数个不同的映射对象，然后查找时，会当作一个整体查找，直到键被找到为止。如Python变量查找规则： 12import builtinspylookup = ChainMap(locals(), globals(), vars(builtins)) collections.Counter 这个类会给键设置一个整数计数器。更新键时会增加这个计数器，可用来计数。 不可变映射类型types 模块中引入了一个封装类名叫MappingProxyType。如果给这个类一个映射，它会返回一个只读的映射视图。虽然是个只读视图，但是它是动态的。这意味着如果对原映射做出了改动，我们通过这个视图可以观察到，但是无法通过这个视图对原映射做出修改。 集合论集合中的元素必须是可散列的，set类型本身是不可散列的，但是frozenset可以。因此可以创建一个包含不同frozenset的set。 集合中缀表达式： a | b : 并集、 a &amp; b : 交集、a - b : 差集 如：needles 的元素在 haystack 里出现的次数，两个变量都是 set 类型 1found = len(needles &amp; haystack) 以上代码可以用在任何可迭代对象上： 123found = len(set(needles) &amp; set(haystack))# 另一种写法：found = len(set(needles).intersection(haystack)) 集合字面量集合字面量 ： {…}，空集：set() 集合推导 {func(i) for i in iterable} dict与散列表由于字典使用了散列表，而散列表又必须是稀疏的，这导致它在空间上的效率低下。 用元组取代字典就能节省空间的原因有两个：其一是避免了散列表所耗费的空间，其二是无需把记录中字段的名字在每个元素里都存一遍。 set与散列表set 和 frozenset 的实现也依赖散列表，但在它们的散列表里存放的只有元素的引用（就像在字典里只存放键而没有相应的值）。在 set 加入到 Python 之前，我们都是把字典加上无意义的值当作集合来用的。 一等函数高阶函数接受函数为参数，或者把函数作为结果返回的函数是高阶函数。 可调用对象 用户定义的函数：使用 def 语句或 lambda 表达式创建。 内置函数：使用 C 语言（CPython）实现的函数，如 len 或 time.strftime。 内置方法：使用 C 语言实现的方法，如 dict.get。 方法：在类的定义体中定义的函数。 类：调用类时会运行类的__new__方法创建一个实例，然后运行__init__ 方法，初始化实例，最后把实例返回给调用方。因为 Python没有 new 运算符，所以调用类相当于调用函数。 类的实例：如果类定义了 __call__ 方法，那么它的实例可以作为函数调用。 生成器函数：使用yield关键字的函数或方法。调用生成器函数返回的是生成器对象。 callable()判断对象是否可以调用。 从定位参数到仅限关键字参数123456789101112def tag(name, *content, cls=None, **attrs): ... # 调用tag('br')tag('p','hello')tag('p','hello',id=33)tag('p','hello','world',cls='sidebar')tag(content='testing',name='img')my_tag = {'name': 'img', 'title': 'Sunset Boulevard', 'src': 'sunset.jpg', 'cls': 'framed'}tag(**my_tag) 以上 cls参数 只能通过关键字指定，它一定不会捕获未命名的定位参数。 定义函数时若想指定关键字参数，要把它们放到有 的参数后面。如果不想支持数量不定的定位参数，但想支持仅限关键字参数，在签名中放一个 ，如下： 1234def f(a,*,b): return a,bprint(f(1,b=2))(1,2) 注意，仅限关键字参数不一定要有默认值，可以像上例中 b 那样，强制必须传入实参。 内省：获取关于参数的信息与内省有关的函数对象 __defaults__属性，它的值是一个元组，保存着定位参数和关键字参数的默认值。 __kwdefaults__属性，保存仅限关键字参数默认值。 __code__属性，保存参数的名称，它的值是一个code对象的引用，自身也有很多属性。 相关模块：inspect 支持函数式编程的包operator模块为多个算术运算符提供了对应的函数，从而避免编写平凡的匿名函数。 1234from functools import reducefrom operator import muldef fact(n): return reduce(mul, range(1, n+1)) operator模块中的itemgetter、attrgetter能从序列中取出元素或读取对象属性。 123456for city in sorted(metro_data, key=itemgetter(1)): print(city)cc_name = itemgetter(1, 0)for city in metro_data: print(cc_name(city)) itemgetter使用[]运算符，因此它不仅支持序列，还支持映射和任何实现__getitem__方法的类。 attrgetter 与 itemgetter 作用类似，它创建的函数根据名称提取对象的属性。如果把多个属性名传给 attrgetter，它也会返回提取的值构成的元组。此外，如果参数名中包含 .（点号），attrgetter 会深入嵌套对象，获取指定的属性。 12345from operator import attrgettername_lat = attrgetter('name', 'coord.lat') for city in sorted(metro_areas, key=attrgetter('coord.lat')): print(name_lat(city)) functools.partial冻结参数1234567&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; triple = partial(mul, 3) &gt;&gt;&gt; triple(7) 21# 使用 partial 构建一个便利的 Unicode 规范化函数nfc = functools.partial(unicodedata.normalize, 'NFC') 使用函数实现设计模式策略模式12345678910111213141516171819202122232425262728293031class Order: # 上下文 def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion(self) return self.total() - discount promos = [func for name, func in inspect.getmembers(promotions, inspect.isfunction)]def best_promo(order): \"\"\"选择可用的最佳折扣 \"\"\" return max(promo(order) for promo in promos)# promotions.pydef fidelity_promo(order): passdef bulk_item_promo(order): pass 函数装饰器和闭包装饰器是可调用对象，其参数是另一个函数（被装饰的函数）。装饰器可能会处理被装饰的函数，然后把它返回，或者将其替换成另一个函数或可调用的对象。 1234567@decoratedef target(): print('running target()')# 等价于def target(): print('running target()')target = decorate(target) 严格来说，装饰器只是语法糖。 Python在何时执行装饰器？函数装饰器在导入模块时立即执行，而被装饰的函数只在明确调用时运行。这突出了导入时和运行时的区别。 使用装饰器改进策略模式1234567891011121314151617promos = []def promotion(promo_func): promos.append(promo_func) return promo_func@promotiondef fidelity_promo(order): # 第一个具体策略@promotiondef bulk_item_promo(order): # 第二个具体策略@promotiondef large_order_promo(order): # 第三个具体策略def best_promo(order): return max(promo(order) for promo in promos) 变量作用域规则1234567891011&gt;&gt;&gt; b = 6&gt;&gt;&gt; def f2(a):... print(a)... print(b)... b = 9...&gt;&gt;&gt; f2(3)3Traceback (most recent call last):...UnboundLocalError: local variable 'b' referenced before assignment Python不要求声明变量，但是假定在函数定义体中的变量是局部变量，参数也是。 闭包闭包是指延伸了作用域的函数，其中包含函数定义体中引用、但是不在定义体中定义的非全局变量。 综上，闭包是一种函数，它会保留定义函数时存在的自由变量的绑定。这样调用函数时，虽然定义作用域不可用了，但仍能使用那些绑定。 nonlocal声明12345678910111213141516171819202122232425def make_averager(): count = 0 total = 0 def averager(new_value): count += 1 total += new_value return total / count return averager&gt;&gt;&gt; avg = make_averager()&gt;&gt;&gt; avg(10)Traceback (most recent call last):...UnboundLocalError: local variable 'count' referenced before assignment&gt;&gt;&gt;def make_averager(): count = 0 total = 0 def averager(new_value): nonlocal count, total count += 1 total += new_value return total / count return averager 实现一个简单的装饰器装饰器的典型行为：把被装饰的函数替换成新函数，二者接受相同的参数，而且（通常）返回被装饰函数本该返回的值，同时做些额外的操作。 12345678910def clock(func): def clocked(*args): t0 = time.perf_counter() result = func(*args) elapsed = time.perf_counter() - t0 name = func.__name__ arg_str = ', '.join(repr(arg) for arg in args) print('[%0.8fs] %s(%s) -&gt; %r' % (elapsed, name, arg_str, result)) return result return clocked 以上实现的装饰器有缺点：遮盖了被装饰函数的__name__和__doc__属性。 可使用functools.wraps 装饰器把相关的属性从 func 复制到 clocked 中。 123456789101112131415161718def clock(func): @functools.wraps(func) def clocked(*args, **kwargs): t0 = time.time() result = func(*args, **kwargs) elapsed = time.time() - t0 name = func.__name__ arg_lst = [] if args: arg_lst.append(', '.join(repr(arg) for arg in args)) if kwargs: pairs = ['%s=%r' % (k, w) for k, w in sorted(kwargs.items())] arg_lst.append(', '.join(pairs)) arg_str = ', '.join(arg_lst) print('[%0.8fs] %s(%s) -&gt; %r ' % (elapsed, name, arg_str, result)) return result # 返回一个被装饰过的函数 return clocked Python 内置了三个用于装饰方法的函数：property、classmethod 和staticmethod。 另一个常见的装饰器是 functools.wraps，它的作用是协助构建行为良好的装饰器。标准库中最值得关注的两个装饰器是 lru_cache 和全新的 singledispatch。 functools.lru_cache做备忘123456789101112131415@functools.lru_cache() @clock def fibonacci(n): if n &lt; 2: return n return fibonacci(n-2) + fibonacci(n-1)$ python3 fibo_demo_lru.py[0.00000119s] fibonacci(0) -&gt; 0[0.00000119s] fibonacci(1) -&gt; 1[0.00010800s] fibonacci(2) -&gt; 1[0.00000787s] fibonacci(3) -&gt; 2[0.00016093s] fibonacci(4) -&gt; 3[0.00001216s] fibonacci(5) -&gt; 5[0.00025296s] fibonacci(6) -&gt; 8 functools.singledispatch 装饰器它可以把整体方案拆分成多个模块，甚至可以为你无法修改的类提供专门的函数。使用@singledispatch装饰的普通函数会变成泛函数（generic function）：根据第一个参数的类型，以不同方式执行相同操作的一组函数。 123456789101112131415161718192021# @singledispatch标记处理object类型的基函数@singledispatch def htmlize(obj): content = html.escape(repr(obj)) return '&lt;pre&gt;{}&lt;/pre&gt;'.format(content)@htmlize.register(str) def _(text): content = html.escape(text).replace('\\n', '&lt;br&gt;\\n') return '&lt;p&gt;{0}&lt;/p&gt;'.format(content)@htmlize.register(numbers.Integral) def _(n): return '&lt;pre&gt;{0} (0x{0:x})&lt;/pre&gt;'.format(n)# 叠放多个register装饰器，让同一个函数支持不同类型@htmlize.register(tuple) @htmlize.register(abc.MutableSequence)def _(seq): inner = '&lt;/li&gt;\\n&lt;li&gt;'.join(htmlize(item) for item in seq) return '&lt;ul&gt;\\n&lt;li&gt;' + inner + '&lt;/li&gt;\\n&lt;/ul&gt;' 以上各个专门函数使用@base_function.register(type)装饰。专门函数的名称无关紧要；使用 _ 简单明了。 只要可能，注册的专门函数应该处理抽象基类（如 numbers.Integral和 abc.MutableSequence），不要处理具体实现（如 int 和list）。这样，代码支持的兼容类型更广泛。 参数化装饰器怎么让装饰器接受其他参数？ 创建一个装饰器工厂函数，返回装饰器。 123456789101112registry = set()def register(active=True): def decorate(func): print('running register(active=%s)-&gt;decorate(%s)' % (active, func)) if active: registry.add(func) else: registry.discard(func) return func return decorate 对象引用、可变性和垃圾回收== 运算符比较两个对象的值（对象中保存的数据），而 is 比较对象的标识。 元组的相对不可变性元组与多数Python容器（列表、字典、集）一样，保存的是对象的引用。元组的不可变性其实是指tuple数据结构的物理内容（即保存的引用）不可变，与引用的对象无关。 元组的相对不变性也是，有些元组不可散列的原因。 默认做浅复制复制列表（或多数内置的可变集合）最简单的方式是使用内置类型的构造方法。 12345678&gt;&gt;&gt; l1 = [3, [55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 = list(l1) &gt;&gt;&gt; l2[3, [55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 == l1 True&gt;&gt;&gt; l2 is l1 False 以上看出，二者指代不同的对象。对列表和其他可变序列来说，还能使用简洁的l2=l1[:]语句来创建副本。 然而，构造方法或[:]做的是浅复制（即复制了最外层的容器，副本中的元素是源容器中元素的引用）。如果所有的元素都是不可变的，那么这样没问题。但是，如果有可变元素，可能就会导致意想不到的问题。 12345678910111213&gt;&gt;&gt; import copy&gt;&gt;&gt; bus1 = Bus(['Alice', 'Bill', 'Claire', 'David'])&gt;&gt;&gt; bus2 = copy.copy(bus1)&gt;&gt;&gt; bus3 = copy.deepcopy(bus1)&gt;&gt;&gt; id(bus1), id(bus2), id(bus3)(4301498296, 4301499416, 4301499752) ➊&gt;&gt;&gt; bus1.drop('Bill')&gt;&gt;&gt; bus2.passengers['Alice', 'Claire', 'David'] ➋&gt;&gt;&gt; id(bus1.passengers), id(bus2.passengers), id(bus3.passengers)(4302658568, 4302658568, 4302657800) ➌&gt;&gt;&gt; bus3.passengers['Alice', 'Bill', 'Claire', 'David'] ➍ 浅复制，不同引用，同一个对象；深复制，不同引用，不同对象。 函数的参数作为引用时Python 唯一支持的参数传递模式是共享传参。共享传参指函数的各个形式参数获得实参中各个引用的副本。也就是说，函数内部的形参是实参的别名。 Java 的引用类型是这样，基本类型按值传参（函数得到参数的副本）。 函数可能会修改接收到的任何可变对象 12345678910111213141516171819202122&gt;&gt;&gt; def f(a, b):... a += b... return a...&gt;&gt;&gt; x = 1&gt;&gt;&gt; y = 2&gt;&gt;&gt; f(x, y)3&gt;&gt;&gt; x, y (1, 2)&gt;&gt;&gt; a = [1, 2]&gt;&gt;&gt; b = [3, 4]&gt;&gt;&gt; f(a, b)[1, 2, 3, 4]&gt;&gt;&gt; a, b ([1, 2, 3, 4], [3, 4])&gt;&gt;&gt; t = (10, 20)&gt;&gt;&gt; u = (30, 40)&gt;&gt;&gt; f(t, u)(10, 20, 30, 40)&gt;&gt;&gt; t, u ((10, 20), (30, 40)) 防御可变参数不要使用可变类型作为参数的默认值。 del和垃圾回收del 语句删除名称，而不是对象。del 命令可能会导致对象被当作垃圾回收，但是仅当删除的变量保存的是对象的最后一个引用，或者无法得到对象时。 重新绑定也可能会导致对象的引用数量归零，导致对象被销毁。 符合Python风格的对象因Python数据模型，自定义类型行为可以像内置类型那样自然。实现如此自然的行为，靠的不是继承，而是鸭子类型（会叫即鸭子）：只需按照预定行为实现对象所需的方法（一般特殊方法）即可。 classmethod与staticmethodclassmethod定义操作类，而不是操作实例的方法。classmethod中第一个参数始终是类本身。classmethod最常用的用途是定义备选构造方法。staticmethod就是普通函数，只是碰巧在类的定义中。 格式化显示'{0.mass:5.3e}' 这样的格式字符串其实包含两部分，冒号左边的 ‘0.mass’ 在代换字段句法中是字段名，冒号后面的 ‘5.3e’ 是格式说明符 str.format() 格式说明符使用的表示法是格式规范化微语言（formatspec）。 New in Python3.6 f-string 真正的运行时计算；双引号 !r 调用 repr()、!s调用 str()、!a调用ascii() Python的私有属性和“受保护的”属性为避免子类意外覆盖“私有”属性，以形如__mode的形式（两个前导下划线）命名实例属性，Python会把属性名存入实例的__dict__属性中，而且会在前面加一个下划线和类名，因此有_Class__mode和_Subclass__mode。 有些Python程序员约定使用一个下划线前缀编写“受保护”的属性（如 self._x）。 默认情况下，各个实例在名为__dict__的特殊属性中存储实例属性。 __slots__类属性，让解释器在元组中储存实例属性，而不是用字典。这样节省大量内存。在类中定义__slots__ 属性的目的是告诉解释器：“这个类中的所有实例属性都在这儿了！” 仅当权衡当下的需求并仔细搜集资料后证明确实有必要时，才应该使用__slots__ 属性。 覆盖类属性Python中：类属性可用于为实例属性提供默认值。 为不存在的实例属性赋值，会创建新的实例属性。为实例属性赋值后，同名的类属性不受影响。然而自此之后，self.objattr读取的是实例属性objattr，也就把类属性覆盖了。 在 Python中，我们可以先使用公开属性，然后等需要时再变成特性。 序列的修改、散列、切片序列类型的构造方法应该接受可迭代的对象为参数，因为所有内置的序列类型就是这样做的。 切片原理Python如何把seq[1:3]句法变成传给seq.__getitem__(...)的参数。 123456789101112131415&gt;&gt;&gt; class MySeq:... def __getitem__(self, index):... return index ...&gt;&gt;&gt; s = MySeq()&gt;&gt;&gt; s[1] 1&gt;&gt;&gt; s[1:4] slice(1, 4, None)&gt;&gt;&gt; s[1:4:2] slice(1, 4, 2)&gt;&gt;&gt; s[1:4:2, 9] (slice(1, 4, 2), 9)&gt;&gt;&gt; s[1:4:2, 7:9] (slice(1, 4, 2), slice(7, 9, None)) indices：假设有个长度为 5 的序列，例如 ‘ABCDE’： 1234&gt;&gt;&gt; slice(None, 10, 2).indices(5) # ➊(0, 5, 2)&gt;&gt;&gt; slice(-3, None, None).indices(5) # ➋(2, 5, 1) ❶ ‘ABCDE’[:10:2] 等同于 ‘ABCDE’[0:5:2]❷ ‘ABCDE’[-3:] 等同于 ‘ABCDE’[2:5:1] 当没有底层序列类型作为依靠，那么使用此方法能节省大量时间。 属性查找失败后，解释器会调用__getattr__方法。简单来说，对my_obj.x 表达式，Python 会检查 my_obj 实例有没有名为 x 的属性；如果没有，到类（my_obj.__class__）中查找；如果还没有，顺着继承树继续查找。 如果依旧找不到，调用 my_obj 所属类中定义的__getattr__ 方法，传入 self 和属性名称的字符串形式（如 ‘x’）。 zip函数zip函数用于并行迭代两个或多个可迭代对象。当一个可迭代的对象耗尽后，它不发出警告就停止。itertools.zip_longest函数的行为有所不同：使用可选的fillvalue填充缺失的值，直到最长的可迭代对象耗尽。 为了避免在for循环中手动处理索引变量，还经常使用内置的enumerate生成器函数。 抽象基类抽象基类常见用途：实现接口时作为超类使用。抽象基类如何检查具体子类是否符合接口定义？如何使用注册机制声明一个类实现了某个接口，而不进行子类化操作。最后说明如何让抽象基类自动“识别”任何符合接口的类——不进行子类化或注册。 Python 是动态语言，因此我们可以在运行时修正一些问题。 object does not support item assignment 问题：可变的序列还必须提供 __setitem__方法。 标准库中的抽象基类collections.abc中的抽象基类最常用。 自定义抽象基类抽象方法使用@abc.abstractmethod标记，而且定义体中通常只有文档字符串。”是否实现抽象方法”基类检测子类是否符合接口的依据。 声明抽象基类最简单的方法是继承abc.ABC或其他抽象基类。 声明抽象类方法 12345class MyABC(abc.ABC): @classmethod @abc.abstractmethod def an_abstract_classmethod(cls, ...): pass 与其他描述符一起使用时，abstractmethod()应放在最里层。 虚拟子类Python新编程风格：使用抽象基类明确声明接口，而且类可以子类化抽象基类或抽象基类注册（无需在继承关系中确立静态的强链接），宣称它实现了某个接口。 继承的优缺点不要子类化内置类型，自定义类应该继承collections模块中的类，例如UserDict、UserList和UserString，它们易于扩展。 运算符重载一元运算符- (__neg__) 、+ (__pos__)、 ~(__invert__) 支持一元运算符很简单，只需实现相应的特殊方法。这些特殊方法只有一个参数，self。运算符一个基本规则：始终返回一个新对象。也就是说，不能修改self，要创建并返回合适类型的新实例。","link":"/2018/11/02/python/fluentpy/"},{"title":"FluentPy Note（2）","text":"可迭代对象、迭代器和生成器迭代器模式：惰性获取数据项的方式。 所有生成器都是迭代器，因为生成器完全实现了迭代器接口。在 Python社区中，大多数时候都把迭代器和生成器视作同一概念。 生成器应用广泛，即使是内置的range()也返回类似生成器对象，如果一定要返回列表，必须明确指明（例如，list(range(100))）。 序列可以迭代的原因：iter函数。 内置的iter函数有以下作用。 检查对象是否实现了__iter__方法，如果实现了即调用，获取一个迭代器。 如果没有实现__iter__方法，但实现了__getitem__方法。Python会创建一个迭代器，尝试按顺序（从索引0开始）获取元素。 失败，抛出TypeError异常。 任何 Python 序列都可迭代的原因是，它们都实现了__getitem__ 方法。其实，标准的序列也都实现了 __iter__方法，因此你也应该这么做。之所以对 __getitem__ 方法做特殊处理，是为了向后兼容，而未来可能不会再这么做（不过，写作本书时还未弃用）。 检查对象 x 能否迭代，最准确的方法是：调用 iter(x) 函数，如果不可迭代，再处理 TypeError 异常。 实现标准的可迭代协议12345678910111213141516171819202122232425class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): return SentenceIterator(self.words) class SentenceIterator: def __init__(self, words): self.words = words self.index = 0 def __next__(self): try: word = self.words[self.index] except IndexError: raise StopIteration() self.index += 1 return word def __iter__(self): return self Python函数中有yield生成器函数，返回生成器。 生成器表达式可以理解为列表推导的惰性版本：不会迫切地构建列表，而是返回一个生成器，按需惰性生成元素。 标准库中的生成器函数按用途可分为以下几类： 过滤 映射 合并 1234567891011121314151617181920&gt;&gt;&gt; def vowel(c):... return c.lower() in 'aeiou'...&gt;&gt;&gt; list(filter(vowel, 'Aardvark'))['A', 'a', 'a']&gt;&gt;&gt; import itertools&gt;&gt;&gt; list(itertools.filterfalse(vowel, 'Aardvark'))['r', 'd', 'v', 'r', 'k']&gt;&gt;&gt; list(itertools.dropwhile(vowel, 'Aardvark'))['r', 'd', 'v', 'a', 'r', 'k']&gt;&gt;&gt; list(itertools.takewhile(vowel, 'Aardvark'))['A', 'a']&gt;&gt;&gt; list(itertools.compress('Aardvark', (1,0,1,1,0,1)))['A', 'r', 'd', 'a']&gt;&gt;&gt; list(itertools.islice('Aardvark', 4))['A', 'a', 'r', 'd']&gt;&gt;&gt; list(itertools.islice('Aardvark', 4, 7))['v', 'a', 'r']&gt;&gt;&gt; list(itertools.islice('Aardvark', 1, 7, 2))['a', 'd', 'a'] yield from 语句。这个语句的作用就是把不同的生成器结合在一起使用。 上下文管理器和 else 块with open 创建文件不创建路径。 仅当 try 块中没有异常抛出时才运行 else 块。 123456try: dangerous_call()except OSError: log('OSError...')else: after_call() with语句的目的是简化try/finally模式。 与函数和模块不同，with 块没有定义新的作用域。 多线程与协程标准库中所有执行阻塞型 I/O 操作的函数，在等待操作系统返回结果时都会释放 GIL。这意味着在 Python 语言这个层次上可以使用多线程，而 I/O 密集型 Python 程序能从中受益：一个 Python 线程等待网络响应时，阻塞型 I/O 函数会释放 GIL，再运行一个线程。 Concurrency is when two or more tasks can start, run, and complete in overlapping time periods. It doesn’t necessarily mean they’ll ever both be running at the same instant. For example, multitaskingon a single-core machine. Parallelism is when tasks literally run at the same time, e.g., on a multicore processor. 异步库依赖于低层线程（直至内核级线程），但是这些库的用户无需创建线程，也无需知道用到了基础设施中的低层线程。在应用中，我们只需确保没有阻塞的代码，事件循环会在背后处理并发。异步系统能避免用户级线程的开销，这是它能比多线程系统管理更多并发连接的主要原因。 并发：充分运用CPU资源，主要是针对线程。 Coroutines12345678910111213async def say_after(delay, what): await asyncio.sleep(delay) print(what)async def main(): print(f\"started at {time.strftime('%X')}\") await say_after(1, 'hello') await say_after(2, 'world') print(f\"finished at {time.strftime('%X')}\")asyncio.run(main()) asyncio.run(coro,*,debug=False)当前线程存在一个事件循环时，该函数不能调用。 该函数调用时新建一个事件循环并在结束时关闭循环。它应该被用作异步程序的主入口并且理想情况下，应该只调用一次。 Task Objectclass asyncio.Task(coro,*,loop=None)Task用于在事件循环中运行协程。当一个协程等待一个Future时，Task中断协程的执行并等待Future完成。当Future完成，协程恢复。 事件循环使用竞争调度：一个事件循环同一时间只运行一个任务。然而，当一任务等待Future的完成时，事件循环运行其他任务等。 asyncio.create_task(coro)把协程包装成Task并调度其执行。Task在事件循环中执行，这个循环通过get_running_loop()获得，若当前线程没有事件循环，抛出RuntimeError。 12345678910111213141516async def say_after(delay, what): await asyncio.sleep(delay) print(what)async def main(): task1 = asyncio.create_task(say_after(1, 'hello')) task2 = asyncio.create_task(say_after(2, 'world')) print(f\"started at {time.strftime('%X')}\") # 并发执行 await task1 await task2 print(f\"finished at {time.strftime('%X')}\")asyncio.run(main()) Awaitables There are three main types of awaitable objects: coroutines, Tasks, and Futures. Tasks are used to schedule coroutines concurrently. A Future is a special low-level awaitable object that represents an eventual result of an asynchronous operation. Normally there is no need to create Future objects at the application level code. coroutine asyncio.sleep(delay, result=None, *, loop=None) sleep() always suspends the current task, allowing other tasks to run. Running Tasks Concurrentlyawaitable asyncio.gather(*aws, loop=None, return_exceptions=False)并发执行aws序列中的awaitable对象。 如果aws中有协程，自动当作Task调度。 If all awaitables are completed successfully, the result is an aggregate list of returned values. The order of result values corresponds to the order of awaitables in aws. If return_exceptions is False (default), the first raised exception is immediately propagated to the task that awaits on gather(). Other awaitables in the aws sequence won’t be cancelled and will continue to run. If return_exceptions is True, exceptions are treated the same as successful results, and aggregated in the result list. If gather() is cancelled, all submitted awaitables (that have not completed yet) are also cancelled. If any Task or Future from the aws sequence is cancelled, it is treated as if it raised CancelledError – the gather() call is not cancelled in this case. This is to prevent the cancellation of one submitted Task/Future to cause other Tasks/Futures to be cancelled. 元编程使用点号访问属性时，Python解释器会调用特殊方法（__getattr__和__setattr__）计算属性。 特性：在不改变类接口的前提下，使用存取方法（即读值方法和设值方法）修改数据属性。 使用特性验证属性@property 123456789101112131415161718192021class LineItem: def __init__(self, description, weight, price): self.description = description # 这里已经使用特性的设值方法了 self.weight = weight self.price = price def subtotal(self): return self.weight * self.price @property def weight(self): # 真正的值存储在私有属性 __weight 中 return self.__weight @weight.setter def weight(self, value): if value &gt; 0: self.__weight = value else: raise ValueError('value must be &gt; 0') 被装饰的读值方法有个 .setter 属性，这个属性也是装饰器；这个装饰器把读值方法和设值方法绑定在一起。 虽然property经常被当作装饰器使用，但它其实是一个类。构造方法如下： property(fget=None, fset=None, fdel=None, doc=None) 老版Python这样用：weight = property(get_weight, set_weight) 特性会覆盖实例属性特性都是类属性，但特性管理的其实是实例属性的存取。 实例属性遮盖类的数据属性，但实例属性不会遮盖类特性。 123456class Class: data = 'the class data attr' @property def prop(self): return 'the prop value' 123456789101112131415161718192021222324252627&gt;&gt;&gt; Class.prop # 获取特性对象本身，不会运行特性读值方法&lt;property object at 0x1072b7408&gt;&gt;&gt;&gt; obj.prop # 执行特性的读值方法'the prop value'&gt;&gt;&gt; obj.prop = 'foo' # 尝试给obj设置prop实例属性，失败（这实现了只读）Traceback (most recent call last):...AttributeError: can't set attribute &gt;&gt;&gt; obj.__dict__['prop'] = 'foo'# 但是可以直接把 'prop' 存入 obj.__dict__&gt;&gt;&gt; vars(obj) # { 'data': 'bar','prop': 'foo'}&gt;&gt;&gt; obj.prop # 然而，读取 obj.prop 时仍会运行特性的读值方法。特性没被实例属# 性遮盖。 'the prop value'&gt;&gt;&gt; Class.prop = 'baz' # 覆盖 Class.prop 特性，销毁特性对象。 &gt;&gt;&gt; obj.prop # 现在，obj.prop 获取的是实例属性。 'foo' 定义特性工厂函数123456789101112131415161718192021222324def quantity(storage_name): def qty_getter(instance): return instance.__dict__[storage_name] def qty_setter(instance, value): if value &gt; 0: # storage_name确定特性数据存储在哪儿 instance.__dict__[storage_name] = value else: raise ValueError('value must be &gt; 0') return property(qty_getter, qty_setter)class ListItem: # 使用工厂函数将自定义特性weight定义为类属性 weight = quantity('weight') price = quantity('price') def __init__(self, description, weight, price): self.description = description # 这里使用特性设值方法 self.weight = weight self.price = price 影响属性处理方式的特殊属性 __class__对象所属类的引用，Python的__getattr__只在类中寻找，而不在实例中寻找。__getattr__只处理不存在的属性名。 __dict__存储对象或类的可写属性。 特殊方法 __delattr__(self, name) 只要使用 del 语句删除属性，就会调用这个方法。 __getattr__(self, name)仅当获取指定的属性失败，搜索过 obj、Class 和超类之后调用。表达式 obj.no_such_attr、getattr(obj, ‘no_such_attr’) 和hasattr(obj, ‘no_such_attr’) 可能会触发Class.__getattr__(obj, 'no_such_attr')方法，但是，仅当在obj、Class 和超类中找不到指定的属性时才会触发。 __getattribute__(self, name) 点号与 getattr 和 hasattr 内置函数会触发这个方法。尝试获取指定的属性时总会调用这个方法，不过，寻找的属性是特殊属性或特殊方法时除外。调用 __getattribute__ 方法且抛出 AttributeError异常时，才会调用 __getattr__方法。 __setattr__(self, name, value) 点号和 setattr 内置函数会触发这个方法。 属性描述符描述符是对多个属性运行相同存取逻辑的一种方法。 描述符是实现了特定协议的类，这个协议包括__get__、__set__和__delete__。其实，我们在真实的代码中见到的大多数描述符只实现了 __get__ 和__set__ 方法，还有很多只实现了其中的一个。 property 类实现了完整的描述符协议。 特性工厂函数借助函数式编程模式避免重复编写读值方法和设值方法。解决这种问题的面向对象的方法是描述符类。 12345678910111213141516171819class Quantity: #描述符类基于协议实现 def __init__(self, storage_name): self.storage_name = storage_name # 尝试为托管属性赋值（weight、price）赋值时，会调用__set__ def __set__(self, instance, value): if value &gt; 0: instance.__dict__[self.storage_name] = value else: raise ValueError('value must be &gt; 0')class LineItem: weight = Quantity('weight') price = Quantity('price') def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price 类元编程类元编程是指在运行时创建或定制类的技术。 类装饰器也是函数，不过能够审查、修改，甚至把被装饰的类替换成其他类。 导入时和运行时区别——是有效使用Python元编程的重要基础。 类装饰器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class AutoStorage: # __counter = 0 def __init__(self): \"\"\"初始化工作在类修饰器中\"\"\" # cls = self.__class__ # prefix = cls.__name__ # index = cls.__counter # self.storage_name = f\"_{prefix}#{index}\" # cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): setattr(instance, self.storage_name, value)class Validated(abc.ABC, AutoStorage): def __set__(self, instance, value): value = self.validate(instance, value) super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return vaildated value or ValueError\"\"\"class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value &lt;= 0: raise ValueError('value must be &gt; 0') return valueclass NonBlank(Validated): \"\"\"a string non-space\"\"\" def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return valuedef entity(cls): for key, attr in cls.__dict__.items(): if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = f\"_{type_name}#{key}\" return cls 1234567891011121314151617181920import model_v5 as model@model.entityclass LineItem: description = model.NonBlank() weight = model.Quantity() price = model.Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = priceif __name__ == '__main__': item1 = LineItem(\"something\", 15, 12) print(dir(item1)[:3]) print(LineItem.description.storage_name) print(item1.description) print(getattr(item1, '_NonBlank#description')) 类装饰器以较简单的方式做到以前元类去做的事情——创建类时定制类。 类装饰器有个重大缺点：只对直接依附的类有效。这意味着，被装饰的类的子类可能继承也可能不继承装饰器所做的改动，具体情况视改动的方式而定。 元类用于构建类的类。Python中，类也是对象，因此类必然是某个类的实例。默认情况下，Python类是type类的实例。也就是说，type 是大多数内置的类和用户定义的类的元类。为了避免无限回溯，type 是其自身的实例。","link":"/2018/11/02/python/fluentpy2/"},{"title":"Spark API in Depth","text":"《Spark in Action》Chapter4 个人总结： DStream &lt;- a seq of RDDs &lt;- Partitions key-value RDD = pair RDD manipulated by funtionByKey() pair RDDskey-value 模型是一种简单、通用的数据模型。 Creating利用map将RDD中数据转换成二元组（f(element), element)，即RDD-&gt;pair RDD。 原理：二元组形式的RDD会隐式转换为PairRDDFunctions的实例(Scala语法)。 Basic pair RDD functionsgetting keys and values1pRDD.keys.distinct.count() counting values per key1234pRDD.countByKey()// 求最值val (cid, purch) = transByCust.countByKey.toSeq.maxBy(_._2) looking up values for a single key1234transByCust.lookup(53)// 打印结果transByCust.lookup(53).foreach(tran =&gt; println(tran.mkString(\", \"))) using the mapValues transformation to change values in a pair RDD只改变值 123456transByCust = transByCust.mapValues(tran =&gt; { if (tran(3).toInt == 25 &amp;&amp; tran(4).toDouble &gt; 1) tran(5) = (tran(5).toDouble * 0.95).toString tran }) using the flatMapValues transformation to add values to keys此函数可以给一个键添加多个值或一起移除某个键（键的数量会增减）。 From each of the values in the return collection, a new key-value pair is created for the corresponding key. 1234567891011transByCust = transByCust.flatMapValues(tran =&gt; { if (tran(3).toInt == 81 &amp;&amp; tran(4).toDouble &gt;= 5) { val cloned = tran.clone() cloned(5) = \"0.00\" cloned(3) = \"70\" cloned(4) = \"1\" List(tran, cloned) } else { List(tran) } })s using reduceByKey transformation to merge all values of a keyfoldByKey 与 reduceByKey 类似，区别在于需要一个额外的 zeroValue 参数。 foldByKey(zeroValue: V)(func: (V, V) =&gt; V): RDD[(K, V)] 由于RDD的并行特性，zeroValues可能被多次使用。 12val amounts = transByCust.mapValues(t =&gt; t(5).toDouble)val totals = amounts.foldByKey(0)(_ + _).collect() using aggregateByKey to group all values of a keydata partition and reducing data shuffling例如，当从本地文件系统加载文件到Spark时，文件内容被分割成分片，最终被分配到集群的结点上。这些分片形成了RDD，同一结点上可能不止一个分片。每个RDD维护一个分片列表。 1println(transByProd.partitions.length) The number of RDD partitions is important because, in addition to influencing data distribution throughout the cluster, it also directly determines the number of tasks that will be running RDD transformations. If this number is too small, the cluster will be underutilized. Furthermore, memory problems could result, because working sets might get too big to fit into the memory of executors. We recommend using three to four times more partitions than there are cores in your cluster. Moderately larger values shouldn’t pose a problem, so feel free to experiment. But don’t get too crazy,because management of a large number of tasks could create a bottleneck. using Spark’s data partitioners两种：HashPartitioner、RangePartitioner。也可定制。 默认是HashPartitioner。 partitionIndex = hashCode % numberOfPartitions Understanding and avoiding unnecessary shuffling Physical movement of data between partitions is called shuffling. It occurs when data from multiple partitions needs to be combined in order to build partitions for a new RDD .When grouping elements by key，shuffling occurs. When grouping elements by key，shuffling occurs. Shuffling when explicitly(显式) changing partitioners Because changing the partitioner provokes shuffles, the safest approach,performance-wise(性能优先), is to use a default partitioner as much as possible and avoidinadvertently causing a shuffle. shuffing caused by partitions removal详细等学Spark优化再看。 Repartitioning RDDspartitionBy只有pair RDD可用，接受一个Partitioner作为参数；当此Partition与原先的不一样时，shuffle发生，重新分片。 collecting partition data with a glom transfotamtionglom(意思同 grab)，即将每个分片合成一个数组，用返回的RDD将这些数组作为元素。新RDD的数组数量等于之前的分片数量。这个过程中，partitioner被移除。 Joining, sorting, and grouping datajoin((K, (V, W))) 非空 leftOuterJoin (K, (V, Option(W))) rightOuterJoin (K, (Option(V), W)) fullOuterJoin (K, (Option(V), Option(W)) using subtract(差集)… Using accumulators and broadcast variables to communicate with Spark executors作用：维护全局状态或在任务和分片之间共享数据。 sending data to executors using broadcast variables(bv)能在集群间共享，与accumulators不同的是，其不能被执行器修改。驱动创造bv，然后执行器读取它。 当有一个大集合数据需要被绝大多数执行器使用时，应使用bv。 创建：SparkContext.broadcast(value)，读Broadcast.value。 总结 pair RDD含二元组：keys 和 values。 scala中pair RDD隐式转换为pairRDDFuctions的实例，它有专有的pair RDD操作。 countByKey返回map，含每个键出现的次数。 mapValues，只改变pair RDD的值。 flatMapValues，一个键能对应零个或多个值（键的总数增加）。 reduceByKey和foldByKey，归约同一个键的所有值到一个值，值类型不变。 aggregateByKey，聚合值，但转换值到其它类型。 Data Partition，是Spark的一种在一个集群的多个结点间分数据的机制。 The number of RDD partitions is important because, in addition to influencingdata distribution throughout the cluster, it also directly determines the numberof tasks that will be running RDD transformations. shffuling时，数据不仅被写到硬盘，而且在网络之间传输。因此，使Spark作业中的shuffle数最小化是重要的。 Every Spark job is divided into stages based on the points where shuffles occur.","link":"/2018/11/30/bigdata/SparkInDepth/"},{"title":"Spark Streaming base on Kafka","text":"实时计算 任务：计算每秒的买、卖数，买或卖总量前五的客户端及最近一小时前五的证券。 《Spark in Action》 chapter 6 Spark流处理概念图。 Spark是面向批处理的，以mini-batches来在实时计算中应用Spark的批处理特性。 以下用以Kafka作为数据源为例。 一、数据源 1、启动Kafka zookeeper-server-start .\\zookeeper.properties（Kafka依赖zookeeper） kafka-server-start .\\server.properties 2、Kafka topic kafka-topics –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic orders kafka-topics –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic metrics 以上创建orders和metrics两topic。 3、做好发送数据的准备 可以用一个脚本模拟数据发送。 1234cat orders.txt | while read line; do echo \"$line\" sleep 0.1done | kafka-console-producer.bat --broker-list $BROKER --topic orders 每隔0.1s向orders生产数据，$BROKER='localhost:9092'（9092kafka默认端口）。 1、创建StreamingContext上下文，设为ssc。本地模式。 123val conf = new SparkConf().setMaster(\"local[*]\") .setAppName(\"Orders\")val ssc = new StreamingContext(conf, Seconds(5)) 第二个参数，指定了Streaming分割输入数据和创建mini-batch的时间间隔。时间间隔暂定为5s，再详谈。 2、连接Kafka 12345678910111213val kafkaParams = Map[String, Object]( \"bootstrap.servers\" -&gt; \"localhost:9092\", \"key.deserializer\" -&gt; classOf[StringDeserializer], \"value.deserializer\" -&gt; classOf[StringDeserializer], \"group.id\" -&gt; \"group1\", \"auto.offset.reset\" -&gt; \"latest\", \"enable.auto.commit\" -&gt; (false: java.lang.Boolean))val topics = Array(\"orders\")val kafkaStream = KafkaUtils .createDirectStream[String, String](ssc, PreferBrokers, Subscribe[String, String](topics, kafkaParams)) kafka流中数据结构是key-value型。访问：.key() .value() 3、处理数据orders.txt 每行是一笔交易。Schema如下： Order timestamp —Format yyyy-mm-dd hh:MM:ssOrder ID —Serially incrementing integerClient ID —Integer randomly picked from the range 1 to 100Stock symbol —Randomly picked from a list of 80 stock symbolsNumber of stocks to be bought or sold —Random number from 1 to 1,000Price at which to buy or sell—Random number from 1 to 100Character B or S —Whether the event is an order to buy or sell 按以上构造一个case class。 case适用于Bean 编译器会添加 1、工厂方法。 2、域访问。 3、 toString, hashCode, and equals。4、copy方法。 12case class Order(time:Timestamp, orderId: Long, cliendId: Long, symbol: String, amount: Int, price: Double, buy: Boolean) 然后处理Kafka中的value()。(kafka中的key()只是标识，不是我们所需的key()，要自己构造key-value) 1val orders = kafkaStream.flatMap(....) 4、构造key-value型DStream 由于二元组DStream隐式转换成PairDStreamFunctions的实例。这样，xxxByKey，flatMapValues这些都能派上用场了。 任务一：要计算每秒的买、卖数，做法：以order.buy类型为参数，构造key-value… 1val numPerType = orders.map(o =&gt; (o.buy, 1L)).reduceByKey(_ + _) 任务二：前五… 任务一只需要当前批处理的数据，但任务二需要追踪时间和不同的mini-batches。 使用updateStateByKey方法。 12345678910val amountPerClient = orders.map(o =&gt; (o.clientId, o.amount * o.price))//累加val amountState = amountPerClient.updateStateByKey( (vals, totalOpt: Option[Double]) =&gt; { totalOpt match { case Some(total) =&gt; Some(vals.sum + total) case None =&gt; Some(vals.sum) }}) 然后提取前五客户端ID。 为了每个Batch处理间隔只写一次结果，将以上结果倍合并。 使用mapWithState 此方法是updateStateByKey的性能改善。此方法只有一个参数，即StateSpec的实例。 StateSpec的函数签名 (Time, KeyType, Option[ValueType], State[StateType]) =&gt; Option[MappedType] State对象的方法： exsits()——若状态已定义，则返回true get()——获得状态值 remove()——移除 update()——更新或设置键的状态值 123456789101112val updateAmountState = (cliendId: Long, amount: Option[Double], state: State[Double]) =&gt; { var total = amount.getOrElse(0.toDouble) if (state.exists()) total += state.get() state.update(total) //total设置为状态 Some((cliendId, total))//Option有两种类型：Some()和None}val amountState = amountPerClient.mapWithState(StateSpec .function(updateAmountState)).stateSnapshots() Without that last method, stateSnapshots , you’d get a DStream with client ID s andtheir total amounts, but only for the clients whose orders arrived during the currentmini-batch. stateSnaphots gives you a DStream with the whole state (all clients), justlike updateStateByKey. 使用window操作来处理限制时间的计算 任务三：每小时前五 这里的窗口时间是一小时，滑动时间间隔可以设为批处理时间间隔（5s），这样可以在每个批处理间隔与其它指标一起产生。 12345678//滑动时间间隔默认是mini-batch时间间隔val stocksPerWindow = orders.map(x =&gt; (x.symbol, x.amount)) .window(Minutes(60)).reduceByKey(_ + _)val top5ClList = top5Clients.repartition(1) .map(_._1.toString) .glom() //每个RDD中的partition聚合成Array .map(arr =&gt; (\"TOPCLIENTS\", arr.toList)) 以上三类：每个批处理、批处理叠加、时间限制。 5、写回kafka。 方式：Producer.send() 最佳模式：每个JVM只创建一个Producer实例（单例模式） 12345678910111213141516171819202122case class KafkaProducerWrapper(brokerList: String) { val producerProps: Properties = { val prop = new Properties() prop.put(\"bootstrap.servers\", brokerList) prop.put(\"key.serializer\", \"org.apache.kafka.common.serialization.ByteArraySerializer\") prop.put(\"value.serializer\", \"org.apache.kafka.common.serialization.ByteArraySerializer\") prop } val producer = new KafkaProducer[Array[Byte], Array[Byte]](producerProps) def send(topic: String, key: String, value: String): Unit = { producer.send(new ProducerRecord[Array[Byte], Array[Byte]](topic, key.toCharArray.map(_.toByte), value.toCharArray.map(_.toByte))) }}object KafkaProducerWrapper { var brokerList = \"\" lazy val instance = new KafkaProducerWrapper(brokerList)//首次使用时实例化} 在metrics主题下消费数据： kafka-console-consumer –bootstrap-server localhost:9092 –topic metrics –property print.key=true","link":"/2018/12/17/bigdata/SparkStreaming/"}],"tags":[{"name":"algorithm","slug":"algorithm","link":"/tags/algorithm/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"bigdata","slug":"bigdata","link":"/tags/bigdata/"}],"categories":[]}