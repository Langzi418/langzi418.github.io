{"meta":{"title":"Blog","subtitle":"Blog","description":"Personal GitPage Website","author":"Singular","url":"https://langzi418.github.io","root":"/"},"pages":[{"title":"tags","date":"2020-01-12T02:47:38.000Z","updated":"2020-01-12T02:47:58.718Z","comments":true,"path":"tags/index.html","permalink":"https://langzi418.github.io/tags/index.html","excerpt":"","text":""},{"title":"About","date":"2020-01-12T02:48:27.000Z","updated":"2020-01-12T03:49:23.358Z","comments":false,"path":"about/index.html","permalink":"https://langzi418.github.io/about/index.html","excerpt":"","text":"下面来介绍我自己 业余历史爱好者 专业程序编写者"},{"title":"categories","date":"2020-01-12T02:46:07.000Z","updated":"2020-01-12T02:46:27.563Z","comments":true,"path":"categories/index.html","permalink":"https://langzi418.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"知识点总结","slug":"java/interview","date":"2019-09-21T06:21:18.781Z","updated":"2020-02-04T02:30:21.388Z","comments":true,"path":"2019/09/21/java/interview/","link":"","permalink":"https://langzi418.github.io/2019/09/21/java/interview/","excerpt":"JAVA基础hashCode()和equals()如果两个对象equals()，那么hashCode()一定相等。（想想散列表） IOIO 阻塞、对每个连接创建一个线程处理 NIO Selector（Netty） AIO 线程池异步处理 容器HashMap关键代码 12345678Node&lt;K,V&gt;[] table;static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt;&#123; final int hash; //定位索引位置 final K key; V value; Node&lt;K,V&gt; next;&#125;","text":"JAVA基础hashCode()和equals()如果两个对象equals()，那么hashCode()一定相等。（想想散列表） IOIO 阻塞、对每个连接创建一个线程处理 NIO Selector（Netty） AIO 线程池异步处理 容器HashMap关键代码 12345678Node&lt;K,V&gt;[] table;static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt;&#123; final int hash; //定位索引位置 final K key; V value; Node&lt;K,V&gt; next;&#125; 良好的Hash算法和扩容机制是的Hash碰撞的概率减少并且哈希桶数组占用的空间少。 threshold = length*Load factor 。默认的负载因子0.75是对空间和时间效率的平衡。 HashMap中table的length必须为2的幂（若自定义initial capacity，会指定为大于它的最小2的幂），这样做是为了在取模和扩容时做优化。 为了减少冲突，HashMap定位哈希桶索引位置时，加入了高位参与运算。 HashMap中哈希算法：取key的hashCode()值、高位运算、取模运算。 Java8在扩容时的链表部分的优化，Java7是“重新计算索引+头插法”，Java8在重新计算索引时做了优化，计算快。下图中新增的比特可以认为是随机的，则在扩容时，均匀地将冲突地结点分散到新链表。 多线程时，可能在put、resize后形成环形链表。 链表元素大于等于8，链表转化为树；扩容时若链表元素小于等于6，转化为链表。红黑树的平均查找长度log(n)，链表为n/2。当n&gt;=8时，有转化为树的必要。另外，在6和8之间有7，可以有效避免树和链表的频繁转化。 Reference java8之重新认识HashMap Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析 HashMap树化的过程TREEIFY_THRESHOLD = 8 MIN_TREEIFY_CAPACITY = 64 以上两者同时满足时，才树化。 HashMap的扩容及树化过程 HashMap分析之红黑树树化过程 ConcurrentHashMap1.7 Segment extends ReentrantLock 1.8 CAS + synchronized 由于已经使用volatile保证了key、value可见性，所以在get时不需要加锁。 Collections.synchronizedMap()和ConcurrentHashMap区别https://stackoverflow.com/questions/510632/whats-the-difference-between-concurrenthashmap-and-collections-synchronizedmap 其他容器源码【死磕 Java 集合】— 总结篇 并发volatileLock前缀指令。 1）将当前处理器缓存行的数据写回到系统内存。 2）以上写回内存操作会使其他CPU里缓存了该内存地址的数据无效。 指令重排。 synchronized任何一个对象都有一个monitor与之关联，当monitor被持有后，它将处于锁定状态。 代码同步块：monitorenter时，尝试获取monitor；monitorexit时，释放monitor。 同步方法：有ACC_SYNCHRONIZED标志，进入方法获取monitor，方法结束释放monitor。 并发番@Synchronized一文通（1.8版） Java实现原子操作CAS+自旋、锁 CAS的“ABA”问题：A-&gt;B-&gt;A，那么CAS操作就会认为A没有变过，可以通过控制变量值的版本来保证CAS操作的正确性。JUC中提供了一个带有标记的原子类来解决此问题。但大多数情况下ABA问题并不会影响程序并发的正确性，所以如果需要解决ABA问题，采用传统的互斥同步可能更高效。 原子类CAS实现，AtomicInteger等可做计数器，更好的实现：LongAdder。 ThreadLocal线程封闭 ThreadLocal提供了get和set等方法，这些方法为每个使用该变量的内存都存有一份独立的副本。 ThreadLocal对象通常用于防止可变的单实例变量（Singleton）或全局变量进行共享。 关键代码 1234// ThreadLocal.javavoid createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 线程终止后，threadLocals=null。 AQS原子性地维护同步状态state（由子类重写tryAcquire、tryRelease…） 阻塞和释放线程（LockSupport） 维护阻塞线程的队列（CLH，双向链表，FIFO） 一行一行源码分析清楚AbstractQueuedSynchronizer ReentrantLock非公平锁：如果获取锁的线程再次请求，则增加state，成功。可能造成饥饿，但线程切换少，吞吐量大。 公平锁：比非公平锁增加了当前结点是否有前驱结点的判断，若有，则不成功，FIFO。线程切换多。 ReentrantReadWriteLock高16位读状态（c&gt;&gt;&gt;16)， 低16位写状态（c&amp;((1&lt;&lt;16) -1)）。 写锁：获取时，若读锁已经被获取（读状态不为0）或者当前线程不是已经获取写锁的线程，则等待。 读锁：在没有其他写线程访问时（写状态为0），读锁成功获取。 如果读锁存在，则写锁不能被获取。原因：若允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他线程就可能无法感知当前写线程的操作。（脏读） 锁降级：锁降级中读锁的获取是必要的。若当前线程不获取读锁而直接释放写锁，假如另一个线程获取写锁并更新数据，那么当前线程可能无法感知数据的更新（可见性）。 线程池execute执行command分四种情况： 如果当前运行线程小于corePoolSize，则创建新线程来执行任务。 1234567int c = ctl.get();if (workerCountOf(c) &lt; corePoolSize) &#123; // addWorker需要获取全局锁 if (addWorker(command, true)) return; c = ctl.get();&#125; 如果运行的线程大于等于corePoolSize，则将任务加入到BlockingQueue。 如果队列已满，再创建新的线程来处理任务（addWorker（command, false））。 如果创建新线程将使当前运行的线程超出maxinumPoolSize，任务将被拒绝，执行饱和策略。 在ThreadPoolExecutor完成预热后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都执行步骤2，而它不需要获取全局锁。 工作线程：线程池创建线程时，会将线程封装成Worker，Worker在执行完任务后，还会循环获取BlockingQueue中的Worker来执行。 提交任务：pool.execute(Runnable); Future\\ future = pool.submit(Runnable); 关闭线程池： shutdown和shutdownNow都会通知线程池不再接受任务，都会立即返回。 区别：showdown仅中断空闲线程，使得BlockingQueue中的线程可以被剩下的线程执行，该方法返回值为void。showdownNow中断所有线程，返回BlockingQueue中的线程列表。 ExecutorThreadPoolExecutor(corePoolsize, maxPoolSize, keepAliveTime, BlockingQueue) 当线程池中的线程数大于corePoolSize时，keepAliveTime为多余的空闲线程等待任务的最长时间，超时则线程终止。 FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列（容量Integer.MAX_VALUE）。影响： 1）线程池中的线程数达到coerPoolSize后，新任务将在无界队列中等待，所以线程池中的线程数将不会超过corePoolSize。 适用于为了满足资源管理的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。 SingleThreadExecutorLinkedBlockingQueue corePoolSize=1 适用于需要保证顺序地执行各个任务；并且在任意地时间点不会有多个线程是活动的应用场景。 CacheThreadPoolSynchronousQueue corePoolSize=0, maxPoolSize=Integer.MAX_VALUE 如果主线程提交任务的速度高于maxPool中处理任务的速度，它会不断地创建新的线程。 适用于执行很多的短期异步任务小程序，或负载较轻的服务器。 Reference 《Java并发编程实战》 《Java并发编程之美》 《Java并发编程的艺术》 内存模型Java虚拟机规范试图定义一种Java内存模型(JMM)来屏蔽各种硬件和操作系统的内存访问差异。 JMM的目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。 Java线程 工作内存 JMM 主内存 虚拟机运行时数据区域程序计数器记录正在执行的虚拟机字节码指令的地址。 Java虚拟机栈每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。 -Xss 可以指定每个线程的Java虚拟机栈内存大小 异常： 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出Stackoverflow异常； 如果虚拟机栈扩展时无法申请到足够的内存，会抛出OOM异常。 本地方法栈与Java虚拟机栈类似 Java堆几乎所有的对象实例以及数组都要在堆上分配，是垃圾收集器管理的主要区域。 从内存回收的角度来看：堆可分为新生代和老年代 从内存分配的进度来看：堆中可能划分出多个、线程私有的分配缓冲区 -Xms 可以指定堆初始值、-Xmx可以设置最大值 堆不需要物理上连续。若堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OOM异常。 方法区用于存储已经被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 垃圾收集器Serial在单CPU的环境中，serial由于没有线程交互的开销，所以能获得最高的单线程收集效率。 ParNewSerial的多线程版本。 Parallel Scavenge目标是达到一个可控制的吞吐量。这里，吞吐量=运行用户代码的时间/（运行用户代码的时间+垃圾收集的时间）。高吞吐量可以高效地利用CPU时间，尽快完成程序的计算任务，主要适合在后台计算而不需要太多交互的场景。 -XX:MaxGCPauseMills（最大垃圾收集停顿时间） -XX:GCTimeRatio（垃圾收集时间占总时间的比率） GC时间的缩短是以牺牲吞吐量的和新生代的空间来换取的：系统把新生代的空间调小。 Serial OldSerial的老年代版本。 Parallel Oldparallel scavenge的老年代版本。 CMS（Concurrent Mark Sweep）目标是获得最短的回收停顿时间。 4个步骤： 1）初始标记：只标记GC Roots能直接关联到的对象，速度很快，需要停顿； 2）并发标记：GC Roots Tracing的过程； 3）重新标记：修正并发标记期间因用户程序继续运行导致标记产生变动的那一部分对象的标记记录，停顿稍长一些； 4）并发清除。 详解CMS垃圾回收机制 G1使用大小相等的独立区域（Region）划分内存以及按优先级来回收内存。 新生代和老年代不再是物理隔离的，它们都是一部分Region（不需要连续）的集合。 内存分配与回收策略分代收集算法分为新生代和老年代。 新生代：每次垃圾收集时都发现大量的对象死亡，存活率低。可以使用复制算法进行收集，只需要使用少量的复制成本，算法简单，效率高。 老年代：对象存活率高、没有额外空间对它进行分配担保，必须使用“标记——清理”，或者“标记——整理”。 大多数情况下，对象在新生代Eden区中分配。很长的字符串以及数组直接进入老年代。 Full GC&amp;Minor GCyoung GC：当young gen中的eden区分配满的时候触发。注意young GC中有部分存活对象会晋升到old gen，所以young GC后old gen的占用量通常会有所升高。 full GC：当准备要触发一次young GC时，如果发现统计数据说之前young GC的平均晋升大小比目前old gen剩余的空间大，则不会触发young GC而是转为触发full GC（因为HotSpot VM的GC里，除了CMS的concurrent collection之外，其它能收集old gen的GC都会同时收集整个GC堆，包括young gen，所以不需要事先触发一次单独的young GC）；或者，如果有perm gen的话，要在perm gen分配空间但已经没有足够空间时，也要触发一次full GC；或者System.gc()、heap dump带GC，默认也是触发full GC。 JVM 系列文章之 Full GC 和 Minor GC 类加载Java类编译、加载、和执行机制 老大难的 Java ClassLoader 再不理解就老了 破坏双亲委派模型情形一：受到加载范围的限制，顶层加载器（Boot、Ext）无法加载到用户代码。 解决：设置线程上下文类加载器，可以在父类加载时使用这个加载器去加载所需的用户代码。 12345678// Launcher.java// 通过聚合实现双亲委派，每个ClassLoader对象内部都有一个parent属性指向它的父加载器。var1 = Launcher.ExtClassLoader.getExtClassLoader();this.loader = Launcher.AppClassLoader.getAppClassLoader(var1);// 默认将AppClassLoader设置为ContextClassLoaderThread.currentThread().setContextClassLoader(this.loader); MySQL基础where子句指定行的条件，having子句指定组的条件。 范式数据库逻辑设计之三大范式通俗理解 索引B-Tree/B+Treem阶B树和B+树的主要区别在于： 在B+树中，叶节点包含信息，所有非叶节点仅起索引作用，非叶节点中的每个索引项只含有对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址。 B+树中，叶节点包含了全部关键字，且相邻叶节点是链接起来的；而在B树中，叶节点包含的关键字和非叶节点包含的关键字不重复。 一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的时间复杂度。 数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧： 每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个节点只需一次I/O。 B-Tree/B+Tree与红黑树比较 平衡树查找操作的时间复杂度和树高 h 相关，O(h)=O(logdN)，其中 d 为每个节点的出度。 红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，查找的次数也就更多。 B+Tree与B-Tree比较 B+Tree更适合索引，原因和节点出度d有关。d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：$$dmax=floor(pagesize/(keysize+datasize+pointsize))$$由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。 MySQL索引背后的数据结构及算法原理 红黑树保证二叉查找树的平衡性代价太高。 为了保证查找树的平衡性，我们需要一些灵活性，因此可以允许树中的一个节点保存多个键——2-3查找树。 2-3树中将一个4-节点分解为一棵2-3树可能有6种情况。每个变换（分解）都会将4-节点中的中键送入到父节点中，并重构相应的链接而不必涉及树的其他部分。这种局部变换不会影响树的全局有序性和平衡性。 红黑二叉查找树背后基本思想是用标准的二叉查找树和一些额外的信息（替换3-节点）来表示2-3树。 左斜红链接表示两个2-节点连接起来构成一个3-节点，黑链接则是2-3树中的普通链接。 满足定义的红黑树与2-3树一一对应。 三种操作：左旋转、右旋转和颜色转换，这三种操作本质上是将红链接向上传递。 Reference 《算法（第四版）》 索引的适用条件联合索引多键值B+树 匹配最左列最左列相等时，才能继续往下使用索引。 《MySQL是怎样运行的：从根儿上理解MySQL》 高性能索引策略独立的列索引不能是表达式的一部分，也不能是函数的参数。 前缀索引和索引选择性选择足够长的前缀以保证较高的选择性，同时又不能太长。前缀索引应该足够长，使得前缀索引的选择性接近于索引整个列。 一般来说，可以通过计算索引的选择性来确定前缀列的长度。不过，也要考虑数据分布不均匀的情况。 前缀索引的缺点：MySQL不能使用前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描（后面介绍）。 MySQL不支持后缀索引，可通过逆序存储数据实现“后缀索引”。 多列索引在出现索引合并时，应考虑查询和表的单列索引是否合适。 给了三个查询 where分别是 a=? b=? 、b=? c=?、c=? a=?，问怎么建索引查找效率高。 索引列的顺序经验法则：把选择性最高的放在前列。 聚簇索引是一种数据存储方式。InnoDB中聚簇索引是在同一个结构中保存了索引和数据行。InnoDB通过主键聚簇数据。 二级索引保存主键值。 覆盖索引一个索引包含（覆盖）所需要查询的字段的值。 对于InnoDB，如果二级索引保存的主键值能够覆盖查询，则可以避免对主键索引的二次查询。 事务ACID原子性 不可分割，要么全部成功提交，要么全部失败回滚。 一致性 数据库总是从一个一致性状态转换到另一个一致性状态（典型例子：转账时资金的增减）。 隔离性 通常来说，一个事务的修改在最终提交之前，对于其他事物是不可见的。 持久性 一旦事务提交，其所做的修改被永久保存在数据库中。 ACID实现Mysql中事务ACID实现原理 隔离级别Read Uncommit（未提交读） 在事务未提交前，其他事务就可以读。事务可以读取未提交的数据，即脏读。在实际过程中很少使用。 Read Commint（提交读） 事务从开始直到提交之前，所做的修改对其他事务都是不可见的。可以解决脏读。但是，不可重复读。 Repeatable Read（可重复读） 该级别保证同一个事务多次读取同样记录的结果是一致的。但可能出现幻读，即某个事务在读取某个范围类的记录时，另外一个事务又在该范围内插入新的记录。 MySQL在REPEATABLE READ隔离级别下，是可以禁止幻读问题的发生的 MySQL默认。 Serializable（可串行化） 在读取的每一行加锁，所以可能导致大量的超时和锁争用的问题。实际也很少使用。 MVCC版本链对于InnoDB的存储引擎，它的聚簇索引中都包含了两个必要的隐藏列： trx_id：事务对记录进行修改时，会将事务的id赋值给trx_id。 roll_pointer：事务对记录进行修改时，会将旧版本写入undo日志中，然后这个隐藏列指向undo日志。 随着更新次数的增多，所有的版本都会被roll_pointer属性连接成一个链表，我们把这个链表称之为版本链，版本链的头节点就是当前记录最新的值。 ReadView对于使用READ COMMITTED和REPEATABLE READ隔离级别的事务来说，核心问题就是：需要判断一下版本链中的哪个版本是当前事务可见的。 ReadView中有四个重要内容： m_ids：表示在生成ReadView时，当前系统中活跃的读写事务的id列表。 min_trx_id：m_ids最小值。 max_trx_id：表示在生成ReadView时，应该分配给下一个事务的id值。 creator_trx_id：表示生成该ReadView的事务的id。 只有在对表中的记录做改动时（执行INSERT、DELETE、UPDATE这些语句时）才会为事务分配事务id，否则在一个只读事务中的事务id值都默认为0。 有了这个ReadView，这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见： trx_id = creator_trx_id 被访问版本的trx_id &lt; min_trx_id，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。 被访问版本的trx_id &gt; max_trx_id，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。 被访问版本的trx_id属性值在min_trx_id和max_trx_id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。 MVCC指的就是在使用READ COMMITTD、REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ这两个隔离级别的一个很大不同就是：生成ReadView的时机不同，READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。 并发方案方案一：读操作利用多版本并发控制（MVCC），写操作进行加锁。 方案二：读、写操作都采用加锁的方式。 如果我们的一些业务场景不允许读取记录的旧版本，而是每次都必须去读取记录的最新版本，比方在银行存款的事务中。 采用MVCC方式的话，读-写操作彼此并不冲突，性能更高，采用加锁方式的话，读-写操作彼此需要排队执行，影响性能。 锁共享锁（S锁） 排他锁（X锁） 锁的粒度表级锁、 行级锁 什么场景加表锁 全表更新。事务需要更新大部分数据，且表较大。若使用行锁，会导致事务执行效率低，从而可能造成其他事务长时间锁等待和更多的锁冲突。 多表查询。事务涉及多个表，比较复杂的关联查询，很可能引起死锁，造成大量事务回滚。这种情况若能一次性锁定事务涉及的表，从而可以避免死锁、减少数据库因事务回滚带来的开销。 意向锁 意向共享锁，英文名：Intention Shared Lock，简称IS锁。当事务准备在某条记录上加S锁时，需要先在表级别加一个IS锁。 意向独占锁，英文名：Intention Exclusive Lock，简称IX锁。当事务准备在某条记录上加X锁时，需要先在表级别加一个IX锁。 IS、IX锁是表级锁，它们的提出仅仅为了在之后加表级别的S锁和X锁时可以快速判断表中的记录是否被上锁，以避免用遍历的方式来查看表中有没有上锁的记录，也就是说其实IS锁和IX锁是兼容的，IX锁和IX锁是兼容的。 InnoDB中具体的行锁形式Record Lock：单个记录 GAP：间隙锁（看SQL语句），解决幻读 Next-Key：Record + GAP insert时的加锁我们前边说一个事务在执行INSERT操作时，如果即将插入的间隙已经被其他事务加了gap锁，那么本次INSERT操作会阻塞，并且当前事务会在该间隙上加一个插入意向锁，否则一般情况下INSERT操作是不加锁的。 别的事务在对这条记录加S锁或者X锁时，由于隐式锁的存在，会先帮助当前事务生成一个锁结构，然后自己再生成一个锁结构后进入等待状态。 Reference 《MySQL是怎样运行的：从根儿上理解MySQL》 Innodb中的事务隔离级别和锁的关系 全面了解mysql锁机制（InnoDB）与问题排查 解决死锁之路 - 常见 SQL 语句的加锁分析 存储引擎InnoDB和MyISAM区别 是否支持行级锁：MyISAM只有表级锁，而InnoDB支持行级锁和表级锁，默认行级锁。 是否支持事务和崩溃后的安全恢复：MyISAM不支持事务，InnoDB支持事务，崩溃恢复能力好。 是否支持外键：MyISAM不支持，InnoDB支持。 是否支持MVCC：仅InnoDB支持。 复制MySQL主从复制的过程概述 在主库上把数据更改记录到二进制日志（binlog）中（这些记录被称为二进制事件）。 备库将主库上的日志复制到自己的中继日志（relay log）中。 备库读取中继日志中的事件，将其重放到备库数据之上。 基于行和基于语句的复制。 MySQL半同步复制 Redis数据类型https://redis.io/topics/data-types 数据结构 string：类似于Java的ArrayList，采用预分配冗余空间来减少内存的频繁分配。 list：将多个ziplist使用双向指针串起来使用。 hash：类似于Java的HashMap数组加链表，特别之处是渐进式rehash()。 set：类似于Java的HashSet。 zset：一个hash字典加一个跳跃列表。 面试官：你看过Redis数据结构底层实现吗？ 深入了解Redis底层数据结构 Spring15个经典的Spring面试常见问题 Javadoop Spring Boot自动配置的”魔法”是如何实现的？ Spring学习（二十二） Bean配置的三种方式（XML、注解、Java类）介绍与对比 网络https://github.com/wolverinn/Waking-Up/ HTTPhttps://mp.weixin.qq.com/s/KH_Edj1F0FJ9fzEB4aQgew HTTPsHTTPS详解 操作系统孤儿进程与僵尸进程总结 select、poll、epoll之间的区别(搜狗面试) 分布式分布式数据库在「不可靠」硬件上，分布式数据库如何保证数据可靠性和服务可用性？ 负载均衡分布式架构实践——负载均衡","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://langzi418.github.io/tags/java/"}]},{"title":"Algorithm Note","slug":"algorithm/algorithm","date":"2019-08-21T11:09:43.000Z","updated":"2020-02-04T07:39:47.560Z","comments":true,"path":"2019/08/21/algorithm/algorithm/","link":"","permalink":"https://langzi418.github.io/2019/08/21/algorithm/algorithm/","excerpt":"一些算法归纳： 排序快速排序1234567891011121314151617void quickSort(int[] a, int start, int end) &#123; if (start &gt;= end) return; int low = start, high = end + 1; int pivot = a[low]; while (low &lt; high) &#123; while (low &lt; high &amp;&amp; a[--high] &gt; pivot) ; a[low] = a[high]; while (low &lt; high &amp;&amp; a[++low] &lt; pivot) ; a[high] = a[low]; &#125; a[low] = pivot; quickSort(a, start, low - 1); quickSort(a, low + 1, end);&#125; 归并排序自顶向下 1234567891011121314151617181920mergeSort(int[] a,int low,int high)&#123; if(high&lt;=low) return; int mid=low+(high-low)/2; mergeSort(a,low,mid); mergeSort(a,mid+1,high); merge(a,low,mid,high);&#125;merge(int[] a,int low,int mid,int high)&#123; //归并排序需要一个辅助数组 System.arraycopy(a,low,aux,low,high-low+1); int i=low,j=mid+1; for(int k=low;k&lt;=high;k++)&#123; if(i&gt;mid) a[k]=aux[j++]; else if(j&gt;high) a[k]=aux[i++]; else if(aux[j]&lt;aux[i]) a[k]=aux[j++]; else a[k]=aux[i++]; &#125;&#125;","text":"一些算法归纳： 排序快速排序1234567891011121314151617void quickSort(int[] a, int start, int end) &#123; if (start &gt;= end) return; int low = start, high = end + 1; int pivot = a[low]; while (low &lt; high) &#123; while (low &lt; high &amp;&amp; a[--high] &gt; pivot) ; a[low] = a[high]; while (low &lt; high &amp;&amp; a[++low] &lt; pivot) ; a[high] = a[low]; &#125; a[low] = pivot; quickSort(a, start, low - 1); quickSort(a, low + 1, end);&#125; 归并排序自顶向下 1234567891011121314151617181920mergeSort(int[] a,int low,int high)&#123; if(high&lt;=low) return; int mid=low+(high-low)/2; mergeSort(a,low,mid); mergeSort(a,mid+1,high); merge(a,low,mid,high);&#125;merge(int[] a,int low,int mid,int high)&#123; //归并排序需要一个辅助数组 System.arraycopy(a,low,aux,low,high-low+1); int i=low,j=mid+1; for(int k=low;k&lt;=high;k++)&#123; if(i&gt;mid) a[k]=aux[j++]; else if(j&gt;high) a[k]=aux[i++]; else if(aux[j]&lt;aux[i]) a[k]=aux[j++]; else a[k]=aux[i++]; &#125;&#125; 自底向上 123456789mergeSort(int[] a)&#123; int N=a.length; for(int sz=2;sz&lt;N;sz=sz+sz)&#123; // 当low=N-sz ，low+sz-1=N-1，只有一个区间 for(int low=0; low&lt;N-sz; low+=sz+sz)&#123; merge(a,low,low+sz-1,min(low+sz+sz-1,N-1)); &#125; &#125;&#125; 链表归并 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748ListNode sortList(ListNode head)&#123; ListNode dummy=new ListNode(0); dummy.next=head; int N=0; while(head!=null)&#123; head=head.next; N++; &#125; for(int sz=1; sz&lt;N; sz&lt;&lt;=1)&#123; ListNode prev=dummy,cur=dummy.next; while(cur!=null)&#123; ListNode left=cur; ListNode right=split(left,sz); cur=split(right,sz); prev=merge(left,right,prev); &#125; &#125; return dummy.next;&#125;ListNode split(ListNode head, int sz)&#123; if(head==null) return null; for(int i=1; head.next!=null &amp;&amp; i&lt;sz; i++) head=head.next; ListNode right=head.next; head.next=null; return right;&#125;ListNode merge(ListNode left, ListNode right, ListNode prev)&#123; ListNode cur=pre; while(left!=null &amp;&amp; right!=null)&#123; if(left.val &lt; right.val)&#123; cur.next =left; left=left.next; &#125;else&#123; cur.next =right; right=right.next; &#125; cur=cur.next; &#125; if(left!=null) cur.next=left; else if(right!=null) cur.next=right; while(cur.next!=null) cur=cur.next; return cur;&#125; 桶排序基本思想：将数组arr分成若干个等大的子区间（桶），分别对每个桶排序，再合并。 一般可以利用 [max(arr)-min(arr)] / arr.length来划分区间。 数据最好均匀分布，使得各个桶的数据均匀。 简版：将每个子区间大小为1，统计每个子区间个数，依次输出即可。 12345678910111213141516171819202122//这里假定数据均匀分布于0.0和1.0之间void bucketSort(float[] arr) &#123; int n = arr.length; List&lt;ArrayList&lt;Float&gt;&gt; buckets = new ArrayList&lt;&gt;(n); for (int i = 0; i &lt; n; i++) &#123; buckets.add(i, new ArrayList&lt;&gt;()); &#125; for (int i = 0; i &lt; n; i++) &#123; // (int)n*arr[i] 映射到桶中 buckets.get((int) (n * arr[i])).add(arr[i]); &#125; for (int i = 0; i &lt; n; i++) &#123; Collections.Sort(buckets.get(i)); &#125; int index = 0; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt; buckets.get(i).size(); j++) arr[index++] = buckets.get(i).get(j);&#125; 搜索123456789101112131415161718192021222324252627//---- 折半查找变种 -----// 第一个大于等于targetint lowerBound(int[] arr,int target) // 可能位于arr.length处 int low=0,high=arr.length; while(low&lt;high)&#123; int mid=low+((high-low)&gt;&gt;1); // high保证了arr[high]&gt;=mid, if(arr[mid]&lt;target) low=mid+1; else high=mid; &#125; return low;&#125;// 第一个大于targetint upperBound(int[] arr,int target)&#123; int low=0,high=arr.length; while(low&lt;high)&#123; int mid=low+((high-low)&gt;&gt;1); // high保证了arr[high]&gt;mid, if(arr[mid]&lt;=target) low=mid+1; else high=mid; &#125; return low;&#125; 链表链表一类距离算法1、求共用节点。 思想 S1 + S3 + S2 = S3 + S2 + S1 1234567891011public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; ListNode pa=headA,pb=headB; while(pa!=pb)&#123; pa=pa.next; pb=pb.next; if(pa==pb) break; if(pa==null) pa=headB; if(pb==null) pb=headA; &#125; return pa;&#125; 2、求环开始时的节点。 快慢指针思想链表回文 123456789101112131415161718192021222324252627282930public boolean isPalindrome(ListNode head) &#123; ListNode fast=head, slow=head; while(fast!=null &amp;&amp; fast.next!=null)&#123; fast=fast.next.next; slow=slow.next; &#125; if(fast!=null) slow=slow.next; slow = reverse(slow); fast= head; while(slow!=null)&#123; if(fast.val != slow.val) return false; fast = fast.next; slow = slow.next; &#125; return true;&#125;// 链表逆序ListNode reverse(ListNode head)&#123; ListNode pre = null; while(head!=null)&#123; ListNode next= head.next; head.next = pre; pre = head; head = next; &#125; return pre;&#125; 回文链表链表对折栈LeetCode 155 最小栈 用一个栈实现最小栈。 123456789101112public void push(int x) &#123; if(x&lt;=min)&#123; stack.push(min); min = x; &#125; stack.push(x);&#125;public void pop() &#123; if(stack.pop() == min) min = stack.pop();&#125; 字符串去掉AAA、AABB，从左往右匹配 12345678910111213141516171819202122232425public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int n = Integer.parseInt(sc.nextLine()); while(n--&gt;0)&#123; StringBuilder sb = new StringBuilder(sc.nextLine()); for(int i=3;i&lt;=sb.length();)&#123; // AAA if(i&gt;=3 &amp;&amp;sb.charAt(i-3)==sb.charAt(i-2) &amp;&amp;sb.charAt(i-2)==sb.charAt(i-1)) &#123; sb.deleteCharAt(i-1); continue; &#125; //AABB if(i&gt;=4 &amp;&amp;sb.charAt(i-4)==sb.charAt(i-3) &amp;&amp;sb.charAt(i-2)==sb.charAt(i-1)) &#123; sb.deleteCharAt(i-1); continue; &#125; i++; &#125; System.out.println(sb.toString()); &#125;&#125; 树树的算法，除层次遍历外，一律优先考虑递归算法。 在分析递归时，画出递归树。 层次遍历12345678910floorOrder(TreeNode root)&#123; Queue queue = ...; queue.offer(root); while(!queue.isEmpty())&#123; TreeNode p=queue.poll(); print(p.value); if(p.left!=null) queue.offer(p.left); if(p.right!=null) queue.offer(p.right); &#125;&#125; 非递归遍历递归转非递归，考虑栈。 12345678910111213preOrder(TreeNode root)&#123; TreeNode p=root; while(p!=null || !stack.isEmpty())&#123; while(p!=null)&#123; print(p.val); stack.push(p); p=p.left; &#125; //当p=null时，则根和左子树都遍历完了 p=stack.pop(); p=p.right; &#125;&#125; 123456789101112131415inOrder(TreeNode root)&#123; TreeNode p=root; while(p!=null || !stack.isEmpty())&#123; while(p!=null)&#123; stack.push(p); p=p.left; &#125; // 当p=null，则已到达最左叶子节点，访问它并问其右子树； // 如果右子树不为空，则继续递归访问； // 如果右子树为空，则当前节点已访问完，那么访问其父节点，即出栈。 p=stack.pop(); print(p.val); p=p.right; &#125;&#125; 后序 12345678910111213141516171819202122postOrder(TreeNode root)&#123; while(p!=null || !stack.isEmpty())&#123; while(p!=null)&#123; stack.push(p); p=p.left; &#125; // 考虑右子树是否为空和前序及后序遍历的思想一致， // 关键在于如何访问父节点 p = stack.peek(); if(p.right==null || p.right==last)&#123; print(p.val); stack.pop(); last=p; p=null; &#125;else&#123; p=p.right; &#125; &#125; &#125; Z子形二叉树另外，二叉树的右视图与此题思想一致。 1234567891011121314151617181920212223242526public List&lt;List&lt;Integer&gt;&gt; zigzagLevelOrder(TreeNode root) &#123; queue.offer(root); int floor=1; while(!queue.isEmpty())&#123; int size=queue.size(); // 关键思想：每次循环清空队列 for(int i=0;i&lt;size;i++)&#123; TreeNode node; if((floor&amp;1)==1)&#123; node=queue.poll(); if(node.left!=null) queue.offer(node.left); if(node.right!=null) queue.offer(node.right); &#125;else&#123; node=queue.pollLast(); if(node.right!=null) queue.offerFirst(node.right); if(node.left!=null) queue.offerFirst(node.left); &#125; tmp.add(node.val); &#125; res.add(tmp); floor=1-floor; &#125; return res;&#125; 树的子结构1234567891011121314151617public boolean HasSubtree(TreeNode root1,TreeNode root2) &#123; boolean res=false; if(root1!=null &amp;&amp; root2!=null)&#123; if(root1.val==root2.val) res=have(root1,root2); if(!res) res=HasSubtree(root1.left, root2); if(!res) res=HasSubtree(root1.right, root2); &#125; return res;&#125;boolean have(TreeNode node1, TreeNode node2)&#123; if(node2==null) return true; if(node1==null) return false; if(node1.val!=node2.val) return false; return have(node1.left, node2.left)&amp;&amp; have(node1.right, node2.right);&#125; 重构二叉树已知前序和中序，重构二叉树。 12345678910111213141516TreeNode construct(int[] pre,int s1,int e1, int[] in,int s2,int e2)&#123; TreeNode root=new TreeNode(pre[s1]); for(int i=s2;i&lt;=e2;i++)&#123; if(in[i]==pre[s1])&#123; if(i!=s2) // 递归构造左子树 root.left=construct(pre,s1+1, s1+i-s2, in,s2,i-1); if(i!=e2) // 递归构造右子树 root.right=construct(pre,s1+i-s2+1,e1, in,i+1, e2); break; &#125; &#125; return root;&#125; 已知二叉树的前序和中序，直接求出后序。思想同重构二叉树。 12345678void post(String s1, String s2) &#123; if (s1.length() == 0) return; int root = s2.indexOf(s1.charAt(0)); post(s1.substring(1, root + 1), s2.substring(0, root)); post(s1.substring(root + 1), s2.substring(root + 1)); System.out.print(s1.charAt(0));&#125; 树的轮廓lintcode878 1234567891011121314151617181920212223242526272829public List&lt;Integer&gt; boundaryOfBinaryTree(TreeNode root) &#123; boundary.add(root.val); collectLeftBoundary(root.left, boundary); collectLeaves(root, boundary); collectRightBoundary(root.right, boundary); return boundary;&#125;private void collectLeftBoundary(TreeNode node, List&lt;Integer&gt; boundary) &#123; if (node == null || isLeaf(node)) return; boundary.add(node.val); collectLeftBoundary(node.left != null ? node.left : node.right, boundary);&#125;private void collectRightBoundary(TreeNode node, List&lt;Integer&gt; boundary) &#123; if (node == null || isLeaf(node)) return; collectRightBoundary(node.right != null ? node.right : node.left, boundary); boundary.add(node.val);&#125;private void collectLeaves(TreeNode node, List&lt;Integer&gt; boundary) &#123; if (node == null) return; if (isLeaf(node)) &#123; boundary.add(node.val); &#125; else &#123; collectLeaves(node.left, boundary); collectLeaves(node.right, boundary); &#125;&#125; 二叉树的宽度1234567891011dfs(root, 0, 1, new LinkedList&lt;&gt;());int dfs(TreeNode node, int d, int index, List&lt;Integer&gt; lefts)&#123; if(node==null) return 0; // the index of leftmost node if(d==lefts.size()) lefts.add(index); return Math.max(index+1-lefts.get(d), Math.max(dfs(node.left, d+1, index*2, lefts), dfs(node.right, d+1, index*2+1, lefts)));&#125; 二叉搜索树性质：中序遍历是排序的。 那么逆中序遍历呢？ 二叉树的最近公共父节点思路：从根节点递归搜索，左子树中有子节点，右子树中也有子节点，那么根节点即为最近的父节点。 图dfs和bfs LintCode 863 先通过dfs标记父节点（相当于把树转换为无向连通图），然后通过bfs找到距离目标为K的节点。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public List&lt;Integer&gt; distanceK(TreeNode root, TreeNode target, int K) &#123; dfs(root, null); LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(null); queue.add(target); Set&lt;TreeNode&gt; visited = new HashSet&lt;&gt;(); visited.add(target); visited.add(null); int dis = 0; while(!queue.isEmpty())&#123; TreeNode node = queue.poll(); if(node == null)&#123; if(dis == K)&#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(queue.size()); for(TreeNode n: queue) ans.add(n.val); return ans; &#125; queue.offer(null); dis++; &#125;else&#123; if(!visited.contains(node.left)) &#123; visited.add(node.left); queue.offer(node.left); &#125; if(!visited.contains(node.right)) &#123; visited.add(node.right); queue.offer(node.right); &#125; if(!visited.contains(parents.get(node))) &#123; visited.add(parents.get(node)); queue.offer(parents.get(node)); &#125; &#125; &#125; return new ArrayList&lt;&gt;();&#125;void dfs(TreeNode node, TreeNode parent)&#123; if(node==null) return; parents.put(node, parent); dfs(node.left, node); dfs(node.right, node);&#125; 递归回溯找到二叉树中所有路径和等于目标值的路径。 123456789101112131415void dfs(TreeNode root,int target,ArrayList&lt;Integer&gt; tmp, ArrayList&lt;ArrayList&lt;Integer&gt;&gt; res)&#123; if(root==null) return; tmp.add(root.val); target-=root.val; if(root.left==null&amp;&amp;root.right==null)&#123; if(target==0) res.add(new ArrayList&lt;&gt;(tmp)); tmp.remove(tmp.size()-1); return; &#125; dfs(root.left,target,tmp, res); dfs(root.right,target, tmp, res); tmp.remove(tmp.size()-1);&#125; 正则表达式匹配 1234567891011public boolean isMatch(String s, String p) &#123; if(p.isEmpty()) return s.isEmpty(); boolean first = (!s.isEmpty() &amp;&amp; (s.charAt(0)==p.charAt(0)|| p.charAt(0)=='.')); if(p.length()&gt;=2 &amp;&amp; p.charAt(1)=='*') return isMatch(s, p.substring(2)) || (first&amp;&amp; isMatch(s.substring(1), p)); return first &amp;&amp; isMatch(s.substring(1), p.substring(1));&#125; Leetcode 93 返回所有合理的IP地址。 滑动窗口最长无重复字符的字串 1234567891011121314151617181920212223242526272829303132// 一直滑动到set中相同字符前int lls(String s)&#123; Set&lt;Character&gt; set=new HashSet&lt;&gt;(); int i=0,j=0; int res=0; while(j&lt;s.length())&#123; if(!set.contains(s.charAt(j)))&#123; set.add(s.charAt(j++)); res=max(res, j-i); &#125;else&#123; set.remove(s.charAt(i++)); &#125; &#125; return res;&#125;//优化，使用Map索引，直接定位int lls(String s)&#123; Map&lt;Character,Integer&gt; map=new HashMap&lt;&gt;(); int i=0,j=0; int res=0; while(j&lt;s.length())&#123; if(map.contains(s.charAt(j)))&#123; //防止回头 i=max(map.get(s.charAt(j)),i); &#125; res=max(res,j-i); map.put(s.charAt(j),j+1); j++; &#125; return res;&#125; 2-PassQ1 给定一个字符串S，返回字符串中所有字符距离指定字符C 的最短距离。 A1 从左至右扫描一次，记下 dis[i]=disLeft；再从右至左扫描一次，dis[i]=min(dis[i], disRight)。 1234567891011121314151617int[] shortestToChar(String s,char c)&#123; int n=s.length(); int[] ans=new int[n]; // 在c第一次出现，将c前面的字符设置为距离c“无穷远” int pos=-n; for(int i=0;i&lt;n;i++)&#123; if(s.charAt(i)==c) pos=i; ans[i]=i-pos; &#125; for(int i=n-1;i&gt;=0;i--)&#123; if(s.charAt(i)==c) pos=i; ans[i]=min(ans[i], abs(i-pos)); &#125; return ans;&#125; Q2 有一个数组，数组中每个元素为一个分数。给每个元素分配一个值，要求： 1、每个元素分配的值至少为1； 2、若元素的分数大于相邻元素，分配的值也要大于相邻元素。求最小分配的值。 123456789101112131415161718int minValue(int[] ratings)&#123; Arrays.fill(ratings, 1); int n=ratings.length; int cnt=new int[n]; for(int i=1; i&lt;n; i++)&#123; if(ratings[i]&gt; ratings[i-1]) cnt[i]=cnt[i-1]+1; &#125; int res=cnt[n-1]; for(int i=n-1; i&gt;0; i--)&#123; if(ratings[i-1]&gt; ratings[i]) cnt[i-1]=max(cnt[i-1] ,cnt[i]+1); res+=cnt[i-1]; &#125; return res;&#125; 动态规划Max 1D Range Sumdescription：Give an integer array A containing n non-zero integers, find the max Range Sum Query(RSQ) between two indices i and j in [0…n-1]. dp[i]代表以A[i]结尾的最大范围和。 对于dp[i]：dp[i]= max(dp[i-1], 0) + A[i]. 最大范围和即dp[i]中的最大值。 12345678main(int A[])&#123; int sum=0,ans=0; for(int i=0;i&lt;A.length,i++)&#123; sum+=A[i]; ans=max(ans,sum); if(sum&lt;0) sum=0; &#125;&#125; LIS最长递增子序列。 例子 ｛-7, 10 , 9 , 2, 3 , 8, 8 , 1｝ 1）LIS[i]= max(LIS[j])+1 (j∈[0,i-1] ,A[j]&lt;A[i] ) 2）L={-7} , L={-7, 10}, L={-7, 9}… Q: 假如袋子里共有5个积木分别为 (2, 2), (2, 4), (3, 3), (2, 5), (4, 5), 则不难判断这些积木最多可以搭成4层, 因为(2, 2) &lt; (2, 4) &lt; (2, 5) &lt; (4, 5)。 1234567891011121314151617public static void main(String[] args)&#123; Arrays.sort(a, (p,q)-&gt;&#123; return p[0]!=q[0]?p[0]-q[0]:p[1]-q[1]; &#125;); int[] dp=new int[n]; int k=0; dp[k++]=a[0][1]; for(int i=1;i&lt;n;i++)&#123; if(a[i][1]&gt;=dp[k-1]) dp[k++]=a[i][1]; else&#123; int pos=upperBound(dp,0,k,a[i][1]); dp[pos]=a[i][1]; &#125; &#125; System.out.println(k);&#125; 0-1 Knapsacktop-down 123456int value(int i,int w)&#123; if(i==N || w==0) return 0; if(dp[i][w]!= -1) return dp[i][w]; if(W[i]&gt;w) return dp[i][w]= value(i+1, w）; return dp[i][w]=max(value(i+1, w), V[i]+ value(i+1, w-W[i]));&#125; bottom-up 123456789101112131415int value(int N, int W)&#123; int[][] dp=new int[N+1][W+1]; for(int i=1;i&lt;=N;i++) for(int j=1;j&lt;=W;j++) if(W[i]&gt;j) dp[i][j]=dp[i-1][j]; else dp[i][j]=max(dp[i-1][j], V[i]+dp[i-1][j-W[i]]);&#125;//可以优化，一维数组解决。int value(int N; int W)&#123; int[] dp=new int[W+1]; for(int i=1;i&lt;=N;i++) for(int j=W;j&gt;=V[i];j--) dp[j]=max(dp[j],dp[j- W[i]]);&#125; Subset Sum1）给定一个非负数整数集S，判断是否有S的非空子集之和等于给定的Sum。 top-down 123456789solve(i,sum) 表示从i开始是否有子集和等于Sum。base case:solve(n,sum)=false (sum&gt;0 &amp;&amp; i==n);solve(i,0)=true (sum==0)//若S[i]&gt;sum，则跳过S[i]if(S[i]&gt;sum) return solve(i+1,sum);solve(i,sum)=solve(i+1,sum) || solve(i+1,sum-S[i]); bottom-up 123456789101112131415//dp[i][j] 表示到前i个数中，是否有sum=j；boolean[][] dp=new boolean[n+1][sum+1];for(int i=0;i&lt;=n;i++) dp[i][0]=true;for(int i=1;i&lt;=n;i++) for(int j=1;j&lt;=sum;j++)&#123; if(j&lt;S[i]) dp[i][j]=dp[i-1][j]; else dp[i][j]=dp[i-1][j] || dp[i-1][j-S[i]]; &#125;//可以优化for(int i=1;i&lt;=n;i++) for(int j=sum;j&gt;=S[i];j--) dp[j]=dp[j] || dp[j-S[i]]; 变种1 给定一个非负数的数组，是否可以将其分成两个和相等的数组？ Q： 搜索该数组中是否有部分和等于数组和的一半。 ​ 1 用Subset Sum。 ​ 2 回溯（见下面变种2）。 变种2 给定一个非负数的数组， 是否可以将其分为 k 个和相等的数组？ Q：回溯搜索该数组，目标为 sum/k。 1234567891011121314151617boolean backtract(int start, int[] a, boolean[] visited, int k, int sum, int target)&#123; if(k==1) return true;//只剩下最后一组 if(sum&gt;target) return false; if(sum==target) return backtract(0,a,visited,k-1,0,target); for(int i=start;i&lt;n;i++)&#123; if(!visited[i])&#123; visited[i]=true; if(backtract(i+1,a,visited,k, sum+a[i], target)) return true; visited[i]=false; &#125; &#125; return false;&#125; Coin Change例子 N=2, 币种 {1,5}, V=10 1 求最少使用多少个硬币。 123change(0)=0;change(&lt;0) = INF;change(i) = min(change(i- coinValue[j])) + 1 2 求有多少种换法。 1234dp[i][0]=1;if(j&lt;coinValue[i]) dp[i][j]=dp[i-1][j];else dp[i][j] = dp[i-1][j]+dp[i][j- coinValue[i]]; K个非负数加到N例如，K=2， N=20，有21种：0+20, … , 20+0 12345678ways(n,k);ways(i,1)=1;for(int j=2;j&lt;=k;j++;) for(int i=0;i&lt;=n;i++) for(int x=0;x&lt;=i;x++) dp[i][j]+=dp[i-x][j-1]; Cutting Sticks123cut(i,i+1)=0；cut(i,j)=min(cut(i,k) + cut(k,j) + A[j]-A[i]) k∈[i+1,j) dp一般思路：State Expressions –&gt; Base Case –&gt; General Case（Top-down , Bottom-up） String Processing With DPLCS(最长公共子序列)12if(a[i]== b[j]) dp[i][j]=dp[i-1][j-1]+1;else dp[i][j]=max(dp[i-1][j], dp[i][j-1]); 另外：最长公共子串 12if(a[i]==b[j]) dp[i][j]=dp[i-1][j-1]+1;else dp[i][j]=0; Longest Palindrome(回文)搜索回文串可用“中心向两边扩散算法”。 一个变种：可删除的情况下，某字符串中最长回文串长度。 12345678dp[l][r] 表示 A[l...r] 最长回文串的长度。Base Case: if(l== r) dp[l][r]= 1Recurrent: if(l&lt;r) if(A[l]==A[r]) dp[l][r]=dp[l+1][r-1]+2; else dp[l][r]= max(dp[l+1,r] , dp[l][r-1]); 最大连续乘积解法一：暴力破解。遍历所有子数组，求最大值。 解法二：存储到某个位置为止的所有子数组的最大值和最小值。 House Robber1234567891011public int rob(int[] nums) &#123; int res=0; int rob=0, nrob=0; for(int i=0;i&lt;nums.length;i++)&#123; rob=nrob+nums[i]; nrob=res; res=Math.max(res,rob); &#125; return res;&#125; TSP12345678910111213141516171819202122232425262728static int n;static int[][] dis,memo;public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); dis=new int[n][n]; for(int i=0;i&lt;n;i++) for(int j=0;j&lt;n;j++) dis[i][j]=sc.nextInt(); memo=new int[n][1&lt;&lt;n]; System.out.println(tsp(0,1));&#125;static int tsp(int pos, int mask)&#123; // 例如，mask=1111 if(mask==(1&lt;&lt;n)-1) return dis[pos][0]; if(memo[pos][mask]!=0) return memo[pos][mask]; int ans=Integer.MAX_VALUE; for(int i=0;i&lt;n;i++)&#123; if(i!=pos &amp;&amp; (mask&amp;(1&lt;&lt;i))==0) ans=Math.min(ans, dis[pos][i]+tsp(i, mask|(1&lt;&lt;i))); &#125; return memo[pos][mask]=ans;&#125; 最大m段子段和123456789101112/* now[j]以a[j]结尾的i段子段最大值pre[j]前j个数的i-1段子段最大值*/for(int i=1;i&lt;=m;i++)&#123; res=Integer.MIN_VALUE; for(int j=i;j&lt;=n;j++)&#123; now[j]=Math.max(now[j-1], pre[j-1])+a[j]; pre[j-1]=res; res=Math.max(res,now[j]); &#125;&#125; 经典动态规划——HDU1024 m段子段和的最大值 股票问题Most consistent ways of dealing with the series of stock problems 单词分割LeetCode 139 12345678910111213141516public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; int n = s.length(); boolean[] dp = new boolean[n+1]; dp[0]=true; for(int i = 1; i&lt;=n; i++)&#123; for(int j = 0; j&lt;i ; j++)&#123; if(dp[j] &amp;&amp; wordDict.contains(s.substring(j, i)))&#123; dp[i] = true; break; &#125; &#125; &#125; return dp[n];&#125; 贪心贪心策略，多用反证法证明。 漂流船问题：每个船载两人，最少的船载完。 贪心策略：尽可能载最大和最小者。 1234567891011121314Arrays.sort(a);int res=0;int i=0,j=a.length-1;while(i&lt;j)&#123; if(a[i]+a[j]&lt;= limit)&#123; i++; j--; &#125;else&#123; j--; &#125; res++;&#125;res+=i==j?1:0;System.out.println(res); 技巧LeetCode 496、503下一个大的数 12345678910111213// 思路：维护一个递减序列public int[] nextGreaterElement(int[] nums1, int[] nums2) &#123; LinkedList&lt;Integer&gt; stack = new LinkedList&lt;&gt;(); Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int i = 0; i&lt;nums2.length; i++)&#123; while(!stack.isEmpty() &amp;&amp; stack.peek()&lt; nums2[i])&#123; map.put(stack.pop(), nums2[i]); &#125; stack.push(nums2[i]); &#125; // ...&#125; 数学约瑟夫环1） 循环链表 123456789101112public int LastRemaining_Solution(int n, int m) &#123; if(n&lt;1||m&lt;1) return -1; LinkedList&lt;Integer&gt; list=new LinkedList&lt;&gt;(); for(int i=0;i&lt;n;i++) list.add(i); int nxt=(m-1)%n; while(list.size()&gt;1)&#123; list.remove(nxt); nxt=(nxt+m-1)%list.size(); &#125; return list.get(0); &#125; 2）数学规律$$f(n,m)=\\begin{cases}0, &amp; \\text{ if } n=1 \\cr[f(n-1,m)+m]\\%n, &amp; \\text{ if } n&gt;1\\end{cases}$$ 组合字典中只含n个“a”和m个“z”，按字典序排列，第k个是什么。 12345678910111213141516171819202122232425262728293031//有点像分治法public static void main(String[] args)&#123; int n=sc.nextInt(),m=sc.nextInt(),k=sc.nextInt(); StringBuilder sb=new StringBuilder(); while(n&gt;0&amp;&amp;m&gt;0)&#123; long cnt=1; for(int i=0;i&lt;n-1;i++)&#123; cnt*=n-1+m-i; cnt/=i+1; if(cnt&gt;k) break; &#125; if(k&lt;=cnt)&#123; sb.append(\"a\"); n--; &#125;else&#123; sb.append(\"z\"); m--; k-=cnt; &#125; &#125; if(k!=1)&#123; System.out.println(-1); return; &#125; while(n--&gt;0) sb.append(\"a\"); while(m--&gt;0) sb.append(\"z\"); System.out.println(sb.toString());&#125; 全排列方法一：基于交换的全排列。 1234567891011121314151617permutation(a, 0, res);//排序Collections.sort(res);void permutationWithSwap(char[] a,int s, ArrayList&lt;String&gt; res)&#123; if(s==a.length-1)&#123; res.add(String.valueOf(a)); return; &#125; Set&lt;Character&gt; set = new HashSet&lt;&gt;(); for(int i=s; i&lt;a.length; i++)&#123; // 去重 if(i==s || !set.contains(a[i]))&#123; set.add(a[i]); swap(a,i,start); permutation(a,start+1); swap(a,i,satrt); &#125; &#125;&#125; 方法二：基于字典序的全排列。 找下一个的思想如下： 从后向前扫描，找到第一个非递增的位置p，保证了p之后序列的逆序递增； 从p+1开始向后扫描，找到最后一个大于p的位置q，结合第1步，可知这个q是大于p的最小位置； 交换p、q，然后对p+1之后的非递减序列逆序。 1234567891011121314151617181920ArrayList&lt;String&gt; permutationWithDict(String str)&#123; ArrayList&lt;String&gt; res=new ArrayList&lt;&gt;(); if(str==null||str.length==0) return res; char[] a=str.toCharArray(); Arrays.sort(a); res.add(String.valueOf(a)); for(;;)&#123; int p=a.length-1, q; while(p&gt;0 &amp;&amp; a[p-1]&gt;=a[p]) p--; //跳出循环 if(p==0) break; q= p--; while(q&lt;a.length &amp;&amp; a[q]&gt;a[p]) q++; q--; swap(a,p,q); reverse(a,p+1); &#125;&#125; 数值的整数次方123456789101112131415public double Power(double base, int exponent) &#123; if(exponent==0) return 1; int n=Math.abs(exponent); double res=1, cur=base; // 如何处理一个数的二进制形式 while(n!=0)&#123; if((n&amp;1)==1) res*=cur; cur*=cur; n&gt;&gt;&gt;=1; &#125; return exponent&gt;0? res:1/res;&#125; 素数筛https://www.cnblogs.com/grubbyskyer/p/3852421.html 其他二叉搜索树（递归）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class BinarySearchTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; static class Node&lt;E&gt; &#123; E elem; Node&lt;E&gt; left, right; public Node(E elem, Node&lt;E&gt; left, Node&lt;E&gt; right) &#123; this.elem = elem; this.left = left; this.right = right; &#125; &#125; Node&lt;T&gt; root; public Node&lt;T&gt; insert(T x) &#123; if (x == null) return null; return root = insert(x, root); &#125; Node&lt;T&gt; insert(T x, Node&lt;T&gt; root) &#123; if (root == null) return new Node&lt;&gt;(x, null, null); int comp = x.compareTo(root.elem); if (comp &gt; 0) root.right = insert(x, root.right); else if (comp &lt; 0) root.left = insert(x, root.left); return root; &#125; public boolean contains(T x) &#123; if (x == null) return false; return contains(x, root); &#125; boolean contains(T x, Node&lt;T&gt; root) &#123; if (root == null) return false; int comp = x.compareTo(root.elem); if (comp &gt; 0) return contains(x, root.right); else if (comp &lt; 0) return contains(x, root.left); return true; &#125; public Node&lt;T&gt; remove(T x) &#123; if (x == null) return null; return root = remove(x, root); &#125; Node&lt;T&gt; remove(T x, Node&lt;T&gt; root) &#123; int comp = x.compareTo(root.elem); if (comp &gt; 0) root.right = remove(x, root.right); else if (comp &lt; 0) root.left = remove(x, root.left); else &#123; // two child if (root.left != null &amp;&amp; root.right != null) &#123; root.elem = findMin(root.right).elem; root.right = remove(root.elem, root); &#125; // one child or leaf else &#123; root = root.left != null ? root.left : root.right; &#125; &#125; return root; &#125; Node&lt;T&gt; findMin(Node&lt;T&gt; root) &#123; if (root == null) return null; while (root.left != null) root = root.left; return root; &#125;&#125; 数组实现堆进而实现优先队列1234567891011121314151617181920212223242526272829303132333435363738394041424344public class MaxPQ&lt;T extends Comparable&lt;T&gt;&gt; &#123; T[] pq; int n = 0; boolean less(int i, int j) &#123; return pq[i].compareTo(pq[j]) &lt; 0; &#125; void exch(int i, int j) &#123; T t = pq[i]; pq[i] = pq[j]; pq[j] = t; &#125; void swim(int k) &#123; while (k &gt; 1 &amp;&amp; less(k / 2, k)) &#123; exch(k, k / 2); k /= 2; &#125; &#125; void sink(int k) &#123; while (2 * k &lt;= n) &#123; int j = 2 * k; if (j &lt; n &amp;&amp; less(j, j + 1)) j++; if (!less(k, j)) break; exch(k, j); k = j; &#125; &#125; void insert(T x) &#123; pq[++n] = x; swim(n); &#125; T delMax() &#123; T max = pq[1]; exch(1, n); pq[n--] = null; sink(1); return max; &#125;&#125; LRU123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class LRUCache &#123; // 双向链表，便于删除和插入 Node head,tail; HashMap&lt;Integer, Node&gt; map; int capacity,size; public LRUCache(int capacity) &#123; head=new Node(0,0); tail=new Node(0,0); head.next=tail; tail.pre=head; this.capacity=capacity; map=new HashMap&lt;&gt;(capacity); &#125; public int get(int key) &#123; if(!map.containsKey(key)) return -1; Node target=map.get(key); remove(target); add(target); return target.value; &#125; public void put(int key, int value) &#123; if(map.containsKey(key))&#123; Node node=map.get(key); node.value=value; remove(node); add(node); &#125;else&#123; Node node=new Node(key,value); if(size==capacity)&#123; Node old=tail.pre; remove(old); map.remove(old.key); &#125;else size++; add(node); map.put(key,node); &#125; &#125; void remove(Node node)&#123; node.next.pre=node.pre; node.pre.next=node.next; &#125; void add(Node node)&#123; head.next.pre=node; node.next=head.next; head.next=node; node.pre=head; &#125;&#125; 前缀树123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class TrieTree &#123; static class TrieNode &#123; Character keyword; Map&lt;Character, TrieNode&gt; subNodes = new HashMap&lt;&gt;(); boolean isKeyWordEnd; TrieNode getSubNode(Character c) &#123; return subNodes.get(c); &#125; void putSubNode(Character c, TrieNode node) &#123; subNodes.put(c, node); &#125; public boolean isKeyWordEnd() &#123; return isKeyWordEnd; &#125; public void setKeyWordEnd(boolean keyWordEnd) &#123; isKeyWordEnd = keyWordEnd; &#125; &#125; TrieNode root = new TrieNode(); final String REPLACE = \"***\"; void build(String word) &#123; TrieNode tempNode = root; for (int i = 0; i &lt; word.length(); i++) &#123; char c = word.charAt(i); TrieNode subNode = tempNode.getSubNode(c); if (subNode == null) &#123; subNode = new TrieNode(); tempNode.putSubNode(c, subNode); &#125; tempNode = subNode; if (i == word.length() - 1) tempNode.setKeyWordEnd(true); &#125; &#125; String filter(String text) &#123; TrieNode subNode = root; int begin = 0, position = 0; StringBuilder sb = new StringBuilder(); while (position &lt; text.length()) &#123; char c = text.charAt(position); subNode = subNode.getSubNode(c); if (subNode == null) &#123; sb.append(text.charAt(begin)); position = ++begin; subNode = root; &#125; else if (subNode.isKeyWordEnd()) &#123; sb.append(REPLACE); begin = ++position; subNode = root; &#125; else &#123; position++; &#125; &#125; if (begin &lt; text.length()) &#123; sb.append(text.substring(begin)); &#125; return sb.toString(); &#125;&#125; 阻塞队列12345678910111213141516171819202122232425262728293031323334353637public class BoundedBuffer &#123; final Lock lock = new ReentrantLock(); final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); int putptr, takeptr, count; Object[] items = new Object[100]; void put(Object x) throws InterruptedException &#123; lock.lock(); try &#123; while (count == items.length) notFull.await(); items[putptr] = x; if (++putptr == items.length) putptr = 0; ++count; notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; Object take() throws InterruptedException &#123; lock.lock(); try &#123; while (count == 0) notEmpty.await(); Object x = items[takeptr]; if (++takeptr == items.length) takeptr = putptr; --count; notFull.signal(); return x; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 赛马问题https://www.iteye.com/blog/hxraid-662643","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://langzi418.github.io/tags/algorithm/"}]},{"title":"Netty新连接接入过程","slug":"java/netty1","date":"2019-08-02T06:13:24.120Z","updated":"2019-08-02T09:21:09.739Z","comments":true,"path":"2019/08/02/java/netty1/","link":"","permalink":"https://langzi418.github.io/2019/08/02/java/netty1/","excerpt":"Netty的NioEventLoop线程中的循环可以分为以下几个步骤： 轮询注册在selector上的IO事件（select） 处理IO事件（processSelectedKey，unsafe.read() 开启事件传播） 执行异步task (runAllTasks)","text":"Netty的NioEventLoop线程中的循环可以分为以下几个步骤： 轮询注册在selector上的IO事件（select） 处理IO事件（processSelectedKey，unsafe.read() 开启事件传播） 执行异步task (runAllTasks) 通常有两类NioEventLoop线程：boss和worker。 对于boss线程来说，轮询出来的基本都是 accept 事件，表示有新的连接，而worker线程轮询出来的基本都是read/write事件，表示网络的读写事件。 服务端在用户进程（main线程）中启动，并将处理新连接的过程封装成一个channel，对应的pipeline为： HeadContext -&gt; ServerBootStrapAcceptor -&gt; TailContext 新连接的建立检测到有新连接接入1234567891011private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); int readyOps = k.readyOps(); if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; //NioServerSocketChannel对应NioMessageUnsafe, NioSocketChannel对应NioByteUnsafe unsafe.read(); &#125;&#125; 下面是NioMessageUnsafe.read()。 123456789101112private final List&lt;Object&gt; readBuf = new ArrayList&lt;Object&gt;();public void read()&#123; final ChannelPipeline pipeline = pipeline(); // 给每条连接创建NioSocketChannel,感兴趣的事件是read doReadMessages(readBuf); for (int i = 0; i &lt; size; i ++) &#123; pipeline.fireChannelRead(readBuf.get(i)); &#125; &#125; 下面是pipeline.fireChannelRead的调用过程。 12345678910111213141516171819202122232425262728293031// DefaultChannelPipeline.javapublic final ChannelPipeline fireChannelRead(Object msg) &#123; AbstractChannelHandlerContext.invokeChannelRead(head, msg); return this;&#125;// AbstractChannelHandlerContext.javastatic void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) &#123; // 是当前channel的事件循环线程 if (executor.inEventLoop()) &#123; next.invokeChannelRead(m); &#125; else &#123; executor.execute(()-&gt;&#123; next.invokeChannelRead(m); &#125;); &#125;&#125;private void invokeChannelRead(Object msg) &#123; // 在服务端通过HeadContext -&gt; ServerBootstrapAcceptor ((ChannelInboundHandler) handler()).channelRead(this, msg);&#125;//ServerBootstrapAcceptor.javapublic void channelRead(ChannelHandlerContext ctx, Object msg) &#123; final Channel child = (Channel) msg; // 将用户代码中服务端定义的childHandler添加到NioSocketChannel,通常为ChannelInitializer child.pipeline().addLast(childHandler); childGroup.register(child)...&#125; addLast()在添加完成后，会回调相应handler的handlerAdded(DefaultChannelHandlerContext)。其中，ChannelInitializer对应的handlerAdded会调用抽象方法initChannel()，这个方法就是我们实现来添加自定义handler的地方。(并且ChannelInitizer后在添加完成后删除自己) 这样之后，NioSocketChannel的pipeline对应为：HeadContext -&gt; 用户自定义ChannelHandler -&gt; TailContext。 将新的连接注册到NioEventLoop线程接着，ServerBoostrapAcceptor中channelRead调用到register(child)。这个方法最终从workerGroup中循环选择一个NioEventLoop线程，然后将child注册到对应的selector上。若当前线程不是child对应的NioEventLoop线程，则启动NioEventLoop线程。若是，则直接执行注册逻辑。 1234567891011121314151617181920212223242526272829303132333435// AbstractChannel.javapublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125;else&#123; eventLoop.execute(()-&gt;&#123;register0(promise);&#125;) &#125;&#125;private void register0(ChannelPromise promise) &#123; doRegister(); if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125; &#125;&#125;beginRead()&#123; doBeginRead();&#125;//AbstractNioChannel.javaprotected void doBeginRead() throws Exception &#123; // Channel.read() or ChannelHandlerContext.read() was called final SelectionKey selectionKey = this.selectionKey; final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) &#123; selectionKey.interestOps(interestOps | readInterestOp); &#125;&#125; 这里其实就是将 SelectionKey.OP_READ事件注册到selector中去，表示这条通道已经可以开始处理read事件了。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://langzi418.github.io/tags/java/"}]},{"title":"IO模型","slug":"java/io","date":"2019-07-23T08:27:18.788Z","updated":"2019-11-02T10:41:14.490Z","comments":true,"path":"2019/07/23/java/io/","link":"","permalink":"https://langzi418.github.io/2019/07/23/java/io/","excerpt":"IO漫话：如何给女朋友解释什么是Linux的五种IO模型？ 基于IO多路复用的并发编程基于思想是使用select函数，要求内核挂起进程，只有一个或多个I/O事件发生后，才将控制返回给应用程序。 1234567891011121314151617// 伪码listenfd = Open_listenfd(); //打开一个监听描述符，监听客户端IO事件FD_ZREO(&amp;read_set); //创建一个空的读集合FD_SET(STDIN, listenfd, &amp;read_set); //添加描述符到读集合// 典型服务器循环while(1)&#123; ready_set = read_set; select(listenfd+1 , &amp;ready_set, ...); //阻塞直到有描述符可读 if(FD_ISSET(STDIN, &amp;ready_set))&#123; // 处理描述符1 &#125; if(FD_ISSET(listenfd, &amp;ready_set))&#123; // 处理描述符2 &#125;&#125;","text":"IO漫话：如何给女朋友解释什么是Linux的五种IO模型？ 基于IO多路复用的并发编程基于思想是使用select函数，要求内核挂起进程，只有一个或多个I/O事件发生后，才将控制返回给应用程序。 1234567891011121314151617// 伪码listenfd = Open_listenfd(); //打开一个监听描述符，监听客户端IO事件FD_ZREO(&amp;read_set); //创建一个空的读集合FD_SET(STDIN, listenfd, &amp;read_set); //添加描述符到读集合// 典型服务器循环while(1)&#123; ready_set = read_set; select(listenfd+1 , &amp;ready_set, ...); //阻塞直到有描述符可读 if(FD_ISSET(STDIN, &amp;ready_set))&#123; // 处理描述符1 &#125; if(FD_ISSET(listenfd, &amp;ready_set))&#123; // 处理描述符2 &#125;&#125; 基于IO多路复用的并发事件驱动服务器事件驱动模型基本逻辑图 参考： key features of event driven programs 一个例子： 1234567891011121314listenfd = Open_listenfd();init_pool(listenfd, &amp;pool); // 初始化客户端连接池，设置读集合while(1)&#123; pool.ready_set = pool.read_set; pool.nready = Select(.., &amp;pool.ready_set, ...); if(FD_ISSET(listenfd, &amp;pool.ready_set))&#123; //如果监听描述符准备好，添加到连接池 add_client(); &#125; // 处理事件 check_clients(&amp;pool);&#125; 硬编码事件驱动是难以维护的。 参考《深入理解计算机系统（第三版）》12.2 线程模型线程池。。。 Reactor模型基于事件驱动IO模型 单线程 个人理解相应代码的逻辑如下图所示。 多线程 主从模式 与Netty线程模型类似。 参考： DL’s NIO","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://langzi418.github.io/tags/java/"}]},{"title":"Spring框架的一些理解","slug":"java/spring","date":"2019-04-22T10:04:57.000Z","updated":"2019-08-28T11:56:04.165Z","comments":true,"path":"2019/04/22/java/spring/","link":"","permalink":"https://langzi418.github.io/2019/04/22/java/spring/","excerpt":"Java Annotation对于注解而言，若没有相应处理器，那它和注释没什么区别。 Java注解示例： 123456789101112131415161718192021222324252627// 声明注解使用的地方。 这里是方法级。@Target(ElementType.METHOD)//声明注解的生命时长。 这里是在运行时被虚拟机获得，所以可以使用反射来读。@Retention(RetentionPolicy.RUNTIME)public @interface UseCase&#123; int id(); String description() default \"no description\";&#125;class A&#123; @UseCase(id=1,description=\"......\") void methodA&#123;...&#125; ....&#125;class UseCaseTracker&#123; public static void trackUseCases(List&lt;Integer&gt; useCases, Class&lt;?&gt; cl)&#123; for(Method m: cl.getDeclaredMethods())&#123; UseCase uc=m.getAnnonation(UseCase.class); if(uc!=null)&#123; print(uc.id(), uc.description()); &#125; &#125; &#125;&#125;","text":"Java Annotation对于注解而言，若没有相应处理器，那它和注释没什么区别。 Java注解示例： 123456789101112131415161718192021222324252627// 声明注解使用的地方。 这里是方法级。@Target(ElementType.METHOD)//声明注解的生命时长。 这里是在运行时被虚拟机获得，所以可以使用反射来读。@Retention(RetentionPolicy.RUNTIME)public @interface UseCase&#123; int id(); String description() default \"no description\";&#125;class A&#123; @UseCase(id=1,description=\"......\") void methodA&#123;...&#125; ....&#125;class UseCaseTracker&#123; public static void trackUseCases(List&lt;Integer&gt; useCases, Class&lt;?&gt; cl)&#123; for(Method m: cl.getDeclaredMethods())&#123; UseCase uc=m.getAnnonation(UseCase.class); if(uc!=null)&#123; print(uc.id(), uc.description()); &#125; &#125; &#125;&#125; 另外，注解特别适用于生成框架的“样板文件”（boilerplate）代码。如Hibernate、Spring Boot等。 SpringIoC 的一种类型是依赖注入。 ApplicationContext接口代表了Spring IoC容器，它负责实例化、配置并装配beans。 而容器是通过读配置metadata来获取配置的指令，其中，metadata包括XML、Java 注解或Java 代码。 @Configuration 表明该类可声明@Bean方法，并可Spring容器处理而产生Bean定义。 12345678910111213141516@Configurationpublic class HelloWorldConfiguration &#123; //等价于&lt;bean id=\"provider\", class=\"...\"/&gt; @Bean public MessageProvider provider() &#123; return new HelloWorldMassgeProvider(); &#125; @Bean public MessageRenderer renderer() &#123; MessageRenderer renderer = new StandardOutMessageRenderer(); renderer.setMessageProvider(provider()); return renderer; &#125;&#125; 相应的测试代码 12345678public class HelloWorldSpringAnnotated &#123; public static void main(String[] args) &#123; ApplicationContext ctx = new AnnotationConfigApplicationContext (HelloWorldConfiguration.class); MessageRenderer renderer = ctx.getBean(\"renderer\", MessageRenderer.class); renderer.render(); &#125;&#125; 以上代码也可以将Bean定义到外面，然后通过@ComponentScan来引入，如下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package ch3.annotated@Service(\"provider\")class ConfigurableMessageProvider implements MessageProvider &#123; private String message; //基于构造器的注入 @Autowired public ConfigurableMessageProvider( @Value(\"Cofigurable message\") String message) &#123; this.message = message; &#125; public String getMessage() &#123; return message; &#125;&#125;//-------@Service(\"renderer\")class StandardOutMessageRenderer implements MessageRenderer &#123; private MessageProvider messageProvider; public void render() &#123; System.out.println(messageProvider.getMessage()); &#125; //基于Setter注入 @Autowired public void setMessageProvider(MessageProvider provider) &#123; messageProvider = provider; &#125; public MessageProvider getMessageProvider() &#123; return messageProvider; &#125;&#125;//--------//启动 @Component的扫描@ComponentScan(\"ch3.annotated\")@Configurationpublic class HelloWorldSpringAnnotated &#123; public static void main(String[] args) &#123; ApplicationContext ctx = new AnnotationConfigApplicationContext (HelloWorldSpringAnnotated.class); MessageRenderer renderer = ctx.getBean(\"renderer\", MessageRenderer.class); renderer.render(); &#125;&#125; 由以上，可以引出Spring Boot中的 @SpringBootApplication。 它等价于 @ComponentScan、@Configuration、@EnableAutoConfiguration。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://langzi418.github.io/tags/java/"}]},{"title":"DynamicProxy","slug":"java/DynamicProxy","date":"2019-03-10T12:56:57.000Z","updated":"2019-03-11T13:36:57.000Z","comments":true,"path":"2019/03/10/java/DynamicProxy/","link":"","permalink":"https://langzi418.github.io/2019/03/10/java/DynamicProxy/","excerpt":"关键代码12345678910111213141516171819202122232425262728293031323334interface Interface&#123; void doSth(String s);&#125;class RealObject implments Interface &#123; void doSth(String s)&#123; //... &#125;&#125;class DynamicProxyHandler implments InvocationHandler &#123; private Object proxied; public DynamicProxyHandler(Object proxied) &#123; this.proxied = proxied; &#125; public Object invoke(Object proxy, Method m, Object[] args)&#123; /* 在此插入代理逻辑 */ return m.invoke(proxied, args); &#125;&#125;public class SimpleDynamicProxy &#123; Interface proxy = (Interface) Proxy.newInstance( Interface.class.getClassLoader(), //一般传这个已加载的类加载器就行 new Class[]&#123;Interface.class&#125;, //实现的接口 new DynamicProxyHandler(new RealObject()) ); proxy.doSth();&#125;","text":"关键代码12345678910111213141516171819202122232425262728293031323334interface Interface&#123; void doSth(String s);&#125;class RealObject implments Interface &#123; void doSth(String s)&#123; //... &#125;&#125;class DynamicProxyHandler implments InvocationHandler &#123; private Object proxied; public DynamicProxyHandler(Object proxied) &#123; this.proxied = proxied; &#125; public Object invoke(Object proxy, Method m, Object[] args)&#123; /* 在此插入代理逻辑 */ return m.invoke(proxied, args); &#125;&#125;public class SimpleDynamicProxy &#123; Interface proxy = (Interface) Proxy.newInstance( Interface.class.getClassLoader(), //一般传这个已加载的类加载器就行 new Class[]&#123;Interface.class&#125;, //实现的接口 new DynamicProxyHandler(new RealObject()) ); proxy.doSth();&#125; 可能生成如下代理类 123456789101112131415161718192021222324final class $proxy0 extends Proxy implments Interface &#123; public $Proxy0(InvocationHandler var1) &#123; super(var1); &#125; public final void doSth(String var)&#123; try&#123; // 这里的h即上文传入的 new DynamicProxyHandler(new RealObject()) super.h.invoke(this, m4, new Object[]&#123;var&#125;); &#125;catch&#123; ... &#125; &#125; static&#123; try&#123; m4=Class.forName(\"ProxyDemo$Interface\").getMethod(\"doSth\", Class.forName(\"java.lang.String\")) &#125;catch&#123; ... &#125; &#125; &#125; Proxy 类的源码简单说：先是生成构造器，再用构造器newInstance生成动态代理对象。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://langzi418.github.io/tags/java/"}]},{"title":"Spark Streaming base on Kafka","slug":"bigdata/SparkStreaming","date":"2018-12-17T09:59:43.000Z","updated":"2018-12-17T10:00:40.074Z","comments":true,"path":"2018/12/17/bigdata/SparkStreaming/","link":"","permalink":"https://langzi418.github.io/2018/12/17/bigdata/SparkStreaming/","excerpt":"实时计算 任务：计算每秒的买、卖数，买或卖总量前五的客户端及最近一小时前五的证券。","text":"实时计算 任务：计算每秒的买、卖数，买或卖总量前五的客户端及最近一小时前五的证券。 《Spark in Action》 chapter 6 Spark流处理概念图。 Spark是面向批处理的，以mini-batches来在实时计算中应用Spark的批处理特性。 以下用以Kafka作为数据源为例。 一、数据源 1、启动Kafka zookeeper-server-start .\\zookeeper.properties（Kafka依赖zookeeper） kafka-server-start .\\server.properties 2、Kafka topic kafka-topics –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic orders kafka-topics –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic metrics 以上创建orders和metrics两topic。 3、做好发送数据的准备 可以用一个脚本模拟数据发送。 1234cat orders.txt | while read line; do echo \"$line\" sleep 0.1done | kafka-console-producer.bat --broker-list $BROKER --topic orders 每隔0.1s向orders生产数据，$BROKER=&#39;localhost:9092&#39;（9092kafka默认端口）。 1、创建StreamingContext上下文，设为ssc。本地模式。 123val conf = new SparkConf().setMaster(\"local[*]\") .setAppName(\"Orders\")val ssc = new StreamingContext(conf, Seconds(5)) 第二个参数，指定了Streaming分割输入数据和创建mini-batch的时间间隔。时间间隔暂定为5s，再详谈。 2、连接Kafka 12345678910111213val kafkaParams = Map[String, Object]( \"bootstrap.servers\" -&gt; \"localhost:9092\", \"key.deserializer\" -&gt; classOf[StringDeserializer], \"value.deserializer\" -&gt; classOf[StringDeserializer], \"group.id\" -&gt; \"group1\", \"auto.offset.reset\" -&gt; \"latest\", \"enable.auto.commit\" -&gt; (false: java.lang.Boolean))val topics = Array(\"orders\")val kafkaStream = KafkaUtils .createDirectStream[String, String](ssc, PreferBrokers, Subscribe[String, String](topics, kafkaParams)) kafka流中数据结构是key-value型。访问：.key() .value() 3、处理数据orders.txt 每行是一笔交易。Schema如下： Order timestamp —Format yyyy-mm-dd hh:MM:ssOrder ID —Serially incrementing integerClient ID —Integer randomly picked from the range 1 to 100Stock symbol —Randomly picked from a list of 80 stock symbolsNumber of stocks to be bought or sold —Random number from 1 to 1,000Price at which to buy or sell—Random number from 1 to 100Character B or S —Whether the event is an order to buy or sell 按以上构造一个case class。 case适用于Bean 编译器会添加 1、工厂方法。 2、域访问。 3、 toString, hashCode, and equals。4、copy方法。 12case class Order(time:Timestamp, orderId: Long, cliendId: Long, symbol: String, amount: Int, price: Double, buy: Boolean) 然后处理Kafka中的value()。(kafka中的key()只是标识，不是我们所需的key()，要自己构造key-value) 1val orders = kafkaStream.flatMap(....) 4、构造key-value型DStream 由于二元组DStream隐式转换成PairDStreamFunctions的实例。这样，xxxByKey，flatMapValues这些都能派上用场了。 任务一：要计算每秒的买、卖数，做法：以order.buy类型为参数，构造key-value… 1val numPerType = orders.map(o =&gt; (o.buy, 1L)).reduceByKey(_ + _) 任务二：前五… 任务一只需要当前批处理的数据，但任务二需要追踪时间和不同的mini-batches。 使用updateStateByKey方法。 12345678910val amountPerClient = orders.map(o =&gt; (o.clientId, o.amount * o.price))//累加val amountState = amountPerClient.updateStateByKey( (vals, totalOpt: Option[Double]) =&gt; &#123; totalOpt match &#123; case Some(total) =&gt; Some(vals.sum + total) case None =&gt; Some(vals.sum) &#125;&#125;) 然后提取前五客户端ID。 为了每个Batch处理间隔只写一次结果，将以上结果倍合并。 使用mapWithState 此方法是updateStateByKey的性能改善。此方法只有一个参数，即StateSpec的实例。 StateSpec的函数签名 (Time, KeyType, Option[ValueType], State[StateType]) =&gt; Option[MappedType] State对象的方法： exsits()——若状态已定义，则返回true get()——获得状态值 remove()——移除 update()——更新或设置键的状态值 123456789101112val updateAmountState = (cliendId: Long, amount: Option[Double], state: State[Double]) =&gt; &#123; var total = amount.getOrElse(0.toDouble) if (state.exists()) total += state.get() state.update(total) //total设置为状态 Some((cliendId, total))//Option有两种类型：Some()和None&#125;val amountState = amountPerClient.mapWithState(StateSpec .function(updateAmountState)).stateSnapshots() Without that last method, stateSnapshots , you’d get a DStream with client ID s andtheir total amounts, but only for the clients whose orders arrived during the currentmini-batch. stateSnaphots gives you a DStream with the whole state (all clients), justlike updateStateByKey. 使用window操作来处理限制时间的计算 任务三：每小时前五 这里的窗口时间是一小时，滑动时间间隔可以设为批处理时间间隔（5s），这样可以在每个批处理间隔与其它指标一起产生。 12345678//滑动时间间隔默认是mini-batch时间间隔val stocksPerWindow = orders.map(x =&gt; (x.symbol, x.amount)) .window(Minutes(60)).reduceByKey(_ + _)val top5ClList = top5Clients.repartition(1) .map(_._1.toString) .glom() //每个RDD中的partition聚合成Array .map(arr =&gt; (\"TOPCLIENTS\", arr.toList)) 以上三类：每个批处理、批处理叠加、时间限制。 5、写回kafka。 方式：Producer.send() 最佳模式：每个JVM只创建一个Producer实例（单例模式） 12345678910111213141516171819202122case class KafkaProducerWrapper(brokerList: String) &#123; val producerProps: Properties = &#123; val prop = new Properties() prop.put(\"bootstrap.servers\", brokerList) prop.put(\"key.serializer\", \"org.apache.kafka.common.serialization.ByteArraySerializer\") prop.put(\"value.serializer\", \"org.apache.kafka.common.serialization.ByteArraySerializer\") prop &#125; val producer = new KafkaProducer[Array[Byte], Array[Byte]](producerProps) def send(topic: String, key: String, value: String): Unit = &#123; producer.send(new ProducerRecord[Array[Byte], Array[Byte]](topic, key.toCharArray.map(_.toByte), value.toCharArray.map(_.toByte))) &#125;&#125;object KafkaProducerWrapper &#123; var brokerList = \"\" lazy val instance = new KafkaProducerWrapper(brokerList)//首次使用时实例化&#125; 在metrics主题下消费数据： kafka-console-consumer –bootstrap-server localhost:9092 –topic metrics –property print.key=true","categories":[],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://langzi418.github.io/tags/bigdata/"}]},{"title":"Spark API in Depth","slug":"bigdata/SparkInDepth","date":"2018-11-30T06:41:43.000Z","updated":"2018-11-30T06:41:24.188Z","comments":true,"path":"2018/11/30/bigdata/SparkInDepth/","link":"","permalink":"https://langzi418.github.io/2018/11/30/bigdata/SparkInDepth/","excerpt":"《Spark in Action》Chapter4 个人总结： DStream &lt;- a seq of RDDs &lt;- Partitions key-value RDD = pair RDD manipulated by funtionByKey()","text":"《Spark in Action》Chapter4 个人总结： DStream &lt;- a seq of RDDs &lt;- Partitions key-value RDD = pair RDD manipulated by funtionByKey() pair RDDskey-value 模型是一种简单、通用的数据模型。 Creating利用map将RDD中数据转换成二元组（f(element), element)，即RDD-&gt;pair RDD。 原理：二元组形式的RDD会隐式转换为PairRDDFunctions的实例(Scala语法)。 Basic pair RDD functionsgetting keys and values1pRDD.keys.distinct.count() counting values per key1234pRDD.countByKey()// 求最值val (cid, purch) = transByCust.countByKey.toSeq.maxBy(_._2) looking up values for a single key1234transByCust.lookup(53)// 打印结果transByCust.lookup(53).foreach(tran =&gt; println(tran.mkString(\", \"))) using the mapValues transformation to change values in a pair RDD只改变值 123456transByCust = transByCust.mapValues(tran =&gt; &#123; if (tran(3).toInt == 25 &amp;&amp; tran(4).toDouble &gt; 1) tran(5) = (tran(5).toDouble * 0.95).toString tran &#125;) using the flatMapValues transformation to add values to keys此函数可以给一个键添加多个值或一起移除某个键（键的数量会增减）。 From each of the values in the return collection, a new key-value pair is created for the corresponding key. 1234567891011transByCust = transByCust.flatMapValues(tran =&gt; &#123; if (tran(3).toInt == 81 &amp;&amp; tran(4).toDouble &gt;= 5) &#123; val cloned = tran.clone() cloned(5) = \"0.00\" cloned(3) = \"70\" cloned(4) = \"1\" List(tran, cloned) &#125; else &#123; List(tran) &#125; &#125;)s using reduceByKey transformation to merge all values of a keyfoldByKey 与 reduceByKey 类似，区别在于需要一个额外的 zeroValue 参数。 foldByKey(zeroValue: V)(func: (V, V) =&gt; V): RDD[(K, V)] 由于RDD的并行特性，zeroValues可能被多次使用。 12val amounts = transByCust.mapValues(t =&gt; t(5).toDouble)val totals = amounts.foldByKey(0)(_ + _).collect() using aggregateByKey to group all values of a keydata partition and reducing data shuffling例如，当从本地文件系统加载文件到Spark时，文件内容被分割成分片，最终被分配到集群的结点上。这些分片形成了RDD，同一结点上可能不止一个分片。每个RDD维护一个分片列表。 1println(transByProd.partitions.length) The number of RDD partitions is important because, in addition to influencing data distribution throughout the cluster, it also directly determines the number of tasks that will be running RDD transformations. If this number is too small, the cluster will be underutilized. Furthermore, memory problems could result, because working sets might get too big to fit into the memory of executors. We recommend using three to four times more partitions than there are cores in your cluster. Moderately larger values shouldn’t pose a problem, so feel free to experiment. But don’t get too crazy,because management of a large number of tasks could create a bottleneck. using Spark’s data partitioners两种：HashPartitioner、RangePartitioner。也可定制。 默认是HashPartitioner。 partitionIndex = hashCode % numberOfPartitions Understanding and avoiding unnecessary shuffling Physical movement of data between partitions is called shuffling. It occurs when data from multiple partitions needs to be combined in order to build partitions for a new RDD .When grouping elements by key，shuffling occurs. When grouping elements by key，shuffling occurs. Shuffling when explicitly(显式) changing partitioners Because changing the partitioner provokes shuffles, the safest approach,performance-wise(性能优先), is to use a default partitioner as much as possible and avoidinadvertently causing a shuffle. shuffing caused by partitions removal详细等学Spark优化再看。 Repartitioning RDDspartitionBy只有pair RDD可用，接受一个Partitioner作为参数；当此Partition与原先的不一样时，shuffle发生，重新分片。 collecting partition data with a glom transfotamtionglom(意思同 grab)，即将每个分片合成一个数组，用返回的RDD将这些数组作为元素。新RDD的数组数量等于之前的分片数量。这个过程中，partitioner被移除。 Joining, sorting, and grouping datajoin((K, (V, W))) 非空 leftOuterJoin (K, (V, Option(W))) rightOuterJoin (K, (Option(V), W)) fullOuterJoin (K, (Option(V), Option(W)) using subtract(差集)… Using accumulators and broadcast variables to communicate with Spark executors作用：维护全局状态或在任务和分片之间共享数据。 sending data to executors using broadcast variables(bv)能在集群间共享，与accumulators不同的是，其不能被执行器修改。驱动创造bv，然后执行器读取它。 当有一个大集合数据需要被绝大多数执行器使用时，应使用bv。 创建：SparkContext.broadcast(value)，读Broadcast.value。 总结 pair RDD含二元组：keys 和 values。 scala中pair RDD隐式转换为pairRDDFuctions的实例，它有专有的pair RDD操作。 countByKey返回map，含每个键出现的次数。 mapValues，只改变pair RDD的值。 flatMapValues，一个键能对应零个或多个值（键的总数增加）。 reduceByKey和foldByKey，归约同一个键的所有值到一个值，值类型不变。 aggregateByKey，聚合值，但转换值到其它类型。 Data Partition，是Spark的一种在一个集群的多个结点间分数据的机制。 The number of RDD partitions is important because, in addition to influencingdata distribution throughout the cluster, it also directly determines the numberof tasks that will be running RDD transformations. shffuling时，数据不仅被写到硬盘，而且在网络之间传输。因此，使Spark作业中的shuffle数最小化是重要的。 Every Spark job is divided into stages based on the points where shuffles occur.","categories":[],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://langzi418.github.io/tags/bigdata/"}]},{"title":"Python编程中邂逅的问题","slug":"python/problem","date":"2018-11-20T10:35:43.000Z","updated":"2019-08-12T12:57:16.371Z","comments":true,"path":"2018/11/20/python/problem/","link":"","permalink":"https://langzi418.github.io/2018/11/20/python/problem/","excerpt":"for循环12345for i in range(5): print(i) i += 1# output 1 2 3 4 5 for 循环中的 循环变量 不会被修改，此时应使用 while。","text":"for循环12345for i in range(5): print(i) i += 1# output 1 2 3 4 5 for 循环中的 循环变量 不会被修改，此时应使用 while。 with表达式12345678910111213141516with open('output/0.txt') as f1: # 这里的f2是动态变化的 f2 = open('output/2.txt') # f2.close() print(f2.readline())print(f1.readline())# output2016-03-22 20:25:28,20001,89,NQ,396,58.00,S Traceback (most recent call last): File \"D:/0hadoop/python/pystudy/action/test.py\", line 7, in &lt;module&gt; print(f1.readline())ValueError: I/O operation on closed file. with表达式建立的上下文会自动关闭IO。 列表123l = []# return None,不应该作为参数,应该 fun(l + [\"sth\"]) l.append(\"sth\") %12# 7print(-123%10) 12// -3System.out.println(-123%10) Python IO读text data 1234567# 读整个文件为一个字符串with open('somefile.txt') as f: data=f.read() #迭代处理文件 with open('somefile.txt') as f: for line in f: 写text data，会覆盖。 12345678with open('somefile.txt') as f: f.write(text1) f.write(text2) with open('somefile.txt') as f: #输出重定向到f，覆盖 print(line1,file=f) print(line2,file=f) 追加文本文件，open(… , ‘at’) binary data such as images、sound files等等。 Infinite如果只需要一个表示无限的数，可以用： 12float('inf')float('-inf') 全局变量不要命名太简单，例如 i，j；否则容易与局部变量冲突。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://langzi418.github.io/tags/python/"}]},{"title":"Java8 Learn","slug":"java/java8","date":"2018-11-12T11:35:43.000Z","updated":"2018-11-12T11:35:26.521Z","comments":true,"path":"2018/11/12/java/java8/","link":"","permalink":"https://langzi418.github.io/2018/11/12/java/java8/","excerpt":"行为参数化 行为参数化，就是一个方法接受多个不同的行为作为参数，并在内部使用它们，完成不同行为的能力。 行为参数化让代码更好地适应不断变化的要求，减轻未来的工作量。 传递代码，就是将新行为作为参数传递给方法。Java API中包括排序、线程和GUI处理。","text":"行为参数化 行为参数化，就是一个方法接受多个不同的行为作为参数，并在内部使用它们，完成不同行为的能力。 行为参数化让代码更好地适应不断变化的要求，减轻未来的工作量。 传递代码，就是将新行为作为参数传递给方法。Java API中包括排序、线程和GUI处理。 Lambda在哪里使用Lambda? 函数式接口函数式接口即只定义一个抽象方法的接口。 Lambda表达式允许你直接以内联的形式为函数式接口的抽象方法提供实现，并把整个表达式作为函数式接口的实例（具体说来，是函数式接口一个具体实现的实例）。 使用： 1234@FunctionalInterfacepublic interface BufferedReaderProcessor &#123; String process(BufferedReader b) throws IOException;&#125; 123456789101112131415public class BufferTest &#123; public static String processFile(BufferedReaderProcessor p) throws IOException &#123; try (BufferedReader br = new BufferedReader(new FileReader(\"data.txt\"))) &#123; return p.process(br); &#125; &#125; public static void main(String[] args) throws IOException &#123; String oneLine = processFile((BufferedReader br) -&gt; br.readLine()); // String oneLine = processFile(BufferedReader::readLine); String twoLines = processFile( (BufferedReader br) -&gt; br.readLine() + br.readLine()); &#125;&#125; 使用函数式接口函数式接口很有用，因为抽象方法的签名可以描述Lambda表达式的签名。函数式接口的抽象方法的签名称为函数描述符。 Java API中已经有了几个函数式接口，比如 Comparable 、 Runnable 和Callable 。 Java 8 中有Predicate 、 Consumer 和 Function。 123456@FunctionalInterfacepublic interface Predicate&lt;T&gt;&#123; boolean test(T t);&#125;Predicate&lt;String&gt; nonEmptyStringPredicate = (String s) -&gt; !s.isEmpty(); 12345678910111213@FunctionalInterfacepublic interface Consumer&lt;T&gt;&#123; void accept(T t);&#125;public static &lt;T&gt; void forEach(List&lt;T&gt; list, Consumer&lt;T&gt; c)&#123; for(T i: list)&#123; c.accept(i); &#125;&#125;forEach( Arrays.asList(1,2,3,4,5),(Integer i) -&gt; System.out.println(i)); 123456789101112131415@FunctionalInterfacepublic interface Function&lt;T, R&gt;&#123; R apply(T t);&#125;public static &lt;T, R&gt; List&lt;R&gt; map(List&lt;T&gt; list,Function&lt;T, R&gt; f)&#123;List&lt;R&gt; result = new ArrayList&lt;&gt;(); for(T s: list)&#123; result.add(f.apply(s)); &#125; return result;&#125;// [7, 2, 6]List&lt;Integer&gt; l = map(Arrays.asList(\"lambdas\",\"in\",\"action\"),(String s) -&gt; s.length()); 原始类型特化比如，在下面的代码中，使用 IntPredicate 就避免了对值 1000 进行装箱操作，但要是用 Predicate&lt;Integer&gt; 就会把参数 1000 装箱到一个 Integer 对象中： 12345678public interface IntPredicate&#123; boolean test(int t);&#125;IntPredicate evenNumbers = (int i) -&gt; i % 2 == 0;evenNumbers.test(1000);Predicate&lt;Integer&gt; oddNumbers = (Integer i) -&gt; i % 2 == 1;oddNumbers.test(1000); 因函数式接口都不允许抛出受检异常。如果需要Lambda表达式抛出异常，有两种方法：定义一个自己的函数式接口，并声明受检异常，或把Lambda包在一个try/catch块中。 类型检查、类型推断以及限制类型推断Java编译器会从上下文（目标类型）推断出用什么函数式接口来配合Lambda表达式，这意味着它也可以推断出适合Lambda的签名，因为函数描述符可以通过目标类型来得到。这样做的好处在于，编译器可以了解Lambda表达式的参数类型，这样就可以在Lambda语法中省去标注参数类型。 方法引用可以视为某些Lambda的快捷写法。可以重复使用现有的方法定义，并像Lambda一样传递它们。 如果一个Lambda表达式只是“直接调用这个方法”，那最好还是用名称来调用它，而不是去描述如何调用它。 复合Lambda表达式的有用方法比较器复合1inventory.sort(comparing(Apple::getWeight).reversed()); 比较器链123inventory.sort(comparing(Apple::getWeight) .reversed() .thenComparing(Apple::getCountry)); 谓词复合123Predicate&lt;Apple&gt; redAndHeavyAppleOrGreen = redApple.and(a -&gt; a.getWeight() &gt; 150) .or(a -&gt; \"green\".equals(a.getColor())); 函数复合1234Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;Function&lt;Integer, Integer&gt; h = f.andThen(g);int result = h.apply(1); 流它允许以声明性方式处理数据集合（通过查询语句来表达，而不是临时编写一个实现）。 只能遍历一次。 内部迭代与外部迭代Java Collection外部迭代，Stream内部迭代。 内部迭代优点：可以透明地并行处理， 或者用更优化的顺序进行处理。 中间操作诸如 filter 或 sorted 等中间操作会返回另一个流。这让多个操作可以连接起来形成一个查询。重要的是，除非流水线上触发一个终端操作，否则中间操作不会执行任何处理——它们很懒。 终端操作终端操作会从流的流水线生成结果。其结果是任何不是流的值，比如 List 、 Integer ，甚至 void 。 使用流三件事：一数据源、二中间操作链、三终端操作。 流的流水线理念类似于构建器模式。 筛选和切片用谓词筛选123List&lt;Dish&gt; vegetarianMenu = menu.stream() .filter(Dish::isVegetarian) .collect(toList()); 流还支持一个叫作 distinct 的方法，它会返回一个元素各异（根据流所生成元素的hashCode 和 equals 方法实现）的流。 截短流流支持 limit(n) 方法，该方法会返回一个不超过给定长度的流。 跳过元素流还支持 skip(n) 方法，返回一个扔掉了前 n 个元素的流。 映射流的扁平化 Arrays.stream() 的方法可以接受一个数组并产生一个流 123456List&lt;String&gt; uniqueCharacters = words.stream() .map(w -&gt; w.split(\"\")) .flatMap(Arrays::stream) .distinct() .collect(Collectors.toList()); flatMap合并为一个流。 查找和匹配allMatch、anyMatch、noneMatch、findFirst、findAny 短路求值对于流而言，某些操作（例如 allMatch 、 anyMatch 、 noneMatch 、 findFirst 和 findAny ）不用处理整个流就能得到结果。只要找到一个元素，就可以有结果了。同样， limit 也是一个短路操作：它只需要创建一个给定大小的流，而用不着处理流中所有的元素。在碰到无限大小的流的时候，这种操作就有用了：它们可以把无限流变成有限流。 归约算术123int sum = numbers.stream().reduce(0, (a, b) -&gt; a + b);int sum = numbers.stream().reduce(0, Integer::sum); 最值1Optional&lt;Integer&gt; max = numbers.stream().reduce(Integer::max); 原始类型流特化IntStream、DoubleStream、LongStream，分别将流中的元素特化为int、long和double，从而避免了暗含的装箱成本。还带来了进行常用数值归约的新方法，如sum、max。 IntStream 还支持其他的方便方法，如max 、 min 、 average 等。 映射到数值流123int calories = menu.stream() .mapToInt(Dish::getCalories) .sum(); 转换回对象流IntStream 上的操作只能产生原始整数： IntStream 的 map 操作接受的Lambda必须接受 int 并返回 int。 1Stream&lt;Integer&gt; stream = intStream.boxed(); 数值范围Java 8引入了两个可以用于 IntStream 和 LongStream 的静态方法，帮助生成这种范围：range 和 rangeClosed 。这两个方法都是第一个参数受起始值，第二个参数接受结束值。但range 是不包含结束值的，而 rangeClosed 则包含结束值。 构建流由值创建流静态方法Stream.of，通过显示值创建流。可接受任意数量的参数。 1Stream&lt;String&gt; stream = Stream.of(\"Java 8 \", \"Lambdas \", \"In \", \"Action\"); 可使用empty得到一个空流。 1Stream&lt;String&gt; emptyStream = Stream.empty(); 由数组创建流Arrays.stream接受数组作为参数，例如，可将一个原始类型int转换成IntStream。 12int[] numbers = &#123;2, 3, 5, 7, 11, 13&#125;;int sum = Arrays.stream(numbers).sum(); 由文件生成流Java NIO（非阻塞IO） 由函数生成流：创建无限流Stream API提供了两个静态方法来从函数生成流： Stream.iterate 和 Stream.generate 。 123Stream.iterate(0, n -&gt; n + 2) .limit(10) .forEach(System.out::println); 都是按需生成，但generate不是依次对每个新生成的值应用函数。它接受一个Supplier&lt;T&gt;类型的Lambda提供新的值。 123Stream.generate(Math::random) .limit(5) .forEach(System.out::println); 用流&lt;收集&gt;数据函数式编程相对于指令式编程一个主要的优势：只需指出希望的结果——“做什么”，而不用操心执行的步骤——“如何做”。 预定义收集器三大功能： 将流元素归约和汇总为一个值 元素分组 元素分区 归约和汇总12long howManyDishes = menu.stream().count()；int howManyDishes = menu.size(); 查找流中的最大值和最小值Collectors.maxBy 和Collectors.minBy ，用来计算流中的最大或最小值。这两个收集器接收一个 Comparator 参数来比较流中的元素。 12345678910Comparator&lt;Dish&gt; dishCaloriesComparator = Comparator.comparingInt(Dish::getCalories);Optional&lt;Dish&gt; mostCalorieDish = menu.stream() .collect(maxBy(dishCaloriesComparator));Optional&lt;Dish&gt; mostCalorieDish = menu.stream() .max(dishCaloriesComp); 汇总12345678910111213141516// 求和int totalCalories = menu.stream().collect(summingInt(Dish::getCalories));int totalCalories = menu.stream() .mapToInt(Dish::getCalories).sum();// 求平均值double avgCalories = menu.stream().collect(averagingInt(Dish::getCalories));OptionalDouble avgCalories2 = menu.stream() .mapToDouble(Dish::getCalories) .average(); 有时候，我们可能希望得到两个或更多这样的结果，而且只需要一次操作就可以完成。此时，可以使用summarizingInt工厂方法返回收集器。例如，通过一次summarinzing操作，即可得到菜肴热量的总和、平均值、最大值、最小值： 12IntSummaryStatistics menuStatistics = menu.stream().collect(summarizingInt(Dish::getCalories)); 收集到一个IntSummaryStatisics中，它提供了一个取值方法来访问结果。 连接字符串joining工厂方法返回一个收集器会把对流中的每一个对象应用toString方法得到的字符串连接成一个字符串。 1String shortMeu = menu.stream().map(Dish::getName).collect(joining()); joining内部使用StringBuilder。如果Dish类有一个toString方法来返回菜肴的名称，那无需用提取每一道菜名称的函数来对原流做映射，就能得到相同的结果： 1String shortMenu = menu.stream().collect(joining()); joining()工厂方法有一个重载版本，可接受分界符， 1String shortMenu = menu.stream().map(Dish::getName).collect(joining(\", \")); 广义的归约汇总以上所有的收集器，都可以用reducing方法定义归约过程。以上方法只是方便程序员而已。 collect与reduce: collect()适合表达可变容器上的归约，更关键的是它适合并行操作。 根据情况选择最佳方案 以下开始发挥collect的作用分组Collections.groupingBy(Function) Function称为分类函数。分组操作的结果是一个Map。 12Map&lt;Dish.Type, List&lt;Dish&gt;&gt; dishesByType = menu.stream().collect(groupingBy(Dish::getType)); 可用Lambda编写复杂的分类函数。 Collections.groupingBy(Function,Collector) 接受collector类型的第二个参数，进行二级分组。可把一个内层的groupingBy传递给外层的groupingBy，作为二级分类标准。 这里的collector可以是任意类型，例如counting()，maxBy()。 maxBy(Comparator) 1234Map&lt;Dish.Type, Optional&lt;Dish&gt;&gt; mostCaloricByType = menu.stream() .collect(groupingBy(Dish::getType, maxBy(comparingInt(Dish::getCalories)))); groupingBy 收集器只有在应用分组条件后，第一次在流中找到某个键对应的元素时才会把键加入分组 Map 中。这意味着 Optional 包装器在这里不是很有用。 把收集器返回的结果转换为另一种类型，你可以使用Collectors.collectingAndThen 工厂方法返回的收集器。 123456Map&lt;Dish.Type, Dish&gt; mostCaloricByType = menu.stream() .collect(groupingBy(Dish::getType, collectingAndThen( maxBy(comparingInt(Dish::getCalories)), Optional::get))); 123Map&lt;Dish.Type, Integer&gt; totalCaloriesByType = menu.stream().collect(groupingBy(Dish::getType, summingInt(Dish::getCalories))); 1234567Map&lt;Dish.Type, Set&lt;CaloricLevel&gt;&gt; caloricLevelsByType = menu.stream().collect( groupingBy(Dish::getType, mapping( dish -&gt; &#123; if (dish.getCalories() &lt;= 400) return CaloricLevel.DIET; else if (dish.getCalories() &lt;= 700) return CaloricLevel.NORMAL; else return CaloricLevel.FAT; &#125;, toSet() ))); 注意在上一个示例中，对于返回的 Set 是什么类型并没有任何保证。但通过使用 toCollection ，你就可以有更多的控制。 1234567Map&lt;Dish.Type, Set&lt;CaloricLevel&gt;&gt; caloricLevelsByType = menu.stream().collect( groupingBy(Dish::getType, mapping( dish -&gt; &#123; if (dish.getCalories() &lt;= 400) return CaloricLevel.DIET; else if (dish.getCalories() &lt;= 700) return CaloricLevel.NORMAL; else return CaloricLevel.FAT; &#125;, toCollection(HashSet::new) ))); 分区它是分组的特殊情况：由一个谓词（返回布尔值的函数）作为分类函数，称为分区函数。 12345Map&lt;Boolean, List&lt;Dish&gt;&gt; partitionedMenu = menu.stream() .collect(partitioningBy(Dish::isVegetarian));List&lt;Dish&gt; vegetarianDishes = partitionedMenu.get(true); 分区的好处在于保留了分区函数返回 true 或 false 的两套流元素列表。 123456Map&lt;Boolean, Dish&gt; mostCaloricPartitionedByVegetarian = menu.stream().collect( partitioningBy(Dish::isVegetarian, collectingAndThen( maxBy(comparingInt(Dish::getCalories)), Optional::get))); 可以仿造groupingBy多级分区。 收集器接口可为collector接口提供自己的实现，从而自由地创建自定义归约操作。 1234567public interface Collector&lt;T, A, R&gt; &#123; Supplier&lt;A&gt; supplier(); BiConsumer&lt;A, T&gt; accumulator(); Function&lt;A, R&gt; finisher(); BinaryOperator&lt;A&gt; combiner(); Set&lt;Characteristics&gt; characteristics();&#125; 并行流对顺序流调用parallel方法，并不意味着流本身有任何实际的变化。它在内部实际上就是设了一个 boolean 标志，表示你想让调用 parallel 之后进行的所有操作都并行执行。 并行流内部使用了默认的ForkJoinPool，它默认的线程数量是处理器的数量，可由Runtime.getRuntime().availableProcessors()得到。 避免共享可变状态，确保并行 Stream 得到正确的结果。 并行流无需显式地处理线程和同步问题。 自定义Spliterator因为原始的 String 在任意位置拆分，所以有时一个词会被分为两个词，然后数了两次。这就说明，拆分流会影响结果，而把顺序流换成并行流就可能使结果出错。 如何解决这个问题呢？解决方案就是要确保 String 不是在随机位置拆开的，而只能在尾拆开。要做到这一点，你必须为 Character 实现一个 Spliterator ，它只能在两个词之间拆开String （如下所示），然后由此创建并行流。 Optional替代Null如何为缺失的对象建模？Optional：当变量存在时，Optional类只是对类的简单封装。当变量不存在时，缺失的值被建模成一个“空”的Optional对象，由方法Optional.empty返回。 Optional.empty() 方法是一个静态工厂方法，它返回 Optional 类的特定单一实例。 Optional.empty()用处： 应用Optional创建Optional对象： 声明一个空的Optional Optional&lt;Car&gt; optCar= Optional.empty(); 依据一个非空值创建Optional Optional&lt;Car&gt; optCar = Optional.of(car); 若car是null，抛出NPE。 可接受null的Optional Optional&lt;Car&gt; optCar = Optional.ofNullable(car); Optional提供的get方法在遭遇空的Optional对象时，也会抛出异常。 怎么办？ 使用map从Optional对象中提取和转换值123456public String getCarInsuranceName(Optional&lt;Person&gt; person) &#123; return person.flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse(\"Unknown\"); // Optional为空时，设置默认值&#125; 由于 Optional 类设计时就没特别考虑将其作为类的字段使用，所以它也并未实现Serializable 接口。 若要实现序列化的域模型，作为替代方案，提供一个能访问声明为 Optional 、变量值可能缺失的接口。 123456public class Person &#123; private Car car; public Optional&lt;Car&gt; getCarAsOptional() &#123; return Optional.ofNullable(car); &#125;&#125; CompleptableFuture:组合式异步编程Future接口它设计初衷是为将来某个时刻会发生的结果进行建模。 这种编程方式让你的线程可以在 ExecutorService 以并发方式调用另一个线程执行耗时操作的同时，去执行一些其他的任务。接着，如果你已经运行到没有异步操作的结果就无法继续任何有意义的工作时，可以调用它的 get 方法去获取操作的结果。如果操作已经完成，该方法会立刻返回操作的结果，否则它会阻塞你的线程，直到操作完成，返回相应的结果。 Future 接口的局限性：很难表述 Future 结果之间的依赖性。 于是CompletableFuture，CompletableFuture 和 Future 的关系就跟 Stream 和 Collection 的关系一样。 使用 CompletableFuture 构建异步应用12345678910public Future&lt;Double&gt; getPriceAsync(String product) &#123; CompletableFuture&lt;Double&gt; futurePrice = new CompletableFuture&lt;&gt;(); new Thread( () -&gt; &#123; double price = calculatePrice(product); futurePrice.complete(price); &#125;).start(); // 无需等待尚未结束的计算，直接返回Future对象 return futurePrice;&#125; 使用工厂方法 supplyAsync 创建 CompletableFuture123public Future&lt;Double&gt; getPriceAsync(String product) &#123; return CompletableFuture.supplyAsync(() -&gt; calculatePrice(product));&#125; supplyAsync 方法接受一个生产者（ Supplier ）作为参数，返回一个CompletableFuture对象，该对象完成异步执行后会读取调用生产者方法的返回值。 生产者方法会交由 ForkJoinPool池中的某个执行线程（ Executor ）运行，但是你也可以使用 supplyAsync 方法的重载版本，传递第二个参数指定不同的执行线程执行生产者方法。一般而言，向 CompletableFuture 的工厂方法传递可选参数，指定生产者方法的执行线程是可行的。 使用 CompletableFuture 发起异步请求 这里使用两个不同的Stream流水线的原因是：流操作之间存在延迟。如果在单一的流水线中处理流，发向不同商家的请求只能以同步、顺序执行的方式才会成功。 寻找更好的方案 当任务数超过四个时，定制执行器。 N(threads) = N(CPU) U(CPU) (1 + W/C)其中： N CPU 是处理器的核的数目，可以通过 Runtime.getRuntime().availableProce-ssors() 得到 U CPU 是期望的CPU利用率（该值应该介于0和1之间） W/C是等待时间与计算时间的比率 123456789private final Executor executor = Executors.newFixedThreadPool(Math.min(shops.size(), 100), new ThreadFactory() &#123; public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); t.setDaemon(true); return t; &#125; &#125;); Java程序无法终止或者退出一个正在运行中的线程，所以最后剩下的那个线程会由于一直等待无法发生的事件而引发问题。与此相反，如果将线程标记为守护进程，意味着程序退出时它也会被回收。这二者之间没有性能上的差异。 并行——使用流还是 CompletableFutures ？ 如果进行的是计算密集型的操作，并且没有IO，推荐使用Stream接口，因为实现简单，同时效率也可能是最高的（如果所有线程都是计算密集型，根据以上估算公式，就没有必要创建比处理器核数更多的线程）。 反之，如果你并行的工作单元还涉及等待I/O的操作（包括网络连接等待），那么使用CompletableFuture 灵活性更好，你可以像前文讨论的那样，依据等待/计算，或者W/C的比率设定需要使用的线程数。这种情况不使用并行流的另一个原因是，处理流的流水线中如果发生I/O等待，流的延迟特性会让我们很难判断到底什么时候触发了等待。 对多个异步任务进行流水线操作123456789101112131415public List&lt;String&gt; findDiscountFuture(String product) &#123; List&lt;CompletableFuture&lt;String&gt;&gt; futureList = shops.stream() .map(shop -&gt; CompletableFuture.supplyAsync( () -&gt; shop.getName() + \" price is \" + shop.getPrice(product),executor)) .map(future -&gt; future.thenApply(Quote::parse)) .map(future -&gt; future.thenCompose(quote -&gt; CompletableFuture.supplyAsync( () -&gt; Discount.applyDiscount(quote), executor))) .collect(toList()); return futureList.stream() .map(CompletableFuture::join) .collect(toList()); &#125; thenCompose方法允许对两个异步操作进行流水线，第一个操作完成时，将其结果作为参数传递给第二个操作。换句话说，即创建两个CompletableFuture对象调用thenCompose，并向其传递一个Function。当第一个CompletableFuture执行完毕后，它的结果结果将作为该函数的参数， 这个函数返回值是以第一个 CompletableFuture 的返回做输入计算出的第二个 CompletableFuture 对象。 thenCompose 方法像 CompletableFuture 类中的其他方法一样，也提供了一个以 Async 后缀结尾的版本 thenComposeAsync 。通常而言，名称中不带 Async的方法和它的前一个任务一样，在同一个线程中运行；而名称以 Async 结尾的方法会将后续的任务提交到一个线程池，所以每个任务是由不同的线程处理的。就这个例子而言，第二个CompletableFuture 对象的结果取决于第一个CompletableFuture ，所以无论你使用哪个版本的方法来处理 CompletableFuture 对象，对于最终的结果，或者大致的时间而言都没有多少差别。我们选择 thenCompose 方法的原因是因为它更高效一些，因为少了很多线程切换的开销。 主线程还能执行其它重要的操作，如响应UI。 另一种比较常见的情况是，你需要将两个完全不相干的 CompletableFuture 对象的结果整合起来，而且你也不希望等到第一个任务完全结束才开始第二项任务。 1234567Future&lt;Double&gt; futurePriceInUSD = CompletableFuture.supplyAsync(() -&gt; shop.getPrice(product)) .thenCombine( CompletableFuture.supplyAsync( () -&gt; exchangeService.getRate(Money.EUR, Money.USD)), (price, rate) -&gt; price * rate ); 这里thenCombine方法，它接受BiFunction作为第二个参数，这个参数定义了两个CompletableFuture 对象完成计算后，如何合并结果。它的Async版本是：导致BiFunction中定义的合并操作被提交到线程池中，由另一个任务以异步的方式执行。其中的两个CompletableFuture 对象是在不同的线程执行的。 CompletableFuture 利用Lambda表达式以声明式的API提供了一种机制，能够用最有效的方式，非常容易地将多个以同步或异步方式执行复杂操作的任务结合到一起。 响应 CompletableFuture 的 completion 事件避免的首要的问题是，等待创建一个包含了所有价格的List创建完成。应该直接处理CompletableFuture。这样每个 CompletableFuture 都在为某个商店执行必要的操作。 1234567891011121314public Stream&lt;CompletableFuture&lt;String&gt;&gt; findDiscountStream(String product) &#123; return shops.stream() .map(shop -&gt; CompletableFuture.supplyAsync( () -&gt; shop.getName() + \" price is \" + shop.getPrice(product), executor)) .map(future -&gt; future.thenApply(Quote::parse)) .map(future -&gt; future.thenCompose(quote -&gt; CompletableFuture.supplyAsync( () -&gt; Discount.applyDiscount(quote), executor))); &#125;findPricesStream(\"myPhone\").map(f -&gt; f.thenAccept(System.out::println)); thenAccept方法也有Async版本。异步版本会对处理结果的消费者进行调度，从线程池中选择一个新的线程继续执行，不再由同一个线程完成CompletableFuture的所有任务。 如果想避免不必要的上下文切换，避免在等待线程上浪费时间，尽快响应CompletableFuture的completion事件，可以不使用异步版本。 由于 thenAccept 方法已经定义了如何处理 CompletableFuture 返回的结果，一旦CompletableFuture 计算得到结果，它就返回一个CompletableFuture&lt;Void&gt;。 1234CompletableFuture[] futures = findPricesStream(\"myPhone\") .map(f -&gt; f.thenAccept(System.out::println)) .toArray(size -&gt; new CompletableFuture[size]);CompletableFuture.allOf(futures).join(); allOf 工厂方法接收一个由 CompletableFuture 构成的数组，数组中的所有CompletableFuture 对象执行完成之后，它返回一个CompletableFuture&lt;Void&gt; 对象。这意味着，如果你需要等待最初 Stream 中的所有 CompletableFuture 对象执行完毕，对 allOf 方法返回的CompletableFuture 执行 join 操作是个不错的主意。 然而在另一些场景中，你可能希望只要 CompletableFuture 对象数组中有任何一个执行完毕就不再等待，比如，你正在查询两个汇率服务器，任何一个返回了结果都能满足你的需求。在这种情况下，你可以使用一个类似的工厂方法 anyOf 。该方法接收一个 CompletableFuture 对象构成的数组，返回由第一个执行完毕的 CompletableFuture 对象的返回值构成的CompletableFuture&lt;Object&gt; 。 新的日期和时间API","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://langzi418.github.io/tags/java/"}]},{"title":"FluentPy Note（2）","slug":"python/fluentpy2","date":"2018-11-02T08:55:43.000Z","updated":"2018-11-12T11:33:57.716Z","comments":true,"path":"2018/11/02/python/fluentpy2/","link":"","permalink":"https://langzi418.github.io/2018/11/02/python/fluentpy2/","excerpt":"可迭代对象、迭代器和生成器迭代器模式：惰性获取数据项的方式。","text":"可迭代对象、迭代器和生成器迭代器模式：惰性获取数据项的方式。 所有生成器都是迭代器，因为生成器完全实现了迭代器接口。在 Python社区中，大多数时候都把迭代器和生成器视作同一概念。 生成器应用广泛，即使是内置的range()也返回类似生成器对象，如果一定要返回列表，必须明确指明（例如，list(range(100))）。 序列可以迭代的原因：iter函数。 内置的iter函数有以下作用。 检查对象是否实现了__iter__方法，如果实现了即调用，获取一个迭代器。 如果没有实现__iter__方法，但实现了__getitem__方法。Python会创建一个迭代器，尝试按顺序（从索引0开始）获取元素。 失败，抛出TypeError异常。 任何 Python 序列都可迭代的原因是，它们都实现了__getitem__ 方法。其实，标准的序列也都实现了 __iter__方法，因此你也应该这么做。之所以对 __getitem__ 方法做特殊处理，是为了向后兼容，而未来可能不会再这么做（不过，写作本书时还未弃用）。 检查对象 x 能否迭代，最准确的方法是：调用 iter(x) 函数，如果不可迭代，再处理 TypeError 异常。 实现标准的可迭代协议12345678910111213141516171819202122232425class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): return SentenceIterator(self.words) class SentenceIterator: def __init__(self, words): self.words = words self.index = 0 def __next__(self): try: word = self.words[self.index] except IndexError: raise StopIteration() self.index += 1 return word def __iter__(self): return self Python函数中有yield生成器函数，返回生成器。 生成器表达式可以理解为列表推导的惰性版本：不会迫切地构建列表，而是返回一个生成器，按需惰性生成元素。 标准库中的生成器函数按用途可分为以下几类： 过滤 映射 合并 1234567891011121314151617181920&gt;&gt;&gt; def vowel(c):... return c.lower() in 'aeiou'...&gt;&gt;&gt; list(filter(vowel, 'Aardvark'))['A', 'a', 'a']&gt;&gt;&gt; import itertools&gt;&gt;&gt; list(itertools.filterfalse(vowel, 'Aardvark'))['r', 'd', 'v', 'r', 'k']&gt;&gt;&gt; list(itertools.dropwhile(vowel, 'Aardvark'))['r', 'd', 'v', 'a', 'r', 'k']&gt;&gt;&gt; list(itertools.takewhile(vowel, 'Aardvark'))['A', 'a']&gt;&gt;&gt; list(itertools.compress('Aardvark', (1,0,1,1,0,1)))['A', 'r', 'd', 'a']&gt;&gt;&gt; list(itertools.islice('Aardvark', 4))['A', 'a', 'r', 'd']&gt;&gt;&gt; list(itertools.islice('Aardvark', 4, 7))['v', 'a', 'r']&gt;&gt;&gt; list(itertools.islice('Aardvark', 1, 7, 2))['a', 'd', 'a'] yield from 语句。这个语句的作用就是把不同的生成器结合在一起使用。 上下文管理器和 else 块with open 创建文件不创建路径。 仅当 try 块中没有异常抛出时才运行 else 块。 123456try: dangerous_call()except OSError: log('OSError...')else: after_call() with语句的目的是简化try/finally模式。 与函数和模块不同，with 块没有定义新的作用域。 多线程与协程标准库中所有执行阻塞型 I/O 操作的函数，在等待操作系统返回结果时都会释放 GIL。这意味着在 Python 语言这个层次上可以使用多线程，而 I/O 密集型 Python 程序能从中受益：一个 Python 线程等待网络响应时，阻塞型 I/O 函数会释放 GIL，再运行一个线程。 Concurrency is when two or more tasks can start, run, and complete in overlapping time periods. It doesn’t necessarily mean they’ll ever both be running at the same instant. For example, multitaskingon a single-core machine. Parallelism is when tasks literally run at the same time, e.g., on a multicore processor. 异步库依赖于低层线程（直至内核级线程），但是这些库的用户无需创建线程，也无需知道用到了基础设施中的低层线程。在应用中，我们只需确保没有阻塞的代码，事件循环会在背后处理并发。异步系统能避免用户级线程的开销，这是它能比多线程系统管理更多并发连接的主要原因。 并发：充分运用CPU资源，主要是针对线程。 Coroutines12345678910111213async def say_after(delay, what): await asyncio.sleep(delay) print(what)async def main(): print(f\"started at &#123;time.strftime('%X')&#125;\") await say_after(1, 'hello') await say_after(2, 'world') print(f\"finished at &#123;time.strftime('%X')&#125;\")asyncio.run(main()) asyncio.run(coro,*,debug=False)当前线程存在一个事件循环时，该函数不能调用。 该函数调用时新建一个事件循环并在结束时关闭循环。它应该被用作异步程序的主入口并且理想情况下，应该只调用一次。 Task Objectclass asyncio.Task(coro,*,loop=None)Task用于在事件循环中运行协程。当一个协程等待一个Future时，Task中断协程的执行并等待Future完成。当Future完成，协程恢复。 事件循环使用竞争调度：一个事件循环同一时间只运行一个任务。然而，当一任务等待Future的完成时，事件循环运行其他任务等。 asyncio.create_task(coro)把协程包装成Task并调度其执行。Task在事件循环中执行，这个循环通过get_running_loop()获得，若当前线程没有事件循环，抛出RuntimeError。 12345678910111213141516async def say_after(delay, what): await asyncio.sleep(delay) print(what)async def main(): task1 = asyncio.create_task(say_after(1, 'hello')) task2 = asyncio.create_task(say_after(2, 'world')) print(f\"started at &#123;time.strftime('%X')&#125;\") # 并发执行 await task1 await task2 print(f\"finished at &#123;time.strftime('%X')&#125;\")asyncio.run(main()) Awaitables There are three main types of awaitable objects: coroutines, Tasks, and Futures. Tasks are used to schedule coroutines concurrently. A Future is a special low-level awaitable object that represents an eventual result of an asynchronous operation. Normally there is no need to create Future objects at the application level code. coroutine asyncio.sleep(delay, result=None, *, loop=None) sleep() always suspends the current task, allowing other tasks to run. Running Tasks Concurrentlyawaitable asyncio.gather(*aws, loop=None, return_exceptions=False)并发执行aws序列中的awaitable对象。 如果aws中有协程，自动当作Task调度。 If all awaitables are completed successfully, the result is an aggregate list of returned values. The order of result values corresponds to the order of awaitables in aws. If return_exceptions is False (default), the first raised exception is immediately propagated to the task that awaits on gather(). Other awaitables in the aws sequence won’t be cancelled and will continue to run. If return_exceptions is True, exceptions are treated the same as successful results, and aggregated in the result list. If gather() is cancelled, all submitted awaitables (that have not completed yet) are also cancelled. If any Task or Future from the aws sequence is cancelled, it is treated as if it raised CancelledError – the gather() call is not cancelled in this case. This is to prevent the cancellation of one submitted Task/Future to cause other Tasks/Futures to be cancelled. 元编程使用点号访问属性时，Python解释器会调用特殊方法（__getattr__和__setattr__）计算属性。 特性：在不改变类接口的前提下，使用存取方法（即读值方法和设值方法）修改数据属性。 使用特性验证属性@property 123456789101112131415161718192021class LineItem: def __init__(self, description, weight, price): self.description = description # 这里已经使用特性的设值方法了 self.weight = weight self.price = price def subtotal(self): return self.weight * self.price @property def weight(self): # 真正的值存储在私有属性 __weight 中 return self.__weight @weight.setter def weight(self, value): if value &gt; 0: self.__weight = value else: raise ValueError('value must be &gt; 0') 被装饰的读值方法有个 .setter 属性，这个属性也是装饰器；这个装饰器把读值方法和设值方法绑定在一起。 虽然property经常被当作装饰器使用，但它其实是一个类。构造方法如下： property(fget=None, fset=None, fdel=None, doc=None) 老版Python这样用：weight = property(get_weight, set_weight) 特性会覆盖实例属性特性都是类属性，但特性管理的其实是实例属性的存取。 实例属性遮盖类的数据属性，但实例属性不会遮盖类特性。 123456class Class: data = 'the class data attr' @property def prop(self): return 'the prop value' 123456789101112131415161718192021222324252627&gt;&gt;&gt; Class.prop # 获取特性对象本身，不会运行特性读值方法&lt;property object at 0x1072b7408&gt;&gt;&gt;&gt; obj.prop # 执行特性的读值方法'the prop value'&gt;&gt;&gt; obj.prop = 'foo' # 尝试给obj设置prop实例属性，失败（这实现了只读）Traceback (most recent call last):...AttributeError: can't set attribute &gt;&gt;&gt; obj.__dict__['prop'] = 'foo'# 但是可以直接把 'prop' 存入 obj.__dict__&gt;&gt;&gt; vars(obj) # &#123; 'data': 'bar','prop': 'foo'&#125;&gt;&gt;&gt; obj.prop # 然而，读取 obj.prop 时仍会运行特性的读值方法。特性没被实例属# 性遮盖。 'the prop value'&gt;&gt;&gt; Class.prop = 'baz' # 覆盖 Class.prop 特性，销毁特性对象。 &gt;&gt;&gt; obj.prop # 现在，obj.prop 获取的是实例属性。 'foo' 定义特性工厂函数123456789101112131415161718192021222324def quantity(storage_name): def qty_getter(instance): return instance.__dict__[storage_name] def qty_setter(instance, value): if value &gt; 0: # storage_name确定特性数据存储在哪儿 instance.__dict__[storage_name] = value else: raise ValueError('value must be &gt; 0') return property(qty_getter, qty_setter)class ListItem: # 使用工厂函数将自定义特性weight定义为类属性 weight = quantity('weight') price = quantity('price') def __init__(self, description, weight, price): self.description = description # 这里使用特性设值方法 self.weight = weight self.price = price 影响属性处理方式的特殊属性 __class__对象所属类的引用，Python的__getattr__只在类中寻找，而不在实例中寻找。__getattr__只处理不存在的属性名。 __dict__存储对象或类的可写属性。 特殊方法 __delattr__(self, name) 只要使用 del 语句删除属性，就会调用这个方法。 __getattr__(self, name)仅当获取指定的属性失败，搜索过 obj、Class 和超类之后调用。表达式 obj.no_such_attr、getattr(obj, ‘no_such_attr’) 和hasattr(obj, ‘no_such_attr’) 可能会触发Class.__getattr__(obj, &#39;no_such_attr&#39;)方法，但是，仅当在obj、Class 和超类中找不到指定的属性时才会触发。 __getattribute__(self, name) 点号与 getattr 和 hasattr 内置函数会触发这个方法。尝试获取指定的属性时总会调用这个方法，不过，寻找的属性是特殊属性或特殊方法时除外。调用 __getattribute__ 方法且抛出 AttributeError异常时，才会调用 __getattr__方法。 __setattr__(self, name, value) 点号和 setattr 内置函数会触发这个方法。 属性描述符描述符是对多个属性运行相同存取逻辑的一种方法。 描述符是实现了特定协议的类，这个协议包括__get__、__set__和__delete__。其实，我们在真实的代码中见到的大多数描述符只实现了 __get__ 和__set__ 方法，还有很多只实现了其中的一个。 property 类实现了完整的描述符协议。 特性工厂函数借助函数式编程模式避免重复编写读值方法和设值方法。解决这种问题的面向对象的方法是描述符类。 12345678910111213141516171819class Quantity: #描述符类基于协议实现 def __init__(self, storage_name): self.storage_name = storage_name # 尝试为托管属性赋值（weight、price）赋值时，会调用__set__ def __set__(self, instance, value): if value &gt; 0: instance.__dict__[self.storage_name] = value else: raise ValueError('value must be &gt; 0')class LineItem: weight = Quantity('weight') price = Quantity('price') def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price 类元编程类元编程是指在运行时创建或定制类的技术。 类装饰器也是函数，不过能够审查、修改，甚至把被装饰的类替换成其他类。 导入时和运行时区别——是有效使用Python元编程的重要基础。 类装饰器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class AutoStorage: # __counter = 0 def __init__(self): \"\"\"初始化工作在类修饰器中\"\"\" # cls = self.__class__ # prefix = cls.__name__ # index = cls.__counter # self.storage_name = f\"_&#123;prefix&#125;#&#123;index&#125;\" # cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): setattr(instance, self.storage_name, value)class Validated(abc.ABC, AutoStorage): def __set__(self, instance, value): value = self.validate(instance, value) super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return vaildated value or ValueError\"\"\"class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value &lt;= 0: raise ValueError('value must be &gt; 0') return valueclass NonBlank(Validated): \"\"\"a string non-space\"\"\" def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return valuedef entity(cls): for key, attr in cls.__dict__.items(): if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = f\"_&#123;type_name&#125;#&#123;key&#125;\" return cls 1234567891011121314151617181920import model_v5 as model@model.entityclass LineItem: description = model.NonBlank() weight = model.Quantity() price = model.Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = priceif __name__ == '__main__': item1 = LineItem(\"something\", 15, 12) print(dir(item1)[:3]) print(LineItem.description.storage_name) print(item1.description) print(getattr(item1, '_NonBlank#description')) 类装饰器以较简单的方式做到以前元类去做的事情——创建类时定制类。 类装饰器有个重大缺点：只对直接依附的类有效。这意味着，被装饰的类的子类可能继承也可能不继承装饰器所做的改动，具体情况视改动的方式而定。 元类用于构建类的类。Python中，类也是对象，因此类必然是某个类的实例。默认情况下，Python类是type类的实例。也就是说，type 是大多数内置的类和用户定义的类的元类。为了避免无限回溯，type 是其自身的实例。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://langzi418.github.io/tags/python/"}]},{"title":"FluentPy Note（1）","slug":"python/fluentpy","date":"2018-11-02T08:54:43.000Z","updated":"2018-11-12T11:33:52.157Z","comments":true,"path":"2018/11/02/python/fluentpy/","link":"","permalink":"https://langzi418.github.io/2018/11/02/python/fluentpy/","excerpt":"python数据模型如何创建符合python风格的类？","text":"python数据模型如何创建符合python风格的类？ 123456789101112131415161718Card = collections.namedtuple('Card', ['rank', 'suit'])class FrenchDeck: \"\"\"扑克牌类\"\"\" ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] 因__getitem__方法把 [ ] 操作交给self._cards列表，故FrenchDeck自动支持切片。 实现__getitem__方法，这个类就变成可迭代的；实现__len__，则可调用len() 迭代通常是隐式的，譬如一个集合类型没有实现__contains__方法，那么in运算符就会按顺序做一次迭代搜索。于是，in可用在FrenchDeck类上。 以上，通过实现__len()__和__getitem__，FrenchDeck就跟Python自有的序列数据类型一样，可以体现Python语言的核心特性（例如迭代和切片）。 如何使用特殊方法特殊方法是为被解释器调用的，在执行len(my_object)时，若my_object是自定义对象，那么解释器调用其实现的__len__ 如果是内置类型，如list、str、bytearray，CPython会抄近路…，快得多。 很多时候，特殊方法的调用是隐式的，如 for i in x -&gt; iter(x) -&gt; x.__iter__() 通常自己的代码无需直接使用特殊方法，除非有大量的元编程存在。 字符串表现形式repr()对应__repr__()，str()对应__str__() !r和!s是对应的格式符 两者的区别在于，__str__是在str()函数被使用，或是在print打印一个对象时候调用，且其返回的字符串更友好，没有引号(&#39;&#39;) 如果只想实现这两个特殊方法中的一个，__repr__是更好的选择。用为如果没有__str__，解释器会用__repr__作为替代。 自定义布尔值默认情况下，自定义类的实例总被认为是真，除非这个类对__bool__或者__len__ 有自己的实现。bool(x)调用x.__bool__()；若未定义__bool__方法，则尝试调用x.__len__()。若返回0，则为False，否则为True。 python中为False constants defined to be false: None and False. zero of any numeric type: 0, 0.0, 0j, Decimal(0), Fraction(0, 1) empty sequences and collections: &#39;&#39;, (), [], {}, set(), range(0) python特殊方法 类别 方法名 字符串/字节序列表示形式 __repr__ __str__ __format__ __bytes__ 数值转换 __abs__ __bool__ __complex__ __int__ __float__ __hash__ __index__ 集合模拟 __len__ __getitem__ __setitem__ __delitem__ __contains__ 迭代模拟 __iter__ __reversed__ __next__ 可调用模拟 __call__ 实例创建和销毁 __new__ __init__ __del__ 属性管理 __getattr__ __getattribute__ __setattr__ __delattr__ __dir__ 属性描述符 __get__ __set__ __delete__ 小结：通过实现特殊方法，自定义数据类型可以表现得跟内置类型一样，从而让我们写出更具表达力的代码——或者说，更具 Python 风格的代码。 数据结构python序列类型 容器序列：list、tuple和collections.deque 这些序列存放不同类型的数据。 扁平序列：str、bytes、bytearray、memoryview和array.array 这些只能容纳一种类型 容器序列存放的是任意类型对象的引用，而扁平序列存放的是值。即，扁平序列其实是一段连续的内存空间。由此可见，扁平序列更加紧凑，但只能存诸如字符、字节和数值这些基础类型。 序列还能按是否被修改分类： 可变序列 list、bytearray、array.array、collections.deque和memoryview 不可变序列 tuple、str和bytes 列表推导内置函数 ord() ：返回字符的Unicode码，如ord(‘a’)返回97； 与 chr() 效果相反。 列表推导同filter和map比较 123symbols = '$¢£¥€¤'beyond_ascii = [ord(s) for s in symbols if ord(s) &gt; 127]beyond_ascii = list(filter(lambda c: c &gt; 127, map(ord, symbols))) 生成器表达式虽然也能用列表推导来初始化元组、数组和其他序列类型，但生成器是更好的选择。 因为生成器表达式遵守迭代器协议，可逐个产出元素，而不是建立一个完整的列表，节约内存。 1tuple(ord(symbol) for symbol in symbols) 元组可用作不可变的列表，还可以用于没有字段名的记录。 若将元组理解为数据记录：元组中的每个元素都存放了记录中一个字段的数据，外加这个字段的位置。 元组拆包元组拆包可应用到任何可迭代的对象上（可迭代元素拆包）。 平行赋值latitude, longitude = (33.9425, -118.408056) 还可以用*运算符把可迭代对象拆开作为函数的参数 quotient, remainder = divmod(*t)。 拆包中，_ 为占位符。 用来处理剩下的元素 ` a, b, rest = range(5)` 嵌套元组拆包 1for name, cc, pop, (latitude, longitude) in metro_areas: 具名元组1Card = collections.namedtuple('Card', ['rank', 'suit']) namedtuple构建的类的实例所消耗的内存跟元组一样，因字段名都被存在对应的类里。 这个实例跟普通的对象实例比起来也要小一些，因Python不会用__dict__来存放这些实例的属性。 具名元组的专有属性： _fields属性是一个包含这个类所有字段的元组 _make()通过接受一个可迭代对象来生成这个类的一个实例 _asdict()把具名元组以collections.OrderedDict形式返回，友好呈现数据 切片s[a:b:c]形式对s在a和b之间以c为间隔取值。c也可以为负，意味反向取值。 1234567&gt;&gt;&gt; s = 'bicycle'&gt;&gt;&gt; s[::3]'bye'&gt;&gt;&gt; s[::-1]'elcycib'&gt;&gt;&gt; s[::-2]'eccb' 可以把切片放在赋值语句左边，或把它作为del操作的对象。 对序列使用+和*123&gt;&gt;&gt; l = [1, 2, 3]&gt;&gt;&gt; l * 5[1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3] 注意在l*n语句中，当序列 l里的元素是对其他可变对象的引用时： 如 my_list= [[]]*3，此时得到的列表里包含的其实是三个引用，而这三个引用指向的是用一个列表。 序列的增量赋值+=背后的特殊方法是__iadd__（“就地加法”）。但如果一个类没有实现这个方法的话，Python会退一步调用__add__。 1a += b 如果 a 实现了__iadd__ 方法，就会调用这个方法。同时对可变序列（例如 list、bytearray 和 array.array）来说，a 会就地改动，就像调用了 a.extend(b) 一样。但是如果 a 没有实现__iadd__ 的话，a+= b 这个表达式的效果就变得跟 a = a + b 一样了：首先计算 a +b，得到一个新的对象，然后赋值给 a。 list.sort()和内置的sorted()参数：reversed 、key 可用bisect管理已排序的序列 当列表不是首选时 存放1000万个浮点数，数组（array）的效率要高得多，因数组背后存放的不是float对象，而是数字的机器翻译，也就是字节表述。 如果需要频繁对序列做先进先出的操作，deque（双端队列）的速度更快。 若检查一个元素是否出现的操作频率很高，用set更合适。 数组如果需要一个只包含数字的列表，那么 array.array 比 list 更高效。数组支持所有跟可变序列有关的操作，包括 .pop 、.insert 和 .extend。另外，数组还提供从文件读取和存入文件的更快的方法，如 .frombytes 和 .tofile。 创建数组需要指定类型码，如 b 类型码代表有符号的字符（signed char） d 代表双精度实数 h 代表短整型有符号整数 123456789101112floats = array('d', (random() for i in range(10 ** 7)))print(floats[-1])# 存with open('output/test/floats.bin', 'wb') as fp: floats.tofile(fp)floats2 = array('d')# 取with open('output/test/floats.bin', 'rb') as fp: floats2.fromfile(fp, 10 ** 7)print(floats2[-1]) 数组排序，需新建一个数组a = array.array(a.typecode, sorted(a)) memoryview是内置类，它能让用户在不复制内容的情况下操作同一个数组的不同切片。 双向队列和其他形式队列列表利用 .append 和 .pop(0) 合起来，就能模拟队列“先进先出”特点，但是删除列表的第一个元素（在第一个元素前插入元素）之类的操作很耗时，因这些操作牵扯移动列表里所有元素。 collections.deque（双向队列）是一个线程安全、可以快速从两端添加或删除元素的数据类型。 123456789101112131415161718&gt;&gt;&gt; dq = deque(range(10), maxlen=10)&gt;&gt;&gt; dqdeque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)&gt;&gt;&gt; dq.rotate(3) # 右移&gt;&gt;&gt; dqdeque([7, 8, 9, 0, 1, 2, 3, 4, 5, 6], maxlen=10)&gt;&gt;&gt; dq.rotate(-4) # 左移&gt;&gt;&gt; dqdeque([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], maxlen=10)&gt;&gt;&gt; dq.appendleft(-1)&gt;&gt;&gt; dqdeque([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)&gt;&gt;&gt; dq.extend([11, 22, 33]) &gt;&gt;&gt; dqdeque([3, 4, 5, 6, 7, 8, 9, 11, 22, 33], maxlen=10)&gt;&gt;&gt; dq.extendleft([10, 20, 30, 40]) &gt;&gt;&gt; dqdeque([40, 30, 20, 10, 3, 4, 5, 6, 7, 8], maxlen=10) 双向队列也付出了一些代价，从队列中间删除元素的操作会慢一些，因为它只对在头尾的操作进行了优化。 字典和集合泛映射类型 以上是形式化的文档，定义了最基本的接口，还可以用来跟 isinstance 做类型判断。非抽象映射类型一般直接对 dict 或是 collections.User.Dict 进行扩展。 标准库中所有的映射类型都是利用dict来实现的，因此有共同的限制，即只有可散列的数据类型才能用作这些映射里的键（值不需要可散列）。 什么是可散列的？ 如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变的。而且这个对象需要实现__hash__()，还要有__qe__()。如果两个可散列的对象是相等的，散列值一定相等。 原子不可变数据类型（str、bytes 和数值类型）都是可散列类型，frozenset 也是可散列的，因为根据其定义，frozenset 里只能容纳可散列类型。元组的话，只有当一个元组包含的所有元素都是可散列类型的情况下，它才是可散列的。 字典构造1234567&gt;&gt;&gt; a = dict(one=1, two=2, three=3)&gt;&gt;&gt; b = &#123;'one': 1, 'two': 2, 'three': 3&#125;&gt;&gt;&gt; c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))&gt;&gt;&gt; d = dict([('two', 2), ('one', 1), ('three', 3)])&gt;&gt;&gt; e = dict(&#123;'three': 3, 'one': 1, 'two': 2&#125;)&gt;&gt;&gt; a == b == c == d == eTrue 字典推导1country_code = &#123;country: code for code, country in DIAL_CODES&#125; 用setdefault处理找不到的键可以用 d.get(k, default) 来代替 d[k]，给找不到的键一个默认的返回值（这比处理 KeyError 要方便不少） 1my_dict.setdefault(key, []).append(new_value) 等价于 123if key not in my_dict: my_dict[key] = []my_dict[key].append(new_value) 映射的弹性键查询有时候为了方便起见，就算某个键在映射里不存在，我们也希望在通过这个键读取值的时候能得到一个默认值。 一个是通过 defaultdict 这个类型而不是普通的 dict，另一个是给自己定义一个 dict 的子类，然后在子类中实现 __missing__ 方法。 对于defaultdict: 如 dd = defaultdict(list)，这里将 list 指定为 default_factory，它是defaultdict用来生成默认值的实例属性，需要存放可调用对象。 这里，若dd[&#39;new_key&#39;]中键 ‘new_key’ 不存在的话，按以下处理： 调用 list() 来建立一个新列表。 把这个新列表作为值，’new-key’ 作为它的键，放到 dd 中。 返回这个列表的引用。 defaultdict 里的 default_factory 只会在__getitem__里被调用，也就是dd[k]会调用default_factory，而dd.get(k)则会返回None。 所有这一切背后的功臣其实是特殊方法 __missing__。它会在defaultdict 遇到找不到的键的时候调用 default_factory，而实际上这个特性是所有映射类型都可以选择去支持的。 特殊方法__missing__如果有一个类继承了 dict，然后这个继承类提供了__missing__方法，那么在 __getitem__ 碰到找不到的键的时候，Python 就会自动调用它，而不是抛出一个 KeyError 异常。 __missing__ 方法只会被 __getitem__ 调用（比如在表达式 d[k] 中） 字典的变种 collections.OrderedDict 这个类型添加键时会保持顺序，因此键的迭代次序总是一致的。 collections.ChainMap 该类型可容纳数个不同的映射对象，然后查找时，会当作一个整体查找，直到键被找到为止。如Python变量查找规则： 12import builtinspylookup = ChainMap(locals(), globals(), vars(builtins)) collections.Counter 这个类会给键设置一个整数计数器。更新键时会增加这个计数器，可用来计数。 不可变映射类型types 模块中引入了一个封装类名叫MappingProxyType。如果给这个类一个映射，它会返回一个只读的映射视图。虽然是个只读视图，但是它是动态的。这意味着如果对原映射做出了改动，我们通过这个视图可以观察到，但是无法通过这个视图对原映射做出修改。 集合论集合中的元素必须是可散列的，set类型本身是不可散列的，但是frozenset可以。因此可以创建一个包含不同frozenset的set。 集合中缀表达式： a | b : 并集、 a &amp; b : 交集、a - b : 差集 如：needles 的元素在 haystack 里出现的次数，两个变量都是 set 类型 1found = len(needles &amp; haystack) 以上代码可以用在任何可迭代对象上： 123found = len(set(needles) &amp; set(haystack))# 另一种写法：found = len(set(needles).intersection(haystack)) 集合字面量集合字面量 ： {…}，空集：set() 集合推导 {func(i) for i in iterable} dict与散列表由于字典使用了散列表，而散列表又必须是稀疏的，这导致它在空间上的效率低下。 用元组取代字典就能节省空间的原因有两个：其一是避免了散列表所耗费的空间，其二是无需把记录中字段的名字在每个元素里都存一遍。 set与散列表set 和 frozenset 的实现也依赖散列表，但在它们的散列表里存放的只有元素的引用（就像在字典里只存放键而没有相应的值）。在 set 加入到 Python 之前，我们都是把字典加上无意义的值当作集合来用的。 一等函数高阶函数接受函数为参数，或者把函数作为结果返回的函数是高阶函数。 可调用对象 用户定义的函数：使用 def 语句或 lambda 表达式创建。 内置函数：使用 C 语言（CPython）实现的函数，如 len 或 time.strftime。 内置方法：使用 C 语言实现的方法，如 dict.get。 方法：在类的定义体中定义的函数。 类：调用类时会运行类的__new__方法创建一个实例，然后运行__init__ 方法，初始化实例，最后把实例返回给调用方。因为 Python没有 new 运算符，所以调用类相当于调用函数。 类的实例：如果类定义了 __call__ 方法，那么它的实例可以作为函数调用。 生成器函数：使用yield关键字的函数或方法。调用生成器函数返回的是生成器对象。 callable()判断对象是否可以调用。 从定位参数到仅限关键字参数123456789101112def tag(name, *content, cls=None, **attrs): ... # 调用tag('br')tag('p','hello')tag('p','hello',id=33)tag('p','hello','world',cls='sidebar')tag(content='testing',name='img')my_tag = &#123;'name': 'img', 'title': 'Sunset Boulevard', 'src': 'sunset.jpg', 'cls': 'framed'&#125;tag(**my_tag) 以上 cls参数 只能通过关键字指定，它一定不会捕获未命名的定位参数。 定义函数时若想指定关键字参数，要把它们放到有 的参数后面。如果不想支持数量不定的定位参数，但想支持仅限关键字参数，在签名中放一个 ，如下： 1234def f(a,*,b): return a,bprint(f(1,b=2))(1,2) 注意，仅限关键字参数不一定要有默认值，可以像上例中 b 那样，强制必须传入实参。 内省：获取关于参数的信息与内省有关的函数对象 __defaults__属性，它的值是一个元组，保存着定位参数和关键字参数的默认值。 __kwdefaults__属性，保存仅限关键字参数默认值。 __code__属性，保存参数的名称，它的值是一个code对象的引用，自身也有很多属性。 相关模块：inspect 支持函数式编程的包operator模块为多个算术运算符提供了对应的函数，从而避免编写平凡的匿名函数。 1234from functools import reducefrom operator import muldef fact(n): return reduce(mul, range(1, n+1)) operator模块中的itemgetter、attrgetter能从序列中取出元素或读取对象属性。 123456for city in sorted(metro_data, key=itemgetter(1)): print(city)cc_name = itemgetter(1, 0)for city in metro_data: print(cc_name(city)) itemgetter使用[]运算符，因此它不仅支持序列，还支持映射和任何实现__getitem__方法的类。 attrgetter 与 itemgetter 作用类似，它创建的函数根据名称提取对象的属性。如果把多个属性名传给 attrgetter，它也会返回提取的值构成的元组。此外，如果参数名中包含 .（点号），attrgetter 会深入嵌套对象，获取指定的属性。 12345from operator import attrgettername_lat = attrgetter('name', 'coord.lat') for city in sorted(metro_areas, key=attrgetter('coord.lat')): print(name_lat(city)) functools.partial冻结参数1234567&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; triple = partial(mul, 3) &gt;&gt;&gt; triple(7) 21# 使用 partial 构建一个便利的 Unicode 规范化函数nfc = functools.partial(unicodedata.normalize, 'NFC') 使用函数实现设计模式策略模式12345678910111213141516171819202122232425262728293031class Order: # 上下文 def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion(self) return self.total() - discount promos = [func for name, func in inspect.getmembers(promotions, inspect.isfunction)]def best_promo(order): \"\"\"选择可用的最佳折扣 \"\"\" return max(promo(order) for promo in promos)# promotions.pydef fidelity_promo(order): passdef bulk_item_promo(order): pass 函数装饰器和闭包装饰器是可调用对象，其参数是另一个函数（被装饰的函数）。装饰器可能会处理被装饰的函数，然后把它返回，或者将其替换成另一个函数或可调用的对象。 1234567@decoratedef target(): print('running target()')# 等价于def target(): print('running target()')target = decorate(target) 严格来说，装饰器只是语法糖。 Python在何时执行装饰器？函数装饰器在导入模块时立即执行，而被装饰的函数只在明确调用时运行。这突出了导入时和运行时的区别。 使用装饰器改进策略模式1234567891011121314151617promos = []def promotion(promo_func): promos.append(promo_func) return promo_func@promotiondef fidelity_promo(order): # 第一个具体策略@promotiondef bulk_item_promo(order): # 第二个具体策略@promotiondef large_order_promo(order): # 第三个具体策略def best_promo(order): return max(promo(order) for promo in promos) 变量作用域规则1234567891011&gt;&gt;&gt; b = 6&gt;&gt;&gt; def f2(a):... print(a)... print(b)... b = 9...&gt;&gt;&gt; f2(3)3Traceback (most recent call last):...UnboundLocalError: local variable 'b' referenced before assignment Python不要求声明变量，但是假定在函数定义体中的变量是局部变量，参数也是。 闭包闭包是指延伸了作用域的函数，其中包含函数定义体中引用、但是不在定义体中定义的非全局变量。 综上，闭包是一种函数，它会保留定义函数时存在的自由变量的绑定。这样调用函数时，虽然定义作用域不可用了，但仍能使用那些绑定。 nonlocal声明12345678910111213141516171819202122232425def make_averager(): count = 0 total = 0 def averager(new_value): count += 1 total += new_value return total / count return averager&gt;&gt;&gt; avg = make_averager()&gt;&gt;&gt; avg(10)Traceback (most recent call last):...UnboundLocalError: local variable 'count' referenced before assignment&gt;&gt;&gt;def make_averager(): count = 0 total = 0 def averager(new_value): nonlocal count, total count += 1 total += new_value return total / count return averager 实现一个简单的装饰器装饰器的典型行为：把被装饰的函数替换成新函数，二者接受相同的参数，而且（通常）返回被装饰函数本该返回的值，同时做些额外的操作。 12345678910def clock(func): def clocked(*args): t0 = time.perf_counter() result = func(*args) elapsed = time.perf_counter() - t0 name = func.__name__ arg_str = ', '.join(repr(arg) for arg in args) print('[%0.8fs] %s(%s) -&gt; %r' % (elapsed, name, arg_str, result)) return result return clocked 以上实现的装饰器有缺点：遮盖了被装饰函数的__name__和__doc__属性。 可使用functools.wraps 装饰器把相关的属性从 func 复制到 clocked 中。 123456789101112131415161718def clock(func): @functools.wraps(func) def clocked(*args, **kwargs): t0 = time.time() result = func(*args, **kwargs) elapsed = time.time() - t0 name = func.__name__ arg_lst = [] if args: arg_lst.append(', '.join(repr(arg) for arg in args)) if kwargs: pairs = ['%s=%r' % (k, w) for k, w in sorted(kwargs.items())] arg_lst.append(', '.join(pairs)) arg_str = ', '.join(arg_lst) print('[%0.8fs] %s(%s) -&gt; %r ' % (elapsed, name, arg_str, result)) return result # 返回一个被装饰过的函数 return clocked Python 内置了三个用于装饰方法的函数：property、classmethod 和staticmethod。 另一个常见的装饰器是 functools.wraps，它的作用是协助构建行为良好的装饰器。标准库中最值得关注的两个装饰器是 lru_cache 和全新的 singledispatch。 functools.lru_cache做备忘123456789101112131415@functools.lru_cache() @clock def fibonacci(n): if n &lt; 2: return n return fibonacci(n-2) + fibonacci(n-1)$ python3 fibo_demo_lru.py[0.00000119s] fibonacci(0) -&gt; 0[0.00000119s] fibonacci(1) -&gt; 1[0.00010800s] fibonacci(2) -&gt; 1[0.00000787s] fibonacci(3) -&gt; 2[0.00016093s] fibonacci(4) -&gt; 3[0.00001216s] fibonacci(5) -&gt; 5[0.00025296s] fibonacci(6) -&gt; 8 functools.singledispatch 装饰器它可以把整体方案拆分成多个模块，甚至可以为你无法修改的类提供专门的函数。使用@singledispatch装饰的普通函数会变成泛函数（generic function）：根据第一个参数的类型，以不同方式执行相同操作的一组函数。 123456789101112131415161718192021# @singledispatch标记处理object类型的基函数@singledispatch def htmlize(obj): content = html.escape(repr(obj)) return '&lt;pre&gt;&#123;&#125;&lt;/pre&gt;'.format(content)@htmlize.register(str) def _(text): content = html.escape(text).replace('\\n', '&lt;br&gt;\\n') return '&lt;p&gt;&#123;0&#125;&lt;/p&gt;'.format(content)@htmlize.register(numbers.Integral) def _(n): return '&lt;pre&gt;&#123;0&#125; (0x&#123;0:x&#125;)&lt;/pre&gt;'.format(n)# 叠放多个register装饰器，让同一个函数支持不同类型@htmlize.register(tuple) @htmlize.register(abc.MutableSequence)def _(seq): inner = '&lt;/li&gt;\\n&lt;li&gt;'.join(htmlize(item) for item in seq) return '&lt;ul&gt;\\n&lt;li&gt;' + inner + '&lt;/li&gt;\\n&lt;/ul&gt;' 以上各个专门函数使用@base_function.register(type)装饰。专门函数的名称无关紧要；使用 _ 简单明了。 只要可能，注册的专门函数应该处理抽象基类（如 numbers.Integral和 abc.MutableSequence），不要处理具体实现（如 int 和list）。这样，代码支持的兼容类型更广泛。 参数化装饰器怎么让装饰器接受其他参数？ 创建一个装饰器工厂函数，返回装饰器。 123456789101112registry = set()def register(active=True): def decorate(func): print('running register(active=%s)-&gt;decorate(%s)' % (active, func)) if active: registry.add(func) else: registry.discard(func) return func return decorate 对象引用、可变性和垃圾回收== 运算符比较两个对象的值（对象中保存的数据），而 is 比较对象的标识。 元组的相对不可变性元组与多数Python容器（列表、字典、集）一样，保存的是对象的引用。元组的不可变性其实是指tuple数据结构的物理内容（即保存的引用）不可变，与引用的对象无关。 元组的相对不变性也是，有些元组不可散列的原因。 默认做浅复制复制列表（或多数内置的可变集合）最简单的方式是使用内置类型的构造方法。 12345678&gt;&gt;&gt; l1 = [3, [55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 = list(l1) &gt;&gt;&gt; l2[3, [55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 == l1 True&gt;&gt;&gt; l2 is l1 False 以上看出，二者指代不同的对象。对列表和其他可变序列来说，还能使用简洁的l2=l1[:]语句来创建副本。 然而，构造方法或[:]做的是浅复制（即复制了最外层的容器，副本中的元素是源容器中元素的引用）。如果所有的元素都是不可变的，那么这样没问题。但是，如果有可变元素，可能就会导致意想不到的问题。 12345678910111213&gt;&gt;&gt; import copy&gt;&gt;&gt; bus1 = Bus(['Alice', 'Bill', 'Claire', 'David'])&gt;&gt;&gt; bus2 = copy.copy(bus1)&gt;&gt;&gt; bus3 = copy.deepcopy(bus1)&gt;&gt;&gt; id(bus1), id(bus2), id(bus3)(4301498296, 4301499416, 4301499752) ➊&gt;&gt;&gt; bus1.drop('Bill')&gt;&gt;&gt; bus2.passengers['Alice', 'Claire', 'David'] ➋&gt;&gt;&gt; id(bus1.passengers), id(bus2.passengers), id(bus3.passengers)(4302658568, 4302658568, 4302657800) ➌&gt;&gt;&gt; bus3.passengers['Alice', 'Bill', 'Claire', 'David'] ➍ 浅复制，不同引用，同一个对象；深复制，不同引用，不同对象。 函数的参数作为引用时Python 唯一支持的参数传递模式是共享传参。共享传参指函数的各个形式参数获得实参中各个引用的副本。也就是说，函数内部的形参是实参的别名。 Java 的引用类型是这样，基本类型按值传参（函数得到参数的副本）。 函数可能会修改接收到的任何可变对象 12345678910111213141516171819202122&gt;&gt;&gt; def f(a, b):... a += b... return a...&gt;&gt;&gt; x = 1&gt;&gt;&gt; y = 2&gt;&gt;&gt; f(x, y)3&gt;&gt;&gt; x, y (1, 2)&gt;&gt;&gt; a = [1, 2]&gt;&gt;&gt; b = [3, 4]&gt;&gt;&gt; f(a, b)[1, 2, 3, 4]&gt;&gt;&gt; a, b ([1, 2, 3, 4], [3, 4])&gt;&gt;&gt; t = (10, 20)&gt;&gt;&gt; u = (30, 40)&gt;&gt;&gt; f(t, u)(10, 20, 30, 40)&gt;&gt;&gt; t, u ((10, 20), (30, 40)) 防御可变参数不要使用可变类型作为参数的默认值。 del和垃圾回收del 语句删除名称，而不是对象。del 命令可能会导致对象被当作垃圾回收，但是仅当删除的变量保存的是对象的最后一个引用，或者无法得到对象时。 重新绑定也可能会导致对象的引用数量归零，导致对象被销毁。 符合Python风格的对象因Python数据模型，自定义类型行为可以像内置类型那样自然。实现如此自然的行为，靠的不是继承，而是鸭子类型（会叫即鸭子）：只需按照预定行为实现对象所需的方法（一般特殊方法）即可。 classmethod与staticmethodclassmethod定义操作类，而不是操作实例的方法。classmethod中第一个参数始终是类本身。classmethod最常用的用途是定义备选构造方法。staticmethod就是普通函数，只是碰巧在类的定义中。 格式化显示&#39;{0.mass:5.3e}&#39; 这样的格式字符串其实包含两部分，冒号左边的 ‘0.mass’ 在代换字段句法中是字段名，冒号后面的 ‘5.3e’ 是格式说明符 str.format() 格式说明符使用的表示法是格式规范化微语言（formatspec）。 New in Python3.6 f-string 真正的运行时计算；双引号 !r 调用 repr()、!s调用 str()、!a调用ascii() Python的私有属性和“受保护的”属性为避免子类意外覆盖“私有”属性，以形如__mode的形式（两个前导下划线）命名实例属性，Python会把属性名存入实例的__dict__属性中，而且会在前面加一个下划线和类名，因此有_Class__mode和_Subclass__mode。 有些Python程序员约定使用一个下划线前缀编写“受保护”的属性（如 self._x）。 默认情况下，各个实例在名为__dict__的特殊属性中存储实例属性。 __slots__类属性，让解释器在元组中储存实例属性，而不是用字典。这样节省大量内存。在类中定义__slots__ 属性的目的是告诉解释器：“这个类中的所有实例属性都在这儿了！” 仅当权衡当下的需求并仔细搜集资料后证明确实有必要时，才应该使用__slots__ 属性。 覆盖类属性Python中：类属性可用于为实例属性提供默认值。 为不存在的实例属性赋值，会创建新的实例属性。为实例属性赋值后，同名的类属性不受影响。然而自此之后，self.objattr读取的是实例属性objattr，也就把类属性覆盖了。 在 Python中，我们可以先使用公开属性，然后等需要时再变成特性。 序列的修改、散列、切片序列类型的构造方法应该接受可迭代的对象为参数，因为所有内置的序列类型就是这样做的。 切片原理Python如何把seq[1:3]句法变成传给seq.__getitem__(...)的参数。 123456789101112131415&gt;&gt;&gt; class MySeq:... def __getitem__(self, index):... return index ...&gt;&gt;&gt; s = MySeq()&gt;&gt;&gt; s[1] 1&gt;&gt;&gt; s[1:4] slice(1, 4, None)&gt;&gt;&gt; s[1:4:2] slice(1, 4, 2)&gt;&gt;&gt; s[1:4:2, 9] (slice(1, 4, 2), 9)&gt;&gt;&gt; s[1:4:2, 7:9] (slice(1, 4, 2), slice(7, 9, None)) indices：假设有个长度为 5 的序列，例如 ‘ABCDE’： 1234&gt;&gt;&gt; slice(None, 10, 2).indices(5) # ➊(0, 5, 2)&gt;&gt;&gt; slice(-3, None, None).indices(5) # ➋(2, 5, 1) ❶ ‘ABCDE’[:10:2] 等同于 ‘ABCDE’[0:5:2]❷ ‘ABCDE’[-3:] 等同于 ‘ABCDE’[2:5:1] 当没有底层序列类型作为依靠，那么使用此方法能节省大量时间。 属性查找失败后，解释器会调用__getattr__方法。简单来说，对my_obj.x 表达式，Python 会检查 my_obj 实例有没有名为 x 的属性；如果没有，到类（my_obj.__class__）中查找；如果还没有，顺着继承树继续查找。 如果依旧找不到，调用 my_obj 所属类中定义的__getattr__ 方法，传入 self 和属性名称的字符串形式（如 ‘x’）。 zip函数zip函数用于并行迭代两个或多个可迭代对象。当一个可迭代的对象耗尽后，它不发出警告就停止。itertools.zip_longest函数的行为有所不同：使用可选的fillvalue填充缺失的值，直到最长的可迭代对象耗尽。 为了避免在for循环中手动处理索引变量，还经常使用内置的enumerate生成器函数。 抽象基类抽象基类常见用途：实现接口时作为超类使用。抽象基类如何检查具体子类是否符合接口定义？如何使用注册机制声明一个类实现了某个接口，而不进行子类化操作。最后说明如何让抽象基类自动“识别”任何符合接口的类——不进行子类化或注册。 Python 是动态语言，因此我们可以在运行时修正一些问题。 object does not support item assignment 问题：可变的序列还必须提供 __setitem__方法。 标准库中的抽象基类collections.abc中的抽象基类最常用。 自定义抽象基类抽象方法使用@abc.abstractmethod标记，而且定义体中通常只有文档字符串。”是否实现抽象方法”基类检测子类是否符合接口的依据。 声明抽象基类最简单的方法是继承abc.ABC或其他抽象基类。 声明抽象类方法 12345class MyABC(abc.ABC): @classmethod @abc.abstractmethod def an_abstract_classmethod(cls, ...): pass 与其他描述符一起使用时，abstractmethod()应放在最里层。 虚拟子类Python新编程风格：使用抽象基类明确声明接口，而且类可以子类化抽象基类或抽象基类注册（无需在继承关系中确立静态的强链接），宣称它实现了某个接口。 继承的优缺点不要子类化内置类型，自定义类应该继承collections模块中的类，例如UserDict、UserList和UserString，它们易于扩展。 运算符重载一元运算符- (__neg__) 、+ (__pos__)、 ~(__invert__) 支持一元运算符很简单，只需实现相应的特殊方法。这些特殊方法只有一个参数，self。运算符一个基本规则：始终返回一个新对象。也就是说，不能修改self，要创建并返回合适类型的新实例。","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://langzi418.github.io/tags/python/"}]}]}